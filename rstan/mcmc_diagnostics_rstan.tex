% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Stan Program}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Markov Chain Monte Carlo Diagnostics},
  pdfauthor={Michael Betancourt},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Markov Chain Monte Carlo Diagnostics}
\author{Michael Betancourt}
\date{2023-07-01}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[sharp corners, boxrule=0pt, breakable, enhanced, borderline west={3pt}{0pt}{shadecolor}, interior hidden, frame hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
In this short note I will preview the new suite of Markov chain Monte
Carlo analysis tools that I will be introducing more formally in
upcoming writing. These tools largely focus on diagnostics but there are
also a few that cover Markov chain Monte Carlo estimation assuming a
central limit theorem.

We'll start with diagnostics specific to Hamiltonian Monte Carlo then
consider more generic diagnostics that consider each expectand of
interest one at a time. Finally we'll look at a way to visualize
one-dimensional pushforward distributions using Markov chain Monte Carlo
to estimate bin probabilities.

Before any of that, however, we need to set up our graphics.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{family=}\StringTok{"serif"}\NormalTok{, }\AttributeTok{las=}\DecValTok{1}\NormalTok{, }\AttributeTok{bty=}\StringTok{"l"}\NormalTok{, }\AttributeTok{cex.axis=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.lab=}\DecValTok{1}\NormalTok{, }\AttributeTok{cex.main=}\DecValTok{1}\NormalTok{,}
    \AttributeTok{xaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{yaxs=}\StringTok{"i"}\NormalTok{, }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{))}
  
\NormalTok{c\_light }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#DCBCBC"}\NormalTok{)}
\NormalTok{c\_light\_highlight }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#C79999"}\NormalTok{)}
\NormalTok{c\_mid }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#B97C7C"}\NormalTok{)}
\NormalTok{c\_mid\_highlight }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#A25050"}\NormalTok{)}
\NormalTok{c\_dark }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#8F2727"}\NormalTok{)}
\NormalTok{c\_dark\_highlight }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#7C0000"}\NormalTok{)}

\NormalTok{c\_light\_teal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#6B8E8E"}\NormalTok{)}
\NormalTok{c\_mid\_teal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#487575"}\NormalTok{)}
\NormalTok{c\_dark\_teal }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"\#1D4F4F"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{extraction}{%
\section{Extraction}\label{extraction}}

The \texttt{extract} function in \texttt{RStan} parses the Markov chain
output within a \texttt{StanFit} object into a usable format. Due to
some unfortunate choices in early development, however, the function
behaves a bit awkwardly.

By default it permutes the Markov chain iterations and then aggregates
them together. This permutation strips the iterations of their
autocorrelations, making it impossible to recover accurate estimates of
the Markov chain Monte Carlo estimator error.

There is an optional argument that deactivates the permutation, but that
also completely changes the output format. In particular it strips the
expectands of their names, requiring that users access each expectand by
the order in which they appear in the original Stan program.

Finally the \texttt{extract} function also ignores all of the
Hamiltonian Monte Carlo diagnostic information emitted at each
transition. Instead the \texttt{get\_sampler\_params} function recovers
this information, albeit it yet another output format.

To facilitate the analysis of Stan output I've included my own custom
extract functions that format the Markov chain Monte Carlo output into
named lists, with one named element for each expectand or Hamiltonian
Monte Carlo diagnostic. The elements themselves are two-dimensional
arrays with the first index denoting the individual Markov chains and
the second index denoting the iterations within an individual Markov
chain.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract unpermuted expectand values from a StanFit object and format }
\CommentTok{\# them for convenient access.  Removes the auxiliary \textasciigrave{}lp\_\_\textasciigrave{} variable.}
\CommentTok{\# @param stan\_fit A StanFit object}
\CommentTok{\# @return A named list of two{-}dimensional arrays for each expectand in }
\CommentTok{\#         the StanFit object.  The first dimension of each element }
\CommentTok{\#         indexes the Markov chains and the second dimension indexes the }
\CommentTok{\#         sequential states within each Markov chain. }
\NormalTok{extract\_expectands }\OperatorTok{\textless{}{-}}\NormalTok{ function(stan\_fit) \{}
\NormalTok{  nom\_params }\OperatorTok{\textless{}{-}}\NormalTok{ rstan:::extract(stan\_fit, permuted}\OperatorTok{=}\NormalTok{FALSE)}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ dim(nom\_params)[}\DecValTok{3}\NormalTok{] }\OperatorTok{{-}} \DecValTok{1}
\NormalTok{  params }\OperatorTok{\textless{}{-}}\NormalTok{ lapply(}\DecValTok{1}\NormalTok{:N, function(n) t(nom\_params[,,n]))}
\NormalTok{  names(params) }\OperatorTok{\textless{}{-}}\NormalTok{ names(stan\_fit)[}\DecValTok{1}\NormalTok{:N]}
\NormalTok{  (params)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract Hamiltonian Monte Carlo diagnostics values from a StanFit}
\CommentTok{\# object and format them for convenient access.}
\CommentTok{\# @param stan\_fit A StanFit object}
\CommentTok{\# @return A named list of two{-}dimensional arrays for each expectand in }
\CommentTok{\#         the StanFit object.  The first dimension of each element }
\CommentTok{\#         indexes the Markov chains and the second dimension indexes the }
\CommentTok{\#         sequential states within each Markov chain. }
\NormalTok{extract\_hmc\_diagnostics }\OperatorTok{\textless{}{-}}\NormalTok{ function(stan\_fit) \{}
\NormalTok{  diagnostic\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}treedepth\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{, }
                        \StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}energy\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{)}

\NormalTok{  nom\_params }\OperatorTok{\textless{}{-}}\NormalTok{ get\_sampler\_params(stan\_fit, inc\_warmup}\OperatorTok{=}\NormalTok{FALSE)}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ length(nom\_params)}
\NormalTok{  params }\OperatorTok{\textless{}{-}}\NormalTok{ lapply(diagnostic\_names, }
\NormalTok{                   function(name) t(sapply(}\DecValTok{1}\NormalTok{:C, function(c) }
\NormalTok{                                  nom\_params[c][[}\DecValTok{1}\NormalTok{]][,name])))}
\NormalTok{  names(params) }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostic\_names}
\NormalTok{  (params)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If users are able to modify these functions to accept the output from
other interfaces to Stan and return the same output format then all of
the following functions will be immediately available. That is all
except for the \texttt{plot\_inv\_metric} function which does require a
separate \texttt{RStan}-specific function for extracting adaptation
information.

\hypertarget{hamiltonian-monte-carlo-diagnostics}{%
\section{Hamiltonian Monte Carlo
Diagnostics}\label{hamiltonian-monte-carlo-diagnostics}}

Hamiltonian Monte Carlo introduces a suite of powerful diagnostics that
can identify obstructions to Markov chain Monte Carlo central limit
theorems. These diagnostics are not only extremely sensitive but also
probe the behavior of the entire Markov chain state instead of the
projections of that state through single expectands.

\hypertarget{check-hamiltonian-monte-carlo-diagnostics}{%
\subsection{Check Hamiltonian Monte Carlo
Diagnostics}\label{check-hamiltonian-monte-carlo-diagnostics}}

All of our diagnostics are assembled in this single
\texttt{check\_all\_hmc\_diagnostics} function.

The first diagnostic looks for unstable numerical Hamiltonian
trajectories, or divergences. These unstable trajectories are known to
obstruct typical central limit theorem conditions. Divergences arise
when the target distribution is compressed into a narrow region; this
forces the Hamiltonian dynamics to accelerate which makes them more
difficult to accurately simulate.

Increasing \texttt{adapt\_delta} will on average result in a less
aggressive step size optimization that in some cases may improve the
stability of the numerical integration but at the cost of longer, and
hence more expensive, numerical Hamiltonian trajectories. In most cases,
however, the only productive way to avoid divergences is to
reparameterize the ambient space to decompress these pinches in the
target distribution.

Stan's Hamiltonian Monte Carlo sampler expands the length of the
numerical Hamiltonian trajectories dynamically to maximize the
efficiency of the exploration. That length, however, is capped at
\(2^{\text{max\_treedepth}}\) steps to prevent trajectories from growing
without bound.

When numerical Hamiltonian trajectories are long but finite this
truncation will limit the computational efficiency. Increasing
\texttt{max\_treedepth} allow the trajectories to expand further. While
the resulting trajectories will be more expensive that added cost will
be more than made up for by increased computational efficiency.

The energy fraction of missing information, or E-FMI, quantifies how
well the Hamiltonian dynamics are able to explore the target
distribution. If the E-FMI is too small then even the exact Hamiltonian
trajectories will be limited to confined regions of the ambient space
and full exploration will be possible only with the momenta resampling
between trajectories. In this case the Markov chain exploration devolves
into less efficient, diffusive behavior where Markov chain Monte Carlo
estimation is fragile at best.

This confinement is caused by certain geometries in the target
distribution, most commonly a funnel geometry where some subset of
parameters shrink together as another parameter ranges across its
typical values. The only way to avoid these problems is to identify the
problematic geometry and then find a reparameterization of the ambient
space that transforms the geometry into something more pleasant.

Finally the average proxy accept statistic is a summary for Stan's step
size adaptation. During warmup the integrator step size is dynamically
tuned until this statistic achieves the target value which defaults to
\(0.801\). Because this adaptation is stochastic the realized average
during the main sampling phase can often vary between \(0.75\) and
\(0.85\).

So long as the target distribution is sufficiently well-behaved then the
adaptation should always converge to that target, at least for long
enough warmup periods. Small averages indicate some obstruction to the
adaptation, for example discontinuities in the target distribution or
inaccurate gradient evaluations.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check all Hamiltonian Monte Carlo Diagnostics }
\CommentTok{\# for an ensemble of Markov chains}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\CommentTok{\# @param adapt\_target Target acceptance proxy statistic for step size }
\CommentTok{\#                     adaptation.}
\CommentTok{\# @param max\_treedepth The maximum numerical trajectory treedepth}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_all\_hmc\_diagnostics }\OperatorTok{\textless{}{-}}\NormalTok{ function(diagnostics,}
\NormalTok{                                      adapt\_target}\OperatorTok{=}\FloatTok{0.801}\NormalTok{,}
\NormalTok{                                      max\_treedepth}\OperatorTok{=}\DecValTok{10}\NormalTok{,}
\NormalTok{                                      max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_divergence\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_treedepth\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_efmi\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_accept\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
  
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}
  
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(diagnostics[[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{]])[}\DecValTok{1}\NormalTok{]}
\NormalTok{  S }\OperatorTok{\textless{}{-}}\NormalTok{ dim(diagnostics[[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{]])[}\DecValTok{2}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    local\_message }\OperatorTok{\textless{}{-}} \StringTok{""}
    \CommentTok{\# Check for divergences}
\NormalTok{    n\_div }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(diagnostics[[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{]][c,])}
    
    \ControlFlowTok{if}\NormalTok{ (n\_div }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      no\_divergence\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}} 
\NormalTok{        paste0(local\_message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: }\SpecialCharTok{\%s}\StringTok{ of }\SpecialCharTok{\%s}\StringTok{ transitions (}\SpecialCharTok{\%.1f\%\%}\StringTok{) \textquotesingle{}}\NormalTok{, }
\NormalTok{                       c, n\_div, S, }\DecValTok{100} \OperatorTok{*}\NormalTok{ n\_div }\OperatorTok{/}\NormalTok{ S),}
               \StringTok{\textquotesingle{}diverged.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    \}}
    
    \CommentTok{\# Check for tree depth saturation}
\NormalTok{    n\_tds }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(sapply(diagnostics[[}\StringTok{\textquotesingle{}treedepth\_\_\textquotesingle{}}\NormalTok{]][c,], }
\NormalTok{                        function(s) s }\OperatorTok{\textgreater{}=}\NormalTok{ max\_treedepth))}
    
    \ControlFlowTok{if}\NormalTok{ (n\_tds }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      no\_treedepth\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}} 
\NormalTok{        paste0(local\_message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: }\SpecialCharTok{\%s}\StringTok{ of }\SpecialCharTok{\%s}\StringTok{ transitions (}\SpecialCharTok{\%s\%\%}\StringTok{) \textquotesingle{}}\NormalTok{, }
\NormalTok{                       c, n\_tds, S, }\DecValTok{100} \OperatorTok{*}\NormalTok{ n\_tds }\OperatorTok{/}\NormalTok{ S),}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}saturated the maximum treedepth of }\SpecialCharTok{\%s}\StringTok{.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, }
\NormalTok{                       max\_treedepth))}
\NormalTok{    \}}
    
    \CommentTok{\# Check the energy fraction of missing information (E{-}FMI)}
\NormalTok{    energies }\OperatorTok{=}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}energy\_\_\textquotesingle{}}\NormalTok{]][c,]}
\NormalTok{    numer }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(diff(energies)}\OperatorTok{**}\DecValTok{2}\NormalTok{) }\OperatorTok{/}\NormalTok{ length(energies)}
\NormalTok{    denom }\OperatorTok{=}\NormalTok{ var(energies)}
\NormalTok{    efmi }\OperatorTok{\textless{}{-}}\NormalTok{ numer }\OperatorTok{/}\NormalTok{ denom}
    \ControlFlowTok{if}\NormalTok{ (efmi }\OperatorTok{\textless{}} \FloatTok{0.2}\NormalTok{) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      no\_efmi\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}} 
\NormalTok{        paste0(local\_message, }
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: E{-}FMI = }\SpecialCharTok{\%.3f}\StringTok{.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c, efmi))}
\NormalTok{    \}}
    
    \CommentTok{\# Check convergence of the stepsize adaptation}
\NormalTok{    ave\_accept\_proxy }\OperatorTok{\textless{}{-}}\NormalTok{ mean(diagnostics[[}\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{]][c,])}
    \ControlFlowTok{if}\NormalTok{ (ave\_accept\_proxy }\OperatorTok{\textless{}} \FloatTok{0.9} \OperatorTok{*}\NormalTok{ adapt\_target) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      no\_accept\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}} 
\NormalTok{        paste0(local\_message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Averge proxy acceptance \textquotesingle{}}\NormalTok{, c),}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}statistic (}\SpecialCharTok{\%.3f}\StringTok{) is}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, ave\_accept\_proxy),}
                       \StringTok{\textquotesingle{}           smaller than 90}\SpecialCharTok{\% o}\StringTok{f the target \textquotesingle{}}\NormalTok{,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}(}\SpecialCharTok{\%.3f}\StringTok{).}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, adapt\_target))}
\NormalTok{    \}}
    
    \ControlFlowTok{if}\NormalTok{ (local\_message }\OperatorTok{!=} \StringTok{""}\NormalTok{) \{}
\NormalTok{      message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, local\_message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{ (no\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}All Hamiltonian Monte Carlo diagnostics are \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}consistent with reliable Markov chain Monte Carlo.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_divergence\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Divergent Hamiltonian transitions result from \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}unstable numerical trajectories.  These \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}instabilities are often due to degenerate target \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}geometry, especially "pinches".  If there are \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}only a small number of divergences then running \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}with adept\_delta larger \textquotesingle{}}\NormalTok{,}
\NormalTok{                   sprintf(}\StringTok{\textquotesingle{}than }\SpecialCharTok{\%.3f}\StringTok{ may reduce the \textquotesingle{}}\NormalTok{, adapt\_target),}
                   \StringTok{\textquotesingle{}instabilities at the cost of more expensive \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}Hamiltonian transitions.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_treedepth\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Numerical trajectories that saturate the \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}maximum treedepth have terminated prematurely.  \textquotesingle{}}\NormalTok{,}
\NormalTok{                   sprintf(}\StringTok{\textquotesingle{}Increasing max\_depth above }\SpecialCharTok{\%s}\StringTok{ \textquotesingle{}}\NormalTok{, max\_treedepth),}
                   \StringTok{\textquotesingle{}should result in more expensive, but more \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}efficient, Hamiltonian transitions.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_efmi\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}E{-}FMI below 0.2 arise when a funnel{-}like geometry \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}obstructs how effectively Hamiltonian trajectories \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}can explore the target distribution.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_accept\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}A small average proxy acceptance statistic \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}indicates that the adaptation of the numerical \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}integrator step size failed to converge.  This is \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}often due to discontinuous or imprecise \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}gradients.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{integrator-inverse-metric-elements}{%
\subsection{Integrator Inverse Metric
Elements}\label{integrator-inverse-metric-elements}}

Diagnostic failures indicate the presence of problems but only hint at
the nature of those problems. In order to resolve the underlying
problems we need to investigate them beyond these hints. Fortunately
Hamiltonian Monte Carlo provides a wealth of additional information that
can assist.

First we can look at the inverse metric adaptation in each of the Markov
chains. Inconsistencies in the adapted inverse metric elements across
the Markov chains are due to the individual chains encountering
different behaviors during warmup.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot outcome of inverse metric adaptation}
\CommentTok{\# @params stan\_fit A StanFit object}
\CommentTok{\# @params B The number of bins for the inverse metric element histograms.}
\NormalTok{plot\_inv\_metric }\OperatorTok{\textless{}{-}}\NormalTok{ function(stan\_fit, B}\OperatorTok{=}\DecValTok{25}\NormalTok{) \{}
\NormalTok{  adaptation\_info }\OperatorTok{\textless{}{-}}\NormalTok{ rstan:::get\_adaptation\_info(stan\_fit)}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ length(adaptation\_info)}

\NormalTok{  inv\_metric\_elems }\OperatorTok{\textless{}{-}} \BuiltInTok{list}\NormalTok{()}
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    raw\_info }\OperatorTok{\textless{}{-}}\NormalTok{ adaptation\_info[[c]]}
\NormalTok{    clean1 }\OperatorTok{\textless{}{-}}\NormalTok{ sub(}\StringTok{"\# Adaptation terminated}\CharTok{\textbackslash{}n}\StringTok{\# Step size = [0{-}9.]*}\CharTok{\textbackslash{}n}\StringTok{\#"}\NormalTok{,}
                  \StringTok{""}\NormalTok{, raw\_info)}
\NormalTok{    clean2 }\OperatorTok{\textless{}{-}}\NormalTok{ sub(}\StringTok{" [a{-}zA{-}Z ]*:}\CharTok{\textbackslash{}n}\StringTok{\# "}\NormalTok{, }\StringTok{""}\NormalTok{, clean1)}
\NormalTok{    clean3 }\OperatorTok{\textless{}{-}}\NormalTok{ sub(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{$"}\NormalTok{, }\StringTok{""}\NormalTok{, clean2)}
\NormalTok{    inv\_metric\_elems[[c]] }\OperatorTok{\textless{}{-}} \ImportTok{as}\NormalTok{.numeric(strsplit(clean3, }\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{)[[}\DecValTok{1}\NormalTok{]])}
\NormalTok{  \}}

\NormalTok{  min\_elem }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(unlist(inv\_metric\_elems))}
\NormalTok{  max\_elem }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(unlist(inv\_metric\_elems))}

\NormalTok{  delta }\OperatorTok{\textless{}{-}}\NormalTok{ (max\_elem }\OperatorTok{{-}}\NormalTok{ min\_elem) }\OperatorTok{/}\NormalTok{ B}
\NormalTok{  min\_elem }\OperatorTok{\textless{}{-}}\NormalTok{ min\_elem }\OperatorTok{{-}}\NormalTok{ delta}
\NormalTok{  max\_elem }\OperatorTok{\textless{}{-}}\NormalTok{ max\_elem }\OperatorTok{+}\NormalTok{ delta}
\NormalTok{  bins }\OperatorTok{\textless{}{-}}\NormalTok{ seq(min\_elem, max\_elem, delta)}
\NormalTok{  B }\OperatorTok{\textless{}{-}}\NormalTok{ B }\OperatorTok{+} \DecValTok{2}  

\NormalTok{  max\_y }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C, function(c)}
    \BuiltInTok{max}\NormalTok{(hist(inv\_metric\_elems[[c]], breaks}\OperatorTok{=}\NormalTok{bins, plot}\OperatorTok{=}\NormalTok{FALSE)$counts)))}

\NormalTok{  idx }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{1}\NormalTok{:B, each}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  x }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(}\DecValTok{1}\NormalTok{:length(idx), function(b) }\ControlFlowTok{if}\NormalTok{(b }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{) bins[idx[b]]}
                                         \ControlFlowTok{else}\NormalTok{ bins[idx[b] }\OperatorTok{+} \DecValTok{1}\NormalTok{])}

\NormalTok{  par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(c\_dark, c\_mid\_highlight, c\_mid, c\_light\_highlight)}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    counts }\OperatorTok{\textless{}{-}}\NormalTok{ hist(inv\_metric\_elems[[c]], breaks}\OperatorTok{=}\NormalTok{bins, plot}\OperatorTok{=}\NormalTok{FALSE)$counts}
\NormalTok{    y }\OperatorTok{\textless{}{-}}\NormalTok{ counts[idx]}

\NormalTok{    plot(x, y, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"l"}\NormalTok{, main}\OperatorTok{=}\NormalTok{paste(}\StringTok{"Chain"}\NormalTok{, c), col}\OperatorTok{=}\NormalTok{colors[c],}
\NormalTok{         xlim}\OperatorTok{=}\NormalTok{c(min\_elem, max\_elem), xlab}\OperatorTok{=}\StringTok{"Inverse Metric Elements"}\NormalTok{,}
\NormalTok{         ylim}\OperatorTok{=}\NormalTok{c(}\DecValTok{0}\NormalTok{, }\FloatTok{1.05} \OperatorTok{*}\NormalTok{ max\_y), ylab}\OperatorTok{=}\StringTok{""}\NormalTok{, yaxt}\OperatorTok{=}\StringTok{"n"}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note that the adaptation information may be accessed differently in
other Stan interfaces, in which case this function would have to be
modified accordingly.

\hypertarget{integrator-step-sizes}{%
\subsection{Integrator Step Sizes}\label{integrator-step-sizes}}

The other product of Stan's adaptation is the step size of the numerical
integrator used to build the numerical Hamiltonian trajectories. As with
the inverse metric elements heterogeneity in the adapted values across
the Markov chains indicates that the Markov chains encountered
substantially different behavior during warmup.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display adapted symplectic integrator step sizes}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\NormalTok{display\_stepsizes }\OperatorTok{\textless{}{-}}\NormalTok{ function(diagnostics) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  stepsizes }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{]]}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(stepsizes)[}\DecValTok{1}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    stepsize }\OperatorTok{\textless{}{-}}\NormalTok{ stepsizes[c, }\DecValTok{1}\NormalTok{]}
\NormalTok{    cat(sprintf(}\StringTok{\textquotesingle{}Chain }\SpecialCharTok{\%s}\StringTok{: Integrator Step Size = }\SpecialCharTok{\%f}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                c, stepsize))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{numerical-trajectory-lengths}{%
\subsection{Numerical Trajectory
Lengths}\label{numerical-trajectory-lengths}}

We can see the consequence of the adapted step sizes by looking at the
numerical trajectories generated for each Hamiltonian Markov transition.
The longer these trajectories the more degenerate the target
distribution, and the more expensive it is to explore.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display symplectic integrator trajectory lengths}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\NormalTok{plot\_num\_leapfrogs }\OperatorTok{\textless{}{-}}\NormalTok{ function(diagnostics) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  lengths }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{]]}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(lengths)[}\DecValTok{1}\NormalTok{]}

\NormalTok{  max\_length }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(lengths) }\OperatorTok{+} \DecValTok{1}
\NormalTok{  max\_count }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C, function(c) }\BuiltInTok{max}\NormalTok{(table(lengths[c,]))))}

\NormalTok{  colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(c\_dark, c\_mid\_highlight, c\_mid, c\_light\_highlight)}

\NormalTok{  idx }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{1}\NormalTok{:max\_length, each}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  xs }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(}\DecValTok{1}\NormalTok{:length(idx), function(b) }\ControlFlowTok{if}\NormalTok{(b }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{) idx[b] }\OperatorTok{+} \FloatTok{0.5}
                                          \ControlFlowTok{else}\NormalTok{ idx[b] }\OperatorTok{{-}} \FloatTok{0.5}\NormalTok{)}

\NormalTok{  plot(}\DecValTok{0}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"n"}\NormalTok{,}
\NormalTok{       xlab}\OperatorTok{=}\StringTok{"Numerical Trajectory Length"}\NormalTok{, }
\NormalTok{       xlim}\OperatorTok{=}\NormalTok{c(}\FloatTok{0.5}\NormalTok{, max\_length }\OperatorTok{+} \FloatTok{0.5}\NormalTok{),}
\NormalTok{       ylab}\OperatorTok{=}\StringTok{""}\NormalTok{, ylim}\OperatorTok{=}\NormalTok{c(}\DecValTok{0}\NormalTok{, }\FloatTok{1.1} \OperatorTok{*}\NormalTok{ max\_count), yaxt}\OperatorTok{=}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    counts }\OperatorTok{\textless{}{-}}\NormalTok{ hist(lengths[c,], }
\NormalTok{                   seq(}\FloatTok{0.5}\NormalTok{, max\_length }\OperatorTok{+} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{), }
\NormalTok{                   plot}\OperatorTok{=}\NormalTok{FALSE)$counts}
\NormalTok{    pad\_counts }\OperatorTok{\textless{}{-}}\NormalTok{ counts[idx]}
\NormalTok{    lines(xs, pad\_counts, lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{, col}\OperatorTok{=}\NormalTok{colors[c])}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display symplectic integrator trajectory lengths by Markov chain}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\NormalTok{plot\_num\_leapfrogs\_by\_chain }\OperatorTok{\textless{}{-}}\NormalTok{ function(diagnostics) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  lengths }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{]]}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(lengths)[}\DecValTok{1}\NormalTok{]}

\NormalTok{  max\_length }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(lengths) }\OperatorTok{+} \DecValTok{1}
\NormalTok{  max\_count }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C, function(c) }\BuiltInTok{max}\NormalTok{(table(lengths[c,]))))}

\NormalTok{  colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(c\_dark, c\_mid\_highlight, c\_mid, c\_light\_highlight)}

\NormalTok{  idx }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{1}\NormalTok{:max\_length, each}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  xs }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(}\DecValTok{1}\NormalTok{:length(idx), function(b) }\ControlFlowTok{if}\NormalTok{(b }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{) idx[b] }\OperatorTok{+} \FloatTok{0.5}
                                          \ControlFlowTok{else}\NormalTok{ idx[b] }\OperatorTok{{-}} \FloatTok{0.5}\NormalTok{)}

\NormalTok{  par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    stepsize }\OperatorTok{\textless{}{-}} \BuiltInTok{round}\NormalTok{(diagnostics[[}\StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{]][c,}\DecValTok{1}\NormalTok{], }\DecValTok{3}\NormalTok{)}
  
\NormalTok{    counts }\OperatorTok{\textless{}{-}}\NormalTok{ hist(lengths[c,], }
\NormalTok{                   seq(}\FloatTok{0.5}\NormalTok{, max\_length }\OperatorTok{+} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{), }
\NormalTok{                   plot}\OperatorTok{=}\NormalTok{FALSE)$counts}
\NormalTok{    pad\_counts }\OperatorTok{\textless{}{-}}\NormalTok{ counts[idx]}
  
\NormalTok{    plot(xs, pad\_counts, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"l"}\NormalTok{,  lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{, col}\OperatorTok{=}\NormalTok{colors[c],}
\NormalTok{         main}\OperatorTok{=}\NormalTok{paste0(}\StringTok{"Chain "}\NormalTok{, c, }\StringTok{" (Stepsize = "}\NormalTok{, stepsize, }\StringTok{")"}\NormalTok{),}
\NormalTok{         xlab}\OperatorTok{=}\StringTok{"Numerical Trajectory Length"}\NormalTok{, xlim}\OperatorTok{=}\NormalTok{c(}\FloatTok{0.5}\NormalTok{, max\_length }\OperatorTok{+} \FloatTok{0.5}\NormalTok{),}
\NormalTok{         ylab}\OperatorTok{=}\StringTok{""}\NormalTok{, ylim}\OperatorTok{=}\NormalTok{c(}\DecValTok{0}\NormalTok{, }\FloatTok{1.1} \OperatorTok{*}\NormalTok{ max\_count), yaxt}\OperatorTok{=}\StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{average-proxy-acceptance-statistic}{%
\subsection{Average Proxy Acceptance
Statistic}\label{average-proxy-acceptance-statistic}}

When the different adaptation outcomes are due to problematic behaviors
encountered during warmup then it the average proxy acceptance
statistics should also vary across the Markov chains.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display empirical average of the proxy acceptance statistic across }
\CommentTok{\# each Markov chain}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\NormalTok{display\_ave\_accept\_proxy }\OperatorTok{\textless{}{-}}\NormalTok{ function(diagnostics) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  proxy\_stats }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{]]}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(proxy\_stats)[}\DecValTok{1}\NormalTok{]}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    ave\_accept\_proxy }\OperatorTok{\textless{}{-}}\NormalTok{ mean(proxy\_stats[c,])}
\NormalTok{    cat(sprintf(}\StringTok{\textquotesingle{}Chain }\SpecialCharTok{\%s}\StringTok{: Average proxy acceptance statistic = }\SpecialCharTok{\%.3f}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                c, ave\_accept\_proxy))}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{divergence-labeled-pairs-plot}{%
\subsection{Divergence-Labeled Pairs
Plot}\label{divergence-labeled-pairs-plot}}

One of the most powerful features of divergent transitions is that they
not only indicate problematic geometry but also provide some spatial
information on the source of that problematic geometry. In particular
the states generated from unstable numerical Hamiltonian trajectories
will tend to be closer to the problematic geometry than those from
stable trajectories.

Consequently if we plot the states from divergent and non-divergent
transitions separately then we should see the divergent states
concentrate towards the problematic behavior. The high-dimensional
states themselves can be visualized with pairs plots.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Apply transformation identity, log, or logit transformation to}
\CommentTok{\# named samples and flatten the output.  Transformation defaults to }
\CommentTok{\# identity if name is not included in \textasciigrave{}transforms\textasciigrave{} dictionary.  A }
\CommentTok{\# ValueError is thrown if samples are not properly constrained.}
\CommentTok{\# @param name Expectand name.}
\CommentTok{\# @param samples A named list of two{-}dimensional arrays for }
\CommentTok{\#                each expectand.  The first dimension of each element }
\CommentTok{\#                indexes the Markov chains and the second dimension }
\CommentTok{\#                indexes the sequential states within each Markov chain.}
\CommentTok{\# @param transforms A named list of transformation flags for each }
\CommentTok{\#                   expectand.}
\CommentTok{\# @return The transformed expectand name and a one{-}dimensional array of}
\CommentTok{\#         flattened transformation outputs.}
\NormalTok{apply\_transform }\OperatorTok{\textless{}{-}}\NormalTok{ function(name, samples, transforms) \{}
\NormalTok{  t }\OperatorTok{\textless{}{-}}\NormalTok{ transforms[[name]]}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(t)) t }\OperatorTok{\textless{}{-}} \DecValTok{0}
  
\NormalTok{  transformed\_name }\OperatorTok{\textless{}{-}} \StringTok{""}
\NormalTok{  transformed\_samples }\OperatorTok{\textless{}{-}} \DecValTok{0}
 
  \ControlFlowTok{if}\NormalTok{ (t }\OperatorTok{==} \DecValTok{0}\NormalTok{) \{}
\NormalTok{    transformed\_name }\OperatorTok{\textless{}{-}}\NormalTok{ name}
\NormalTok{    transformed\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ c(t(samples[[name]]), recursive}\OperatorTok{=}\NormalTok{TRUE)}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (t }\OperatorTok{==} \DecValTok{1}\NormalTok{) \{}
    \ControlFlowTok{if}\NormalTok{ (}\BuiltInTok{min}\NormalTok{(samples[[name]]) }\OperatorTok{\textless{}=} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      stop(paste0(}\StringTok{\textquotesingle{}Log transform requested for expectand \textquotesingle{}}\NormalTok{,}
\NormalTok{                  sprintf(}\StringTok{\textquotesingle{}}\SpecialCharTok{\%s}\StringTok{ \textquotesingle{}}\NormalTok{, name),}
                  \StringTok{\textquotesingle{}but expectand values are not strictly positive.\textquotesingle{}}\NormalTok{))}
\NormalTok{    \}}
\NormalTok{    transformed\_name }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}log(\textquotesingle{}}\NormalTok{, name, }\StringTok{\textquotesingle{})\textquotesingle{}}\NormalTok{)}
\NormalTok{    transformed\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ log(c(t(samples[[name]]), recursive}\OperatorTok{=}\NormalTok{TRUE))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (t }\OperatorTok{==} \DecValTok{2}\NormalTok{) \{}
    \ControlFlowTok{if}\NormalTok{ (}\BuiltInTok{min}\NormalTok{(samples[[name]]) }\OperatorTok{\textless{}=} \DecValTok{0} \OperatorTok{|} \BuiltInTok{max}\NormalTok{(samples[[name]] }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{)) \{}
\NormalTok{      stop(paste0(}\StringTok{\textquotesingle{}Logit transform requested for expectand \textquotesingle{}}\NormalTok{,}
\NormalTok{                  sprintf(}\StringTok{\textquotesingle{}}\SpecialCharTok{\%s}\StringTok{ \textquotesingle{}}\NormalTok{ , name),}
                  \StringTok{\textquotesingle{}but expectand values are not strictly confined \textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}to the unit interval.\textquotesingle{}}\NormalTok{))}
\NormalTok{    \}}
\NormalTok{    transformed\_name }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}logit(\textquotesingle{}}\NormalTok{, name, }\StringTok{\textquotesingle{})\textquotesingle{}}\NormalTok{)}
\NormalTok{    transformed\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(c(t(samples[[name]]), recursive}\OperatorTok{=}\NormalTok{TRUE), }
\NormalTok{                                  function(x) log(x }\OperatorTok{/} \DecValTok{1} \OperatorTok{{-}}\NormalTok{ x))}
\NormalTok{  \}}
  \ControlFlowTok{return}\NormalTok{ (}\BuiltInTok{list}\NormalTok{(}\StringTok{\textquotesingle{}t\_name\textquotesingle{}} \OperatorTok{=}\NormalTok{ transformed\_name, }
               \StringTok{\textquotesingle{}t\_samples\textquotesingle{}} \OperatorTok{=}\NormalTok{ transformed\_samples))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot pairwise scatter plots with non{-}divergent and divergent }
\CommentTok{\# transitions separated by color}
\CommentTok{\# @param x\_names A list of expectand names to be plotted on the x axis.}
\CommentTok{\# @param y\_names A list of expectand names to be plotted on the y axis.}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for }
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the }
\CommentTok{\#                          second dimension indexes the sequential }
\CommentTok{\#                          states within each Markov chain.}
\CommentTok{\# @param diagnostics A named list of two{-}dimensional arrays for }
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the }
\CommentTok{\#                    second dimension indexes the sequential }
\CommentTok{\#                    states within each Markov chain.}
\CommentTok{\# @params transforms A named list of flags configurating which if any}
\CommentTok{\#                    transformation to apply to each named expectand:}
\CommentTok{\#                      0: identity}
\CommentTok{\#                      1: log}
\CommentTok{\#                      2: logit}
\CommentTok{\# @param xlim       Optional global x{-}axis bounds for all pair plots.}
\CommentTok{\#                   Defaults to dynamic bounds for each pair plot.}
\CommentTok{\# @param ylim       Optional global y{-}axis bounds for all pair plots.}
\CommentTok{\#                   Defaults to dynamic bounds for each pair plot.}
\CommentTok{\# @params plot\_mode Plotting style configuration: }
\CommentTok{\#                     0: Non{-}divergent transitions are plotted in }
\CommentTok{\#                        transparent red while divergent transitions are}
\CommentTok{\#                        plotted in transparent green.}
\CommentTok{\#                     1: Non{-}divergent transitions are plotted in gray }
\CommentTok{\#                        while divergent transitions are plotted in }
\CommentTok{\#                        different shades of teal depending on the }
\CommentTok{\#                        trajectory length.  Transitions from shorter}
\CommentTok{\#                        trajectories should cluster somewhat closer to }
\CommentTok{\#                        the neighborhoods with problematic geometries.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{plot\_div\_pairs }\OperatorTok{\textless{}{-}}\NormalTok{ function(x\_names, y\_names, }
\NormalTok{                           expectand\_samples, diagnostics, }
\NormalTok{                           transforms}\OperatorTok{=}\BuiltInTok{list}\NormalTok{(), xlim}\OperatorTok{=}\NormalTok{NULL, ylim}\OperatorTok{=}\NormalTok{NULL,}
\NormalTok{                           plot\_mode}\OperatorTok{=}\DecValTok{0}\NormalTok{, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(x\_names)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}x\_names\textasciigrave{} is not a list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(y\_names)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}y\_names\textasciigrave{} is not a list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(diagnostics)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}diagnostics\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(transforms)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}transforms\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \CommentTok{\# Check transform flags}
  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ names(transforms)) \{}
    \ControlFlowTok{if}\NormalTok{ (transforms[[name]] }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{|}\NormalTok{ transforms[[name]] }\OperatorTok{\textgreater{}} \DecValTok{2}\NormalTok{) \{}
\NormalTok{      warning }\OperatorTok{\textless{}{-}} 
\NormalTok{        paste0(sprintf(}\StringTok{\textquotesingle{}The transform flag }\SpecialCharTok{\%s}\StringTok{ for expectand }\SpecialCharTok{\%s}\StringTok{ \textquotesingle{}}\NormalTok{, }
\NormalTok{                       transforms[[name]], name),}
               \StringTok{\textquotesingle{}is invalid.  Plot will default to no tranformation.\textquotesingle{}}\NormalTok{)}
\NormalTok{      warning }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(warning, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{      cat(warning)}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \CommentTok{\# Check plot mode}
  \ControlFlowTok{if}\NormalTok{ (plot\_mode }\OperatorTok{\textless{}} \DecValTok{0} \OperatorTok{|}\NormalTok{ plot\_mode }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    stop(sprintf(}\StringTok{\textquotesingle{}Invalid \textasciigrave{}plot\_mode\textasciigrave{} value }\SpecialCharTok{\%s}\StringTok{.\textquotesingle{}}\NormalTok{, plot\_mode))}
\NormalTok{  \}}
  
  \CommentTok{\# Transform expectand samples}
\NormalTok{  transformed\_samples }\OperatorTok{=} \BuiltInTok{list}\NormalTok{()}
  
\NormalTok{  transformed\_x\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ x\_names) \{}
\NormalTok{    r }\OperatorTok{\textless{}{-}}\NormalTok{ apply\_transform(name, expectand\_samples, transforms)}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(r))}
\NormalTok{      stop()}
\NormalTok{    transformed\_x\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(transformed\_x\_names, r$t\_name)}
    \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{ r$t\_name }\OperatorTok{\%}\KeywordTok{in}\OperatorTok{\%}\NormalTok{ transformed\_samples) \{}
\NormalTok{      transformed\_samples[[r$t\_name]] }\OperatorTok{\textless{}{-}}\NormalTok{ r$t\_samples}
\NormalTok{    \}}
\NormalTok{  \}}
  
\NormalTok{  transformed\_y\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ y\_names) \{}
\NormalTok{    r }\OperatorTok{\textless{}{-}}\NormalTok{ apply\_transform(name, expectand\_samples, transforms)}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(r))}
\NormalTok{      stop()}
\NormalTok{    transformed\_y\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(transformed\_y\_names, r$t\_name)}
    \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{ r$t\_name }\OperatorTok{\%}\KeywordTok{in}\OperatorTok{\%}\NormalTok{ transformed\_samples) \{}
\NormalTok{      transformed\_samples[[r$t\_name]] }\OperatorTok{\textless{}{-}}\NormalTok{ r$t\_samples}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \CommentTok{\# Create pairs of transformed expectands, dropping duplicates}
\NormalTok{  pairs }\OperatorTok{\textless{}{-}} \BuiltInTok{list}\NormalTok{()}
  \ControlFlowTok{for}\NormalTok{ (x\_name }\KeywordTok{in}\NormalTok{ transformed\_x\_names) \{}
    \ControlFlowTok{for}\NormalTok{ (y\_name }\KeywordTok{in}\NormalTok{ transformed\_y\_names) \{}
      \ControlFlowTok{if}\NormalTok{ (x\_name }\OperatorTok{==}\NormalTok{ y\_name) }\BuiltInTok{next}
      \ControlFlowTok{if}\NormalTok{ (}\BuiltInTok{any}\NormalTok{(sapply(pairs, identical, c(x\_name, y\_name)))) }\BuiltInTok{next}
      \ControlFlowTok{if}\NormalTok{ (}\BuiltInTok{any}\NormalTok{(sapply(pairs, identical, c(y\_name, x\_name)))) }\BuiltInTok{next}
\NormalTok{      pairs[[length(pairs) }\OperatorTok{+} \DecValTok{1}\NormalTok{]] }\OperatorTok{\textless{}{-}}\NormalTok{ c(x\_name, y\_name)}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \CommentTok{\# Extract non{-}divergent and divergent transition indices}
\NormalTok{  divs }\OperatorTok{\textless{}{-}}\NormalTok{ diagnostics[[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{]]}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(divs)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  nondiv\_filter }\OperatorTok{\textless{}{-}}\NormalTok{ c(sapply(}\DecValTok{1}\NormalTok{:C, function(c) divs[c,] }\OperatorTok{==} \DecValTok{0}\NormalTok{))}
\NormalTok{  div\_filter    }\OperatorTok{\textless{}{-}}\NormalTok{ c(sapply(}\DecValTok{1}\NormalTok{:C, function(c) divs[c,] }\OperatorTok{==} \DecValTok{1}\NormalTok{))}
  
\NormalTok{  nlfs }\OperatorTok{\textless{}{-}}\NormalTok{ c(sapply(}\DecValTok{1}\NormalTok{:C, }
\NormalTok{                   function(c) diagnostics[[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{]][c,]))}
\NormalTok{  div\_nlfs }\OperatorTok{\textless{}{-}}\NormalTok{ nlfs[div\_filter]}
\NormalTok{  max\_nlf }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(div\_nlfs)}
\NormalTok{  nom\_colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(c\_light\_teal, c\_mid\_teal, c\_dark\_teal)}
\NormalTok{  cmap }\OperatorTok{\textless{}{-}}\NormalTok{ colormap(colormap}\OperatorTok{=}\NormalTok{nom\_colors, nshades}\OperatorTok{=}\NormalTok{max\_nlf)}
  
  \CommentTok{\# Set plot layout dynamically}
\NormalTok{  N\_cols }\OperatorTok{\textless{}{-}} \DecValTok{3}
\NormalTok{  N\_plots }\OperatorTok{\textless{}{-}}\NormalTok{ length(pairs)}
  \ControlFlowTok{if}\NormalTok{ (N\_plots }\OperatorTok{\textless{}=} \DecValTok{3}\NormalTok{) \{}
\NormalTok{    par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{1}\NormalTok{, N\_plots), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (N\_plots }\OperatorTok{==} \DecValTok{4}\NormalTok{) \{}
\NormalTok{    par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (N\_plots }\OperatorTok{==} \DecValTok{6}\NormalTok{) \{}
\NormalTok{    par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{3}\NormalTok{, N\_cols), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{  \}}
  
  \CommentTok{\# Plot!}
\NormalTok{  c\_dark\_trans }\OperatorTok{\textless{}{-}}\NormalTok{ c(}\StringTok{"\#8F272780"}\NormalTok{)}
\NormalTok{  c\_green\_trans }\OperatorTok{\textless{}{-}}\NormalTok{ c(}\StringTok{"\#00FF0080"}\NormalTok{)}
  
  \ControlFlowTok{for}\NormalTok{ (pair }\KeywordTok{in}\NormalTok{ pairs) \{}
\NormalTok{    x\_name }\OperatorTok{\textless{}{-}}\NormalTok{ pair[}\DecValTok{1}\NormalTok{]}
\NormalTok{    x\_nondiv\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ transformed\_samples[[x\_name]][nondiv\_filter]}
\NormalTok{    x\_div\_samples    }\OperatorTok{\textless{}{-}}\NormalTok{ transformed\_samples[[x\_name]][div\_filter]}
    
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(xlim)) \{}
\NormalTok{      xmin }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(transformed\_samples[[x\_name]])}
\NormalTok{      xmax }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(transformed\_samples[[x\_name]])}
\NormalTok{      local\_xlim }\OperatorTok{\textless{}{-}}\NormalTok{ c(xmin, xmax)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      local\_xlim }\OperatorTok{\textless{}{-}}\NormalTok{ xlim}
\NormalTok{    \}}
    
\NormalTok{    y\_name }\OperatorTok{\textless{}{-}}\NormalTok{ pair[}\DecValTok{2}\NormalTok{]}
\NormalTok{    y\_nondiv\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ transformed\_samples[[y\_name]][nondiv\_filter]}
\NormalTok{    y\_div\_samples    }\OperatorTok{\textless{}{-}}\NormalTok{ transformed\_samples[[y\_name]][div\_filter]}
    
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(ylim)) \{}
\NormalTok{      ymin }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(transformed\_samples[[y\_name]])}
\NormalTok{      ymax }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(transformed\_samples[[y\_name]])}
\NormalTok{      local\_ylim }\OperatorTok{\textless{}{-}}\NormalTok{ c(ymin, ymax)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      local\_ylim }\OperatorTok{\textless{}{-}}\NormalTok{ ylim}
\NormalTok{    \}}
 
    \ControlFlowTok{if}\NormalTok{ (plot\_mode }\OperatorTok{==} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      plot(x\_nondiv\_samples, y\_nondiv\_samples,}
\NormalTok{           col}\OperatorTok{=}\NormalTok{c\_dark\_trans, pch}\OperatorTok{=}\DecValTok{16}\NormalTok{, main}\OperatorTok{=}\StringTok{""}\NormalTok{,}
\NormalTok{           xlab}\OperatorTok{=}\NormalTok{x\_name, xlim}\OperatorTok{=}\NormalTok{local\_xlim, }
\NormalTok{           ylab}\OperatorTok{=}\NormalTok{y\_name, ylim}\OperatorTok{=}\NormalTok{local\_ylim)}
\NormalTok{      points(x\_div\_samples, y\_div\_samples,}
\NormalTok{             col}\OperatorTok{=}\NormalTok{c\_green\_trans, pch}\OperatorTok{=}\DecValTok{16}\NormalTok{)}
\NormalTok{    \}}
    \ControlFlowTok{if}\NormalTok{ (plot\_mode }\OperatorTok{==} \DecValTok{1}\NormalTok{) \{}
\NormalTok{      plot(x\_nondiv\_samples, y\_nondiv\_samples,}
\NormalTok{           col}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{, pch}\OperatorTok{=}\DecValTok{16}\NormalTok{, main}\OperatorTok{=}\StringTok{""}\NormalTok{,}
\NormalTok{           xlab}\OperatorTok{=}\NormalTok{x\_name, xlim}\OperatorTok{=}\NormalTok{local\_xlim, }
\NormalTok{           ylab}\OperatorTok{=}\NormalTok{y\_name, ylim}\OperatorTok{=}\NormalTok{local\_ylim)}
\NormalTok{      points(x\_div\_samples, y\_div\_samples,}
\NormalTok{             col}\OperatorTok{=}\NormalTok{cmap[div\_nlfs], pch}\OperatorTok{=}\DecValTok{16}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{expectand-diagnostic-functions}{%
\section{Expectand Diagnostic
Functions}\label{expectand-diagnostic-functions}}

The Hamiltonian Monte Carlo diagnostics exploited the particular
structure of the Hamiltonian Markov transition. For a general Markov
transition we don't have any particular structure to exploit, and hence
limited diagnostic options. In this general setting we have to
investigate the behavior of not the entire state but instead particular
expectands of interest.

\hypertarget{xihat}{%
\subsection{xihat}\label{xihat}}

A Markov chain Monte Carlo central limit theorem cannot exist for the
expectand \(f : X \rightarrow \mathbb{R}\) unless both
\(\mathbb{E}_{\pi}[f]\) and \(\mathbb{E}_{\pi}[f^{2}]\) are finite, in
which case we say that the expectand is sufficiently integrable.
Moreover the smaller the following moments the faster the central limit
theorem will kick in.

\(\hat{\xi}\) uses the tail behavior of a realized Markov chain to
estimate the integrability of an expectand. More specifically
\(\hat{\xi}\) estimates the shape of a general Pareto density function
from non-central values of the expectand.\\
If the tail behavior were exactly general Pareto then the larger the
shape parameter \(\xi\) the fewer moments of the distribution will be
well-defined. Formally the \(m\)th-order moment is well-defined only if
\[
m < \frac{1}{\xi}.
\]

For example with \(\xi = 0.9\) the expectation \(\mathbb{E}_{\pi}[f]\)
is finite but \(\mathbb{E}_{\pi}[f^{2}]\) is not. Similarly for
\(\xi = 0.4\) the expectations \(\mathbb{E}_{\pi}[f]\) and
\(\mathbb{E}_{\pi}[f^{2}]\) are finite but the third-order moment
\(\mathbb{E}_{\pi}[f^{3}]\) is not.

The estimator \(\hat{\xi}\) is constructed from the smallest and largest
values of an expectand evaluated across a realized Markov chain, where
the smallest and largest values are separated from the central values
using a heuristic. Because \(\hat{\xi}\) only estimates the tail shape I
require a conservative threshold of \(\hat{\xi} \ge 0.25\) for the
diagnostic warning to be triggered.

If the expectand output is bounded then the lower and upper tail might
consist of the same value. In this case the \(\hat{\xi}\) estimator is
poorly-behaved, but the boundedness also guarantees that moments of all
orders exist. To make this diagnostic as robust as possible
\(\hat{\xi}\) will return \(-2\) in these cases to avoid the diagnostic
threshold.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute hat\{xi\}, an estimate for the shape of a generalized Pareto }
\CommentTok{\# distribution from a sample of positive values using the method }
\CommentTok{\# introduced in "A New and Efficient Estimation Method for the }
\CommentTok{\# Generalized Pareto Distribution" by Zhang and Stephens }
\CommentTok{\# https://doi.org/10.1198/tech.2009.08017.}
\CommentTok{\# }
\CommentTok{\# Within the generalized Pareto distribution family all moments up to }
\CommentTok{\# the mth order are finite if and only if }
\CommentTok{\#  xi \textless{} 1 / m.}
\CommentTok{\#}
\CommentTok{\# @params fs A one{-}dimensional array of positive values.}
\CommentTok{\# @return Shape parameter estimate.}
\NormalTok{compute\_xi\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs)}
\NormalTok{  sorted\_fs }\OperatorTok{\textless{}{-}}\NormalTok{ sort(fs)}

  \CommentTok{\# Return erroneous result if all input values are the same }
  \ControlFlowTok{if}\NormalTok{ (sorted\_fs[}\DecValTok{1}\NormalTok{] }\OperatorTok{==}\NormalTok{ sorted\_fs[N]) \{}
    \ControlFlowTok{return}\NormalTok{ (NaN)}
\NormalTok{  \}}

  \CommentTok{\# Return erroneous result if all input values are not positive}
  \ControlFlowTok{if}\NormalTok{ (sorted\_fs[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{    cat(}\StringTok{"Input values must be positive!"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ (NaN)}
\NormalTok{  \}}

  \CommentTok{\# Estimate 25\% quantile}
\NormalTok{  q }\OperatorTok{\textless{}{-}}\NormalTok{ sorted\_fs[floor(}\FloatTok{0.25} \OperatorTok{*}\NormalTok{ N }\OperatorTok{+} \FloatTok{0.5}\NormalTok{)]}

  \ControlFlowTok{if}\NormalTok{ (q }\OperatorTok{==}\NormalTok{ sorted\_fs[}\DecValTok{1}\NormalTok{]) \{}
    \ControlFlowTok{return}\NormalTok{ (}\OperatorTok{{-}}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}

  \CommentTok{\# Heurstic generalized Pareto shape configuration}
\NormalTok{  M }\OperatorTok{\textless{}{-}} \DecValTok{20} \OperatorTok{+}\NormalTok{ floor(sqrt(N))}

\NormalTok{  b\_hat\_vec }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, M)}
\NormalTok{  log\_w\_vec }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, M)}

  \ControlFlowTok{for}\NormalTok{ (m }\KeywordTok{in} \DecValTok{1}\NormalTok{:M) \{}
\NormalTok{    b\_hat\_vec[m] }\OperatorTok{\textless{}{-}} \DecValTok{1} \OperatorTok{/}\NormalTok{ sorted\_fs[N] }\OperatorTok{+} 
\NormalTok{                 (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ sqrt(M }\OperatorTok{/}\NormalTok{ (m }\OperatorTok{{-}} \FloatTok{0.5}\NormalTok{))) }\OperatorTok{/}\NormalTok{ (}\DecValTok{3} \OperatorTok{*}\NormalTok{ q)}
    \ControlFlowTok{if}\NormalTok{ (b\_hat\_vec[m] }\OperatorTok{!=} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      xi\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ mean( log(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ b\_hat\_vec[m] }\OperatorTok{*}\NormalTok{ sorted\_fs) )}
\NormalTok{      log\_w\_vec[m] }\OperatorTok{\textless{}{-}}\NormalTok{ N }\OperatorTok{*}\NormalTok{ ( log(}\OperatorTok{{-}}\NormalTok{b\_hat\_vec[m] }\OperatorTok{/}\NormalTok{ xi\_hat) }\OperatorTok{{-}}\NormalTok{ xi\_hat }\OperatorTok{{-}} \DecValTok{1}\NormalTok{ )}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      log\_w\_vec[m] }\OperatorTok{\textless{}{-}} \DecValTok{0}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \CommentTok{\# Remove terms that don\textquotesingle{}t contribute to average to improve numerical }
  \CommentTok{\# stability}
\NormalTok{  log\_w\_vec }\OperatorTok{\textless{}{-}}\NormalTok{ log\_w\_vec[b\_hat\_vec }\OperatorTok{!=} \DecValTok{0}\NormalTok{]}
\NormalTok{  b\_hat\_vec }\OperatorTok{\textless{}{-}}\NormalTok{ b\_hat\_vec[b\_hat\_vec }\OperatorTok{!=} \DecValTok{0}\NormalTok{]}

\NormalTok{  max\_log\_w }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(log\_w\_vec)}
\NormalTok{  b\_hat }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(b\_hat\_vec }\OperatorTok{*}\NormalTok{ exp(log\_w\_vec }\OperatorTok{{-}}\NormalTok{ max\_log\_w)) }\OperatorTok{/}
           \BuiltInTok{sum}\NormalTok{(exp(log\_w\_vec }\OperatorTok{{-}}\NormalTok{ max\_log\_w))}

\NormalTok{  mean( log (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ b\_hat }\OperatorTok{*}\NormalTok{ sorted\_fs) )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical generalized Pareto shape for upper and lower tails}
\CommentTok{\# for an arbitrary sample of expectand values, ignoring any }
\CommentTok{\# autocorrelation between the values.}
\CommentTok{\# @param fs A one{-}dimensional array of expectand values.}
\CommentTok{\# @return Left and right shape estimators.}
\NormalTok{compute\_tail\_xi\_hats }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
\NormalTok{  f\_center }\OperatorTok{\textless{}{-}}\NormalTok{ median(fs)}
  
  \CommentTok{\# Isolate lower and upper tails which can be adequately modeled by a }
  \CommentTok{\# generalized Pareto shape for sufficiently well{-}behaved distributions}
\NormalTok{  fs\_left }\OperatorTok{\textless{}{-}} \BuiltInTok{abs}\NormalTok{(fs[fs }\OperatorTok{\textless{}}\NormalTok{ f\_center] }\OperatorTok{{-}}\NormalTok{ f\_center)}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs\_left)}
\NormalTok{  M }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(}\FloatTok{0.2} \OperatorTok{*}\NormalTok{ N, }\DecValTok{3} \OperatorTok{*}\NormalTok{ sqrt(N))}
\NormalTok{  fs\_left }\OperatorTok{\textless{}{-}}\NormalTok{ fs\_left[M:N]}
  
\NormalTok{  fs\_right }\OperatorTok{\textless{}{-}}\NormalTok{ fs[fs }\OperatorTok{\textgreater{}}\NormalTok{ f\_center] }\OperatorTok{{-}}\NormalTok{ f\_center}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs\_right)}
\NormalTok{  M }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(}\FloatTok{0.2} \OperatorTok{*}\NormalTok{ N, }\DecValTok{3} \OperatorTok{*}\NormalTok{ sqrt(N))}
\NormalTok{  fs\_right }\OperatorTok{\textless{}{-}}\NormalTok{ fs\_right[M:N]}
  
  \CommentTok{\# Default to NaN if left tail is ill{-}defined}
\NormalTok{  xi\_hat\_left }\OperatorTok{\textless{}{-}}\NormalTok{ NaN}
  \ControlFlowTok{if}\NormalTok{ (length(fs\_left) }\OperatorTok{\textgreater{}} \DecValTok{40}\NormalTok{)}
\NormalTok{    xi\_hat\_left }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_xi\_hat(fs\_left)}

  \CommentTok{\# Default to NaN if right tail is ill{-}defined}
\NormalTok{  xi\_hat\_right }\OperatorTok{\textless{}{-}}\NormalTok{ NaN}
  \ControlFlowTok{if}\NormalTok{ (length(fs\_right) }\OperatorTok{\textgreater{}} \DecValTok{40}\NormalTok{)}
\NormalTok{    xi\_hat\_right }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_xi\_hat(fs\_right)}

\NormalTok{  c(xi\_hat\_left, xi\_hat\_right)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check upper and lower tail behavior of a given expectand output }
\CommentTok{\# ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_tail\_xi\_hats }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}
  
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    xi\_hats }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tail\_xi\_hats(samples[c,])}
\NormalTok{    xi\_hat\_threshold }\OperatorTok{\textless{}{-}} \FloatTok{0.25}
    \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{1}\NormalTok{]) }\OperatorTok{\&} \KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{2}\NormalTok{]) ) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Both left and right \textquotesingle{}}\NormalTok{, c),}
               \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{xi\}}\StringTok{s are NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    \} }
    \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{1}\NormalTok{]) ) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Left hat}\SpecialCharTok{\{xi\}}\StringTok{ is NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{2}\NormalTok{]) ) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Right hat}\SpecialCharTok{\{xi\}}\StringTok{ is NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{      xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{              sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Both left and right tail \textquotesingle{}}\NormalTok{, c),}
\NormalTok{              sprintf(}\StringTok{\textquotesingle{}hat}\SpecialCharTok{\{xi\}}\StringTok{s (}\SpecialCharTok{\%.3f}\StringTok{, }\SpecialCharTok{\%.3f}\StringTok{) exceed }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, }
\NormalTok{                      xi\_hats[}\DecValTok{1}\NormalTok{], xi\_hats[}\DecValTok{2}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{               xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Right tail hat}\SpecialCharTok{\{xi\}}\StringTok{ \textquotesingle{}}\NormalTok{, c),}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}(}\SpecialCharTok{\%.3f}\StringTok{) exceeds }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                       xi\_hats[}\DecValTok{2}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{               xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Left tail hat}\SpecialCharTok{\{xi\}}\StringTok{ \textquotesingle{}}\NormalTok{, c),}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}(}\SpecialCharTok{\%.3f}\StringTok{) exceeds }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                       xi\_hats[}\DecValTok{1}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (no\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} \StringTok{\textquotesingle{}Expectand appears to be sufficiently integrable.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Large tail xi\_hats suggest that the expectand \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}might not be sufficiently integrable.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}
  
\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{frozen-chains}{%
\subsection{Frozen Chains}\label{frozen-chains}}

Another sign of problems is when all evaluations of an expectand are
constant. This could be due to the Markov chain being stuck at a single
state or just that the pushforward distribution of the expectand
concentrates on a single value. We can't distinguish between these
possibilities without more information, but we can signal a constant
expectand by looking at its empirical variance.

Here we'll use a Welford accumulator to compute the empirical variance
of the expectand values in a single sweep.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical mean and variance of a given sequence with a single}
\CommentTok{\# pass using Welford accumulators.}
\CommentTok{\# @params A one{-}dimensional array of expectand values.}
\CommentTok{\# @return The empirical mean and variance.}
\NormalTok{welford\_summary }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
\NormalTok{  mean }\OperatorTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  var }\OperatorTok{\textless{}{-}} \DecValTok{0}

\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs)}
  \ControlFlowTok{for}\NormalTok{ (n }\KeywordTok{in} \DecValTok{1}\NormalTok{:N) \{}
\NormalTok{    delta }\OperatorTok{\textless{}{-}}\NormalTok{ fs[n] }\OperatorTok{{-}}\NormalTok{ mean}
\NormalTok{    mean }\OperatorTok{\textless{}{-}}\NormalTok{ mean }\OperatorTok{+}\NormalTok{ delta }\OperatorTok{/}\NormalTok{ n}
\NormalTok{    var }\OperatorTok{\textless{}{-}}\NormalTok{ var }\OperatorTok{+}\NormalTok{ delta }\OperatorTok{*}\NormalTok{ (fs[n] }\OperatorTok{{-}}\NormalTok{ mean)}
\NormalTok{  \}}

\NormalTok{  var }\OperatorTok{\textless{}{-}}\NormalTok{ var}\OperatorTok{/}\NormalTok{ (N }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}

  \ControlFlowTok{return}\NormalTok{(c(mean, var))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check expectand output ensemble for vanishing empirical variance.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_variances }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    var }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(samples[c,])[}\DecValTok{2}\NormalTok{]}
    \ControlFlowTok{if}\NormalTok{ (var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{) \{}
\NormalTok{      message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message,}
\NormalTok{                        sprintf(}\StringTok{\textquotesingle{}Chain }\SpecialCharTok{\%s}\StringTok{: Expectand is constant!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (no\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} \StringTok{\textquotesingle{}Expectand is varying across all Markov chains.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}If the expectand is not expected to be nearly \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}constant then the Markov transition might be \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}misbehaving.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}
  
\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{split-rhat}{%
\subsection{Split Rhat}\label{split-rhat}}

One of the key features of Markov chain equilibrium is that the
distribution of Markov chain realizations is independent of the
initialization. In particular the expectand evaluations from any
equilibrated Markov chain should be statistically equivalent to any
other. Even more the evaluations across any subset of Markov chain
states should be equivalent.

The split \(\hat{R}\) statistic quantifies the heterogeneity in the
expectand evaluations across an ensemble of Markov chains, each of which
has been split in half. Mathematically split \(\hat{R}\) is similar to
analysis of variance in that compares the empirical variance of the
average expectand values in each chain half to the average of the
empirical variances in each chain half; the key difference is that split
\(\hat{R}\) transforms this ratio so that in equilibrium the statistic
decays towards \(1\) from above.

When split \(\hat{R}\) is much larger than \(1\) the expectand
evaluations across each Markov chain halves are not consistent with each
other. This could be because the Markov chains have not converged to the
same typical set or because they have not yet expanded into that typical
set.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Split a sequence of expectand values in half to create an initial and }
\CommentTok{\# terminal Markov chains}
\CommentTok{\# @params chain A sequence of expectand values derived from a single }
\CommentTok{\#               Markov chain.}
\CommentTok{\# @return Two subsequences of expectand values.}
\NormalTok{split\_chain }\OperatorTok{\textless{}{-}}\NormalTok{ function(chain) \{}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(chain)}
\NormalTok{  M }\OperatorTok{\textless{}{-}}\NormalTok{ N }\OperatorTok{\%/\%} \DecValTok{2}
  \BuiltInTok{list}\NormalTok{(chain1 }\OperatorTok{\textless{}{-}}\NormalTok{ chain[}\DecValTok{1}\NormalTok{:M], chain2 }\OperatorTok{\textless{}{-}}\NormalTok{ chain[(M }\OperatorTok{+} \DecValTok{1}\NormalTok{):N])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute split hat\{R\} for the expectand values across a Markov chain }
\CommentTok{\# ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @return Split Rhat estimate.}
\NormalTok{compute\_split\_rhat }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  split\_chains }\OperatorTok{\textless{}{-}}\NormalTok{ unlist(lapply(}\DecValTok{1}\NormalTok{:C, }
\NormalTok{                                function(c) split\_chain(samples[c,])),}
\NormalTok{                         recursive}\OperatorTok{=}\NormalTok{FALSE)}

\NormalTok{  N\_chains }\OperatorTok{\textless{}{-}}\NormalTok{ length(split\_chains)}
\NormalTok{  N }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C, function(c) length(samples[c,])))}

\NormalTok{  means }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, N\_chains)}
  \BuiltInTok{vars} \OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, N\_chains)}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:N\_chains) \{}
\NormalTok{    summary }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(split\_chains[[c]])}
\NormalTok{    means[c] }\OperatorTok{\textless{}{-}}\NormalTok{ summary[}\DecValTok{1}\NormalTok{]}
    \BuiltInTok{vars}\NormalTok{[c] }\OperatorTok{\textless{}{-}}\NormalTok{ summary[}\DecValTok{2}\NormalTok{]}
\NormalTok{  \}}

\NormalTok{  total\_mean }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(means) }\OperatorTok{/}\NormalTok{ N\_chains}
\NormalTok{  W }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(}\BuiltInTok{vars}\NormalTok{) }\OperatorTok{/}\NormalTok{ N\_chains}
\NormalTok{  B }\OperatorTok{=}\NormalTok{ N }\OperatorTok{*} \BuiltInTok{sum}\NormalTok{(sapply(means, function(m)}
\NormalTok{                            (m }\OperatorTok{{-}}\NormalTok{ total\_mean)}\OperatorTok{**}\DecValTok{2}\NormalTok{)) }\OperatorTok{/}\NormalTok{ (N\_chains }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}

\NormalTok{  rhat }\OperatorTok{=}\NormalTok{ NaN}
  \ControlFlowTok{if}\NormalTok{ (}\BuiltInTok{abs}\NormalTok{(W) }\OperatorTok{\textgreater{}} \FloatTok{1e{-}10}\NormalTok{)}
\NormalTok{    rhat }\OperatorTok{=}\NormalTok{ sqrt( (N }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{+}\NormalTok{ B }\OperatorTok{/}\NormalTok{ W) }\OperatorTok{/}\NormalTok{ N )}

\NormalTok{  (rhat)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute split hat\{R\} for all input expectands}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for }
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the }
\CommentTok{\#                          second dimension indexes the sequential }
\CommentTok{\#                          states within each Markov chain.}
\NormalTok{compute\_split\_rhats }\OperatorTok{\textless{}{-}}\NormalTok{ function(expectand\_samples) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{  rhats }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ names(expectand\_samples)) \{}
\NormalTok{    samples }\OperatorTok{\textless{}{-}}\NormalTok{ expectand\_samples[[name]]}
\NormalTok{    rhats }\OperatorTok{\textless{}{-}}\NormalTok{ c(rhats, compute\_split\_rhat(samples))}
\NormalTok{  \}}
  \ControlFlowTok{return}\NormalTok{(rhats)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check split hat\{R\} across a given expectand output ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_rhat }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{  rhat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_split\_rhat(samples)}

\NormalTok{  no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}

  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.nan(rhat)) \{}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, }
                      \StringTok{\textquotesingle{}All Markov chains appear to be frozen!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{) \{}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, sprintf(}\StringTok{\textquotesingle{}Split hat}\SpecialCharTok{\{R\}}\StringTok{ is }\SpecialCharTok{\%f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, rhat))}
\NormalTok{    no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (no\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} \StringTok{\textquotesingle{}Markov chain behavior is consistent with equilibrium.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Split hat}\SpecialCharTok{\{R\}}\StringTok{ larger than 1.1 suggests that at \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}least one of the Markov chains has not reached \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}an equilibrium.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}
  
\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{integrated-autocorrelation-time}{%
\subsection{Integrated Autocorrelation
Time}\label{integrated-autocorrelation-time}}

The information about the target distribution encoded within a Markov
chain, and hence the potential precision of Markov chain Monte Carlo
estimators, is limited by the autocorrelation of the internal states.
Assuming equilibrium we can estimate the stationary autocorrelations
between the outputs of a given expectand from the realized Markov chain
and then combine them into an estimate of the integrated autocorrelation
time \(\tau[f]\) which moderates the asymptotic variance of well-behaved
Markov chain Monte Carlo estimators.

In practice it's often easier to interpret the effective sample size, \[
\text{ESS}[f] = \frac{N}{\tau[f]},
\] or in practice the empirical effective sample size that we estimate
from the realized Markov chains, \[
\hat{\text{ESS}[f]} = \frac{N}{\hat{\tau}[f]}.
\] The effective sample size can be interpreted as how large of an
ensemble of exact samples we would need to achieve the same estimator
error for the particular expectand of interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical integrated autocorrelation time for a sequence}
\CommentTok{\# of expectand values, known here as \textbackslash{}hat\{tau\}.}
\CommentTok{\# @param fs A one{-}dimensional array of expectand values.}
\CommentTok{\# @return Left and right shape estimators.}
\NormalTok{compute\_tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
  \CommentTok{\# Compute empirical autocorrelations}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs)}
\NormalTok{  zs }\OperatorTok{\textless{}{-}}\NormalTok{ fs }\OperatorTok{{-}}\NormalTok{ mean(fs)}
  
  \ControlFlowTok{if}\NormalTok{ (var(fs) }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{(Inf)}

\NormalTok{  B }\OperatorTok{\textless{}{-}} \DecValTok{2}\OperatorTok{**}\NormalTok{ceiling(log2(N)) }\CommentTok{\# Next power of 2 after N}
\NormalTok{  zs\_buff }\OperatorTok{\textless{}{-}}\NormalTok{ c(zs, rep(}\DecValTok{0}\NormalTok{, B }\OperatorTok{{-}}\NormalTok{ N))}

\NormalTok{  Fs }\OperatorTok{\textless{}{-}}\NormalTok{ fft(zs\_buff)}
\NormalTok{  Ss }\OperatorTok{\textless{}{-}}\NormalTok{ Fs }\OperatorTok{*}\NormalTok{ Conj(Fs)}
\NormalTok{  Rs }\OperatorTok{\textless{}{-}}\NormalTok{ fft(Ss, inverse}\OperatorTok{=}\NormalTok{TRUE)}

\NormalTok{  acov\_buff }\OperatorTok{\textless{}{-}}\NormalTok{ Re(Rs)}
\NormalTok{  rhos }\OperatorTok{\textless{}{-}}\NormalTok{ head(acov\_buff, N) }\OperatorTok{/}\NormalTok{ acov\_buff[}\DecValTok{1}\NormalTok{]}

  \CommentTok{\# Drop last lag if (L + 1) is odd so that the lag pairs are complete}
\NormalTok{  L }\OperatorTok{\textless{}{-}}\NormalTok{ N}
  \ControlFlowTok{if}\NormalTok{ ((L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{)}
\NormalTok{    L }\OperatorTok{\textless{}{-}}\NormalTok{ L }\OperatorTok{{-}} \DecValTok{1}

  \CommentTok{\# Number of lag pairs}
\NormalTok{  P }\OperatorTok{\textless{}{-}}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{/} \DecValTok{2}

  \CommentTok{\# Construct asymptotic correlation from initial monotone sequence}
\NormalTok{  old\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ rhos[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2}\NormalTok{]}
  \ControlFlowTok{for}\NormalTok{ (p }\KeywordTok{in} \DecValTok{2}\NormalTok{:P) \{}
\NormalTok{    current\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p]}
  
    \ControlFlowTok{if}\NormalTok{ (current\_pair\_sum }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      rho\_sum }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(rhos[}\DecValTok{2}\NormalTok{:(}\DecValTok{2} \OperatorTok{*}\NormalTok{ p)])}
    
      \ControlFlowTok{if}\NormalTok{ (rho\_sum }\OperatorTok{\textless{}=} \OperatorTok{{-}}\FloatTok{0.25}\NormalTok{)}
\NormalTok{        rho\_sum }\OperatorTok{\textless{}{-}} \OperatorTok{{-}}\FloatTok{0.25}
    
\NormalTok{      asymp\_corr }\OperatorTok{\textless{}{-}} \FloatTok{1.0} \OperatorTok{+} \DecValTok{2} \OperatorTok{*}\NormalTok{ rho\_sum}
      \ControlFlowTok{return}\NormalTok{ (asymp\_corr)}
\NormalTok{    \}}
  
    \ControlFlowTok{if}\NormalTok{ (current\_pair\_sum }\OperatorTok{\textgreater{}}\NormalTok{ old\_pair\_sum) \{}
\NormalTok{      current\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}{-}} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p] }\OperatorTok{\textless{}{-}} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{    \}}
  
    \ControlFlowTok{if}\NormalTok{ (p }\OperatorTok{==}\NormalTok{ P) \{}
      \ControlFlowTok{return}\NormalTok{ (NaN)}
\NormalTok{    \}}
  
\NormalTok{    old\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ current\_pair\_sum}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute the minimum empirical effective sample size across the }
\CommentTok{\# Markov chains for the given expectands}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for }
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the }
\CommentTok{\#                          second dimension indexes the sequential }
\CommentTok{\#                          states within each Markov chain.}
\NormalTok{compute\_min\_eesss }\OperatorTok{\textless{}{-}}\NormalTok{ function(expectand\_samples) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{  min\_eesss }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ names(expectand\_samples)) \{}
\NormalTok{    samples }\OperatorTok{\textless{}{-}}\NormalTok{ expectand\_samples[[name]]}
\NormalTok{    C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
\NormalTok{    S }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{2}\NormalTok{]}
    
\NormalTok{    eesss }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, C)}
    \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{      tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tau\_hat(samples[c,])}
\NormalTok{      eesss[c] }\OperatorTok{\textless{}{-}}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
\NormalTok{    \}}
\NormalTok{    min\_eesss }\OperatorTok{\textless{}{-}}\NormalTok{ c(min\_eesss, }\BuiltInTok{min}\NormalTok{(eesss))}
\NormalTok{  \}}
  \ControlFlowTok{return}\NormalTok{(min\_eesss)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Assuming stationarity we can use the empirical effective sample size to
estimate the Markov chain Monte Carlo standard error for any
well-behaved expectand estimator \[
\hat{f} \approx \mathbb{E}_{\pi}[f].
\] The necessary effective sample size depends on the precision required
for a given Markov chain Monte Carlo estimator. This can vary not only
from analysis to analysis but also between multiple expectands within a
single analysis. That said an effective sample size of \(100\) is
sufficient for most applications and provides a useful rule of thumb.

When Markov chains have not equilibrated the empirical effective sample
size will have no relation to the error of Markov chain Monte Carlo
estimators. To avoid any confusion we should interpret an empirical
effective sample size simply as a quantification of the autocorrelations
of a particular expectand within a realized Markov chain. In particular
an empirical effective sample size below \(100\) indicates strong
autocorrelation that will complicate Markov chain Monte Carlo estimation
in the worst case and reduce estimator precision in the best case.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check the empirical effective sample size (EESS) for all a given }
\CommentTok{\# expectand output ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @param min\_eess\_per\_chain The minimum empirical effective sample size}
\CommentTok{\#                           before a warning message is passed.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_eess }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples,}
\NormalTok{                       min\_eess\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                       max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{2}\NormalTok{]}
  
\NormalTok{  no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}
  
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tau\_hat(samples[c,])}
\NormalTok{    eess }\OperatorTok{\textless{}{-}}\NormalTok{ N }\OperatorTok{/}\NormalTok{ tau\_hat}
    \ControlFlowTok{if}\NormalTok{ (eess }\OperatorTok{\textless{}}\NormalTok{ min\_eess\_per\_chain) \{}
\NormalTok{      message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message,}
\NormalTok{                        sprintf(}\StringTok{\textquotesingle{}Chain }\SpecialCharTok{\%s}\StringTok{: The empirical effective \textquotesingle{}}\NormalTok{, c),}
\NormalTok{                        sprintf(}\StringTok{\textquotesingle{}sample size }\SpecialCharTok{\%f}\StringTok{ is too small!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, eess))}
\NormalTok{      no\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{    \}}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (no\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}The empirical effective sample size is large \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}enough for Markov chain Monte Carlo estimation \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}to be reliable assuming that a central limit \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}theorem holds.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Small empirical effective sample sizes indicate strong \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}empirical autocorrelations in the realized Markov chains. \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}If the empirical effective sample size is too \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}small then Markov chain Monte Carlo estimation \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}may be unreliable even when a central limit \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}theorem holds.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{2}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}
  
\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

For example empirical effective sample sizes can provide a useful way to
distinguish if some diagnostic failures are due to Markov chains that
are just too short or more persistent problems.

\hypertarget{all-expectand-diagnostics}{%
\subsection{All Expectand Diagnostics}\label{all-expectand-diagnostics}}

In practice we have no reason not to check all of these diagnostics at
once for each expectand of interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check all expectand{-}specific diagnostics.}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for }
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the }
\CommentTok{\#                          second dimension indexes the sequential }
\CommentTok{\#                          states within each Markov chain.}
\CommentTok{\# @param min\_eess\_per\_chain The minimum empirical effective sample size}
\CommentTok{\#                           before a warning message is passed.}
\CommentTok{\# @param exclude\_zvar Binary variable to exclude all expectands with}
\CommentTok{\#                     vanishing empirical variance from other diagnostic}
\CommentTok{\#                     checks.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{check\_all\_expectand\_diagnostics }\OperatorTok{\textless{}{-}}\NormalTok{ function(expectand\_samples,}
\NormalTok{                                            min\_eess\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                                            exclude\_zvar}\OperatorTok{=}\NormalTok{FALSE,}
\NormalTok{                                            max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_zvar\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_rhat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{  no\_eess\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}

\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}

  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ names(expectand\_samples)) \{}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(expectand\_samples[[name]])) \{}
\NormalTok{      cat(sprintf(}\StringTok{\textquotesingle{}The samples for expectand \textasciigrave{}}\SpecialCharTok{\%s}\StringTok{\textasciigrave{} are ill{-}formed.\textquotesingle{}}\NormalTok{, name))}
      \ControlFlowTok{continue}
\NormalTok{    \}}
    
\NormalTok{    samples }\OperatorTok{\textless{}{-}}\NormalTok{ expectand\_samples[[name]]}
\NormalTok{    C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
\NormalTok{    S }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{2}\NormalTok{]}
    
\NormalTok{    local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{    local\_message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(name, }\StringTok{\textquotesingle{}:}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
  
    \ControlFlowTok{if}\NormalTok{ (exclude\_zvar) \{}
      \CommentTok{\# Check zero variance across all Markov chains for exclusion}
\NormalTok{      any\_zvar }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
      \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{        var }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(samples[c,])[}\DecValTok{2}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ (var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{)}
\NormalTok{          any\_zvar }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{      \}}
      \ControlFlowTok{if}\NormalTok{ (any\_zvar) \{}
        \BuiltInTok{next}
\NormalTok{      \}}
\NormalTok{    \}}
  
    \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{      fs }\OperatorTok{\textless{}{-}}\NormalTok{ samples[c,]}
      
      \CommentTok{\# Check tail behavior in each Markov chain}
\NormalTok{      xi\_hat\_threshold }\OperatorTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{      xi\_hats }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tail\_xi\_hats(fs)}
      \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{1}\NormalTok{]) }\OperatorTok{\&} \KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{2}\NormalTok{]) ) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Both left and right \textquotesingle{}}\NormalTok{, c),}
                         \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{xi\}}\StringTok{s are NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{      \}}
      \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{1}\NormalTok{]) ) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Left hat}\SpecialCharTok{\{xi\}}\StringTok{ is NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{      \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{2}\NormalTok{]) ) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Right hat}\SpecialCharTok{\{xi\}}\StringTok{ is NaN!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, c))}
\NormalTok{      \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{          xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Both left and right tail \textquotesingle{}}\NormalTok{, c),}
\NormalTok{                sprintf(}\StringTok{\textquotesingle{}hat}\SpecialCharTok{\{xi\}}\StringTok{s (}\SpecialCharTok{\%.3f}\StringTok{, }\SpecialCharTok{\%.3f}\StringTok{) exceed }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, }
\NormalTok{                        xi\_hats[}\DecValTok{1}\NormalTok{], xi\_hats[}\DecValTok{2}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{      \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{                 xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Right tail hat}\SpecialCharTok{\{xi\}}\StringTok{ \textquotesingle{}}\NormalTok{, c),}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}(}\SpecialCharTok{\%.3f}\StringTok{) exceeds }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                         xi\_hats[}\DecValTok{2}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{      \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }\OperatorTok{\&} 
\NormalTok{                 xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Left tail hat}\SpecialCharTok{\{xi\}}\StringTok{ \textquotesingle{}}\NormalTok{, c),}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}(}\SpecialCharTok{\%.3f}\StringTok{) exceeds }\SpecialCharTok{\%.2f}\StringTok{!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{                         xi\_hats[}\DecValTok{1}\NormalTok{], xi\_hat\_threshold))}
\NormalTok{      \}}
      
      \CommentTok{\# Check empirical variance in each Markov chain}
\NormalTok{      var }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(fs)[}\DecValTok{2}\NormalTok{]}
      \ControlFlowTok{if}\NormalTok{ (var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{) \{}
\NormalTok{        no\_zvar\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: Expectand exhibits vanishing \textquotesingle{}}\NormalTok{, c),}
                         \StringTok{\textquotesingle{}empirical variance!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{      \}}
\NormalTok{    \}}
  
    \CommentTok{\# Check split Rhat across Markov chains}
\NormalTok{    rhat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_split\_rhat(samples)}

    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.nan(rhat)) \{}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(local\_message,}
                              \StringTok{\textquotesingle{}  Split hat}\SpecialCharTok{\{R\}}\StringTok{ is ill{-}defined!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{) \{}
\NormalTok{      no\_rhat\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{      local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{      local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{        paste0(local\_message,}
\NormalTok{               sprintf(}\StringTok{\textquotesingle{}  Split hat}\SpecialCharTok{\{R\}}\StringTok{ (}\SpecialCharTok{\%.3f}\StringTok{) exceeds 1.1!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, rhat))}
\NormalTok{    \}}

    \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
      \CommentTok{\# Check empirical effective sample size}
\NormalTok{      fs }\OperatorTok{\textless{}{-}}\NormalTok{ samples[c,]}
      
\NormalTok{      tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tau\_hat(fs)}
\NormalTok{      eess }\OperatorTok{\textless{}{-}}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
      
      \ControlFlowTok{if}\NormalTok{ (eess }\OperatorTok{\textless{}}\NormalTok{ min\_eess\_per\_chain) \{}
\NormalTok{        no\_eess\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
\NormalTok{        local\_warning }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{        local\_message }\OperatorTok{\textless{}{-}}
\NormalTok{          paste0(local\_message,}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}  Chain }\SpecialCharTok{\%s}\StringTok{: hat}\SpecialCharTok{\{ESS\}}\StringTok{ (}\SpecialCharTok{\%.3f}\StringTok{) is smaller than \textquotesingle{}}\NormalTok{,}
\NormalTok{                         c, eess),}
\NormalTok{                 sprintf(}\StringTok{\textquotesingle{}desired (}\SpecialCharTok{\%s}\StringTok{)!}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, min\_eess\_per\_chain))}
\NormalTok{      \}}
\NormalTok{    \}}
    
    \ControlFlowTok{if}\NormalTok{ (local\_warning) \{}
\NormalTok{      message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, local\_message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_xi\_hat\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Large tail hat}\SpecialCharTok{\{xi\}}\StringTok{s suggest that the expectand \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{} might not be sufficiently integrable.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_zvar\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}If the expectands are not constant then zero \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}empirical variance suggests that the Markov \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}transitions may be misbehaving.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_rhat\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Split Rhat larger than 1.1 suggests that at \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}least one of the Markov chains has not reached \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}an equilibrium.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\NormalTok{no\_eess\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}Small empirical effective sample sizes indicate strong \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}empirical autocorrelations in the realized Markov chains. \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}If the empirical effective sample size is too \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}small then Markov chain Monte Carlo estimation \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}may be unreliable even when a central limit \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}theorem holds.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, desc)}
\NormalTok{  \}}

  \ControlFlowTok{if}\NormalTok{(no\_xi\_hat\_warning }\OperatorTok{\&}\NormalTok{ no\_zvar\_warning }\OperatorTok{\&} 
\NormalTok{     no\_rhat\_warning }\OperatorTok{\&}\NormalTok{ no\_eess\_warning) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}All expectands checked appear to be behaving \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}well enough for reliable Markov chain Monte \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}Carlo estimation.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}

\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

That said for particularly problematic fits the output from checking all
of the expectands can be overwhelming. In cases where that may be a risk
we can summarize the output more compactly.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Summarize all expectand{-}specific diagnostics.}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for}
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the }
\CommentTok{\#                          second dimension indexes the sequential }
\CommentTok{\#                          states within each Markov chain.}
\CommentTok{\# @param min\_eess\_per\_chain The minimum empirical effective sample size}
\CommentTok{\#                           before a warning message is passed.}
\CommentTok{\# @param exclude\_zvar Binary variable to exclude all expectands with}
\CommentTok{\#                     vanishing empirical variance from other diagnostic}
\CommentTok{\#                     checks.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\NormalTok{summarize\_expectand\_diagnostics }\OperatorTok{\textless{}{-}}\NormalTok{ function(expectand\_samples,}
\NormalTok{                                            min\_eess\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                                            exclude\_zvar}\OperatorTok{=}\NormalTok{FALSE,}
\NormalTok{                                            max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{  failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
\NormalTok{  failed\_xi\_hat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
\NormalTok{  failed\_zvar\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
\NormalTok{  failed\_rhat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
\NormalTok{  failed\_eess\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}

  \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ names(expectand\_samples)) \{}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(expectand\_samples[[name]])) \{}
\NormalTok{      cat(sprintf(}\StringTok{\textquotesingle{}The samples for expectand \textasciigrave{}}\SpecialCharTok{\%s}\StringTok{\textasciigrave{} are ill{-}formed.\textquotesingle{}}\NormalTok{, name))}
      \ControlFlowTok{continue}
\NormalTok{    \}}
    
\NormalTok{    samples }\OperatorTok{\textless{}{-}}\NormalTok{ expectand\_samples[[name]]}
\NormalTok{    C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
\NormalTok{    S }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{2}\NormalTok{]}
    
    \ControlFlowTok{if}\NormalTok{ (exclude\_zvar) \{}
      \CommentTok{\# Check zero variance across all Markov chains for exclusion}
\NormalTok{      any\_zvar }\OperatorTok{\textless{}{-}}\NormalTok{ FALSE}
      \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{        var }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(samples[c,])[}\DecValTok{2}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ (var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{)}
\NormalTok{          any\_zvar }\OperatorTok{\textless{}{-}}\NormalTok{ TRUE}
\NormalTok{      \}}
      \ControlFlowTok{if}\NormalTok{ (any\_zvar) \{}
        \BuiltInTok{next}
\NormalTok{      \}}
\NormalTok{    \}}

    \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{      fs }\OperatorTok{\textless{}{-}}\NormalTok{ samples[c,]}
      
      \CommentTok{\# Check tail behavior in each Markov chain}
\NormalTok{      xi\_hat\_threshold }\OperatorTok{\textless{}{-}} \FloatTok{0.25}
\NormalTok{      xi\_hats }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tail\_xi\_hats(fs)}
      \ControlFlowTok{if}\NormalTok{ ( }\KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{1}\NormalTok{]) }\OperatorTok{|} \KeywordTok{is}\NormalTok{.nan(xi\_hats[}\DecValTok{2}\NormalTok{]) ) \{}
\NormalTok{        failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{        failed\_xi\_hat\_nameas }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_xi\_hat\_names, name)}
\NormalTok{      \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }\OperatorTok{|} 
\NormalTok{                 xi\_hats[}\DecValTok{2}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold) \{}
\NormalTok{        failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{        failed\_xi\_hat\_nameas }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_xi\_hat\_names, name)}
\NormalTok{      \}}
      
      \CommentTok{\# Check empirical variance in each Markov chain}
\NormalTok{      var }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(fs)[}\DecValTok{2}\NormalTok{]}
      \ControlFlowTok{if}\NormalTok{ (var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{) \{}
\NormalTok{        failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{        failed\_zvar\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_zvar\_names, name) }
\NormalTok{      \}}
\NormalTok{    \}}

    \CommentTok{\# Check split Rhat across Markov chains}
\NormalTok{    rhat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_split\_rhat(samples)}

    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.nan(rhat)) \{}
\NormalTok{      failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{      failed\_rhat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_rhat\_names, name)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{) \{}
\NormalTok{      failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{      failed\_rhat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_rhat\_names, name)}
\NormalTok{    \}}

    \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
      \CommentTok{\# Check empirical effective sample size}
\NormalTok{      tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tau\_hat(samples[c,])}
\NormalTok{      eess }\OperatorTok{\textless{}{-}}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
      
      \ControlFlowTok{if}\NormalTok{ (eess }\OperatorTok{\textless{}}\NormalTok{ min\_eess\_per\_chain) \{}
\NormalTok{        failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_names, name)}
\NormalTok{        failed\_eess\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(failed\_eess\_names, name)}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  
\NormalTok{  message }\OperatorTok{\textless{}{-}} \StringTok{""}
  
\NormalTok{  failed\_names }\OperatorTok{\textless{}{-}}\NormalTok{ unique(failed\_names)}
  \ControlFlowTok{if}\NormalTok{ (length(failed\_names)) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} 
\NormalTok{      sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ triggered diagnostic warnings.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{              paste(failed\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{))}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(}\StringTok{\textquotesingle{}All expectands checked appear to be behaving \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}well enough for reliable Markov chain Monte \textquotesingle{}}\NormalTok{,}
                   \StringTok{\textquotesingle{}Carlo estimation.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc)}
\NormalTok{  \}}

\NormalTok{  failed\_xi\_hat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ unique(failed\_xi\_hat\_names)}
  \ControlFlowTok{if}\NormalTok{ (length(failed\_xi\_hat\_names)) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} 
\NormalTok{      paste0(sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ triggered hat}\SpecialCharTok{\{xi\}}\StringTok{ warnings.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{             paste(failed\_xi\_hat\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{)),}
             \StringTok{\textquotesingle{}  Large tail hat}\SpecialCharTok{\{xi\}}\StringTok{s suggest that the expectand \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}might not be sufficiently integrable.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
        
\NormalTok{  failed\_zvar\_names }\OperatorTok{\textless{}{-}}\NormalTok{ unique(failed\_zvar\_names)}
  \ControlFlowTok{if}\NormalTok{ (length(failed\_zvar\_names)) \{ }
\NormalTok{    desc }\OperatorTok{\textless{}{-}} 
\NormalTok{      paste0(sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ triggered zero variance warnings.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{             paste(failed\_zvar\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{)),}
             \StringTok{\textquotesingle{}  If the expectands are not constant then zero \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}empirical variance suggests that the Markov \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}transitions may be misbehaving.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  failed\_rhat\_names }\OperatorTok{\textless{}{-}}\NormalTok{ unique(failed\_rhat\_names)}
  \ControlFlowTok{if}\NormalTok{ (length(failed\_rhat\_names)) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} 
\NormalTok{      paste0(sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ triggered hat}\SpecialCharTok{\{R\}}\StringTok{ warnings.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{             paste(failed\_rhat\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{)),}
             \StringTok{\textquotesingle{}  Split Rhat larger than 1.1 suggests that at \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}least one of the Markov chains has not reached \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}an equilibrium.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  failed\_eess\_names }\OperatorTok{\textless{}{-}}\NormalTok{ unique(failed\_eess\_names)}
  \ControlFlowTok{if}\NormalTok{ (length(failed\_eess\_names)) \{}
\NormalTok{    desc }\OperatorTok{\textless{}{-}} 
\NormalTok{      paste0(sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ triggered hat}\SpecialCharTok{\{ESS\}}\StringTok{ warnings.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{,}
\NormalTok{             paste(failed\_eess\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{)),}
             \StringTok{\textquotesingle{}  Small empirical effective sample sizes indicate strong \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}empirical autocorrelations in the realized Markov chains. \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}If the empirical effective sample size is too \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}small then Markov chain Monte Carlo estimation \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}may be unreliable even when a central limit \textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}theorem holds.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(desc, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(message, desc, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  cat(message)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Alternatively we might filter the expectands, keeping only those of
immediate interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Filter \textasciigrave{}expectand\_samples\textasciigrave{} by name.}
\CommentTok{\# @param expectand\_samples A named list of two{-}dimensional arrays for}
\CommentTok{\#                          each expectand.  The first dimension of each}
\CommentTok{\#                          element indexes the Markov chains and the}
\CommentTok{\#                          second dimension indexes the sequential}
\CommentTok{\#                          states within each Markov chain.}
\CommentTok{\# @param requested\_names Expectand names to keep.}
\CommentTok{\# @param check\_arrays Binary variable indicating whether or not requested}
\CommentTok{\#                     names should be expanded to array components.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\CommentTok{\# @return A named list of two{-}dimensional arrays for each requested}
\CommentTok{\#         expectand.}
\NormalTok{filter\_expectands }\OperatorTok{\textless{}{-}}\NormalTok{ function(expectand\_samples, requested\_names,}
\NormalTok{                              check\_arrays}\OperatorTok{=}\NormalTok{FALSE, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(expectand\_samples)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_samples\textasciigrave{} is not a named list!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.vector(requested\_names)) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}requested\_names\textasciigrave{} is empty!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (check\_arrays }\OperatorTok{==}\NormalTok{ TRUE) \{}
\NormalTok{    good\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
\NormalTok{    bad\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c()}
    \ControlFlowTok{for}\NormalTok{ (name }\KeywordTok{in}\NormalTok{ requested\_names) \{}
      \CommentTok{\# Search for array suffix}
\NormalTok{      array\_names }\OperatorTok{\textless{}{-}}\NormalTok{ grep(paste0(name, }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{[\textquotesingle{}}\NormalTok{), }
\NormalTok{                          names(expectand\_samples), }
\NormalTok{                          value}\OperatorTok{=}\NormalTok{TRUE)}
      
      \CommentTok{\# Append array names, if found}
      \ControlFlowTok{if}\NormalTok{ (length(array\_names) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{        good\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(good\_names, array\_names)}
\NormalTok{      \} }\ControlFlowTok{else}\NormalTok{ \{}
        \ControlFlowTok{if}\NormalTok{ (name }\OperatorTok{\%}\KeywordTok{in}\OperatorTok{\%}\NormalTok{ names(expectand\_samples)) \{}
          \CommentTok{\# Append bare name, if found}
\NormalTok{          good\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(good\_names, name)}
\NormalTok{        \}  }\ControlFlowTok{else}\NormalTok{ \{}
          \CommentTok{\# Add to list of bad names}
\NormalTok{          bad\_names }\OperatorTok{\textless{}{-}}\NormalTok{ c(bad\_names, name)}
\NormalTok{        \}}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    bad\_names }\OperatorTok{\textless{}{-}}\NormalTok{ setdiff(requested\_names, names(expectand\_samples))}
\NormalTok{    good\_names }\OperatorTok{\textless{}{-}}\NormalTok{ intersect(requested\_names, names(expectand\_samples))}
\NormalTok{  \}}
    
  \ControlFlowTok{if}\NormalTok{ (length(bad\_names) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(sprintf(}\StringTok{\textquotesingle{}The expectands }\SpecialCharTok{\%s}\StringTok{ \textquotesingle{}}\NormalTok{, }
\NormalTok{                              paste(bad\_names, collapse}\OperatorTok{=}\StringTok{", "}\NormalTok{)),}
                      \StringTok{\textquotesingle{}were not found in the \textasciigrave{}expectand\_samples\textasciigrave{} \textquotesingle{}}\NormalTok{,}
                      \StringTok{\textquotesingle{}object and will be ignored.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{\textless{}{-}}\NormalTok{ paste0(strwrap(message, max\_width, }\DecValTok{0}\NormalTok{), collapse}\OperatorTok{=}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    cat(message)}
\NormalTok{  \}}
  
\NormalTok{  expectand\_samples[good\_names]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{empirical-autocorrelation-visualization}{%
\subsection{Empirical Autocorrelation
Visualization}\label{empirical-autocorrelation-visualization}}

If we encounter large empirical integrated autocorrelation times, or
small estimated effective sample sizes, then we may want to follow up
with the empirical autocorrelations themselves. An empirical correlogram
provides a useful visualization of these estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical autocorrelations for a given Markov chain sequence}
\CommentTok{\# @parmas fs A one{-}dimensional array of sequential expectand values.}
\CommentTok{\# @return A one{-}dimensional array of empirical autocorrelations at each }
\CommentTok{\#         lag up to the length of the sequence.}
\NormalTok{compute\_rhos }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
  \CommentTok{\# Compute empirical autocorrelations}
\NormalTok{  N }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs)}
\NormalTok{  zs }\OperatorTok{\textless{}{-}}\NormalTok{ fs }\OperatorTok{{-}}\NormalTok{ mean(fs)}
  
  \ControlFlowTok{if}\NormalTok{ (var(fs) }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{(rep(}\DecValTok{1}\NormalTok{, N))}

\NormalTok{  B }\OperatorTok{\textless{}{-}} \DecValTok{2}\OperatorTok{**}\NormalTok{ceiling(log2(N)) }\CommentTok{\# Next power of 2 after N}
\NormalTok{  zs\_buff }\OperatorTok{\textless{}{-}}\NormalTok{ c(zs, rep(}\DecValTok{0}\NormalTok{, B }\OperatorTok{{-}}\NormalTok{ N))}

\NormalTok{  Fs }\OperatorTok{\textless{}{-}}\NormalTok{ fft(zs\_buff)}
\NormalTok{  Ss }\OperatorTok{\textless{}{-}}\NormalTok{ Fs }\OperatorTok{*}\NormalTok{ Conj(Fs)}
\NormalTok{  Rs }\OperatorTok{\textless{}{-}}\NormalTok{ fft(Ss, inverse}\OperatorTok{=}\NormalTok{TRUE)}

\NormalTok{  acov\_buff }\OperatorTok{\textless{}{-}}\NormalTok{ Re(Rs)}
\NormalTok{  rhos }\OperatorTok{\textless{}{-}}\NormalTok{ head(acov\_buff, N) }\OperatorTok{/}\NormalTok{ acov\_buff[}\DecValTok{1}\NormalTok{]}

  \CommentTok{\# Drop last lag if (L + 1) is odd so that the}
  \CommentTok{\# lag pairs are complete}
\NormalTok{  L }\OperatorTok{\textless{}{-}}\NormalTok{ N}
  \ControlFlowTok{if}\NormalTok{ ((L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{)}
\NormalTok{    L }\OperatorTok{\textless{}{-}}\NormalTok{ L }\OperatorTok{{-}} \DecValTok{1}

  \CommentTok{\# Number of lag pairs}
\NormalTok{  P }\OperatorTok{\textless{}{-}}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{/} \DecValTok{2}

  \CommentTok{\# Construct asymptotic correlation from initial monotone sequence}
\NormalTok{  old\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ rhos[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2}\NormalTok{]}
\NormalTok{  max\_L }\OperatorTok{\textless{}{-}}\NormalTok{ N}

  \ControlFlowTok{for}\NormalTok{ (p }\KeywordTok{in} \DecValTok{2}\NormalTok{:P) \{}
\NormalTok{    current\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p]}
  
    \ControlFlowTok{if}\NormalTok{ (current\_pair\_sum }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{) \{}
\NormalTok{      max\_L }\OperatorTok{\textless{}{-}} \DecValTok{2} \OperatorTok{*}\NormalTok{ p}
\NormalTok{      rhos[(max\_L }\OperatorTok{+} \DecValTok{1}\NormalTok{):N] }\OperatorTok{\textless{}{-}} \DecValTok{0}
      \ControlFlowTok{break}
\NormalTok{    \}}
  
    \ControlFlowTok{if}\NormalTok{ (current\_pair\_sum }\OperatorTok{\textgreater{}}\NormalTok{ old\_pair\_sum) \{}
\NormalTok{      current\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{{-}} \DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}{-}} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p] }\OperatorTok{\textless{}{-}} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{    \}}
  
\NormalTok{    old\_pair\_sum }\OperatorTok{\textless{}{-}}\NormalTok{ current\_pair\_sum}
\NormalTok{  \}}
  \ControlFlowTok{return}\NormalTok{(rhos)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot empirical correlograms for a given expectand across a Markov }
\CommentTok{\# chain ensemble.}
\CommentTok{\# @param fs A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#           with the first dimension indexing the Markov chains and }
\CommentTok{\#           the second dimension indexing the sequential states }
\CommentTok{\#           within each Markov chain.}
\CommentTok{\# @param max\_L Maximum autocorrelation lag}
\CommentTok{\# @param rho\_lim Plotting range of autocorrelation values}
\CommentTok{\# @display\_name Name of expectand}
\NormalTok{plot\_empirical\_correlogram }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs,}
\NormalTok{                                       max\_L,}
\NormalTok{                                       rho\_lim}\OperatorTok{=}\NormalTok{c(}\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{1.1}\NormalTok{),}
\NormalTok{                                       display\_name}\OperatorTok{=}\StringTok{""}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(fs)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    cat(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}fs\textasciigrave{} has the wrong dimensions!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(fs)[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  idx }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{:max\_L, each}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  xs }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(}\DecValTok{1}\NormalTok{:length(idx), function(b) }\ControlFlowTok{if}\NormalTok{(b }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{0}\NormalTok{) idx[b] }\OperatorTok{+} \FloatTok{0.5}
                                          \ControlFlowTok{else}\NormalTok{ idx[b] }\OperatorTok{{-}} \FloatTok{0.5}\NormalTok{)}

\NormalTok{  plot(}\DecValTok{0}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"n"}\NormalTok{, main}\OperatorTok{=}\NormalTok{display\_name,}
\NormalTok{       xlab}\OperatorTok{=}\StringTok{"Lag"}\NormalTok{, xlim}\OperatorTok{=}\NormalTok{c(}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, max\_L }\OperatorTok{+} \FloatTok{0.5}\NormalTok{),}
\NormalTok{       ylab}\OperatorTok{=}\StringTok{"Empirical Autocorrelation"}\NormalTok{, ylim}\OperatorTok{=}\NormalTok{rho\_lim)}
\NormalTok{  abline(h}\OperatorTok{=}\DecValTok{0}\NormalTok{, col}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{, lty}\OperatorTok{=}\DecValTok{2}\NormalTok{, lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

\NormalTok{  colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(c\_dark, c\_mid\_highlight, c\_mid, c\_light\_highlight)}
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    rhos }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_rhos(fs[c,])}
\NormalTok{    pad\_rhos }\OperatorTok{\textless{}{-}}\NormalTok{ unlist(lapply(idx, function(n) rhos[n }\OperatorTok{+} \DecValTok{1}\NormalTok{]))}
\NormalTok{    lines(xs, pad\_rhos, lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{, col}\OperatorTok{=}\NormalTok{colors[c])}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{chain-separated-pairs-plot}{%
\subsection{Chain-Separated Pairs
Plot}\label{chain-separated-pairs-plot}}

We can also visualize strong autocorrelations by coloring the states of
each Markov chain in a continuous gradient. When neighboring states are
strongly correlated these colors will appear to vary smoothly across the
ambient space. More productive Markov transitions result in a more
chaotic spray of colors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Visualize the projection of a Markov chain ensemble along two }
\CommentTok{\# expectands as a pairs plot.  Point colors darken along each Markov }
\CommentTok{\# chain to visualize the autocorrelation.}
\CommentTok{\# @param f1s A two{-}dimensional array of expectand values with the first }
\CommentTok{\#            dimension indexing the Markov chains and the second }
\CommentTok{\#            dimension indexing the sequential states  within each }
\CommentTok{\#            Markov chain.}
\CommentTok{\# @params display\_name1 Name of first expectand}
\CommentTok{\# @param f2s A two{-}dimensional array of expectand values with the first }
\CommentTok{\#            dimension indexing the Markov chains and the second }
\CommentTok{\#            dimension indexing the sequential states  within each }
\CommentTok{\#            Markov chain.}
\CommentTok{\# @params display\_name2 Name of second expectand}
\NormalTok{plot\_pairs\_by\_chain }\OperatorTok{\textless{}{-}}\NormalTok{ function(f1s, display\_name1,}
\NormalTok{                                f2s, display\_name2) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(f1s)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}f1s\textasciigrave{} has the wrong dimensions!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C1 }\OperatorTok{\textless{}{-}}\NormalTok{ dim(f1s)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  S1 }\OperatorTok{\textless{}{-}}\NormalTok{ dim(f1s)[}\DecValTok{2}\NormalTok{]}

  \ControlFlowTok{if}\NormalTok{ (length(dim(f2s)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}f1s\textasciigrave{} has the wrong dimensions!\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  C2 }\OperatorTok{\textless{}{-}}\NormalTok{ dim(f2s)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  S2 }\OperatorTok{\textless{}{-}}\NormalTok{ dim(f2s)[}\DecValTok{2}\NormalTok{]}
  
  \ControlFlowTok{if}\NormalTok{ (C1 }\OperatorTok{!=}\NormalTok{ C2) \{}
\NormalTok{    C }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(C1, C2)}
\NormalTok{    C1 }\OperatorTok{\textless{}{-}}\NormalTok{ C}
\NormalTok{    C2 }\OperatorTok{\textless{}{-}}\NormalTok{ C}
\NormalTok{    cat(sprintf(}\StringTok{\textquotesingle{}Plotting only }\SpecialCharTok{\%s}\StringTok{ Markov chains.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{, C))}
\NormalTok{  \}}

\NormalTok{  nom\_colors }\OperatorTok{\textless{}{-}}\NormalTok{ c(}\StringTok{"\#DCBCBC"}\NormalTok{, }\StringTok{"\#C79999"}\NormalTok{, }\StringTok{"\#B97C7C"}\NormalTok{,}
                  \StringTok{"\#A25050"}\NormalTok{, }\StringTok{"\#8F2727"}\NormalTok{, }\StringTok{"\#7C0000"}\NormalTok{)}
\NormalTok{  cmap }\OperatorTok{\textless{}{-}}\NormalTok{ colormap(colormap}\OperatorTok{=}\NormalTok{nom\_colors, nshades}\OperatorTok{=}\BuiltInTok{max}\NormalTok{(S1, S2))}

\NormalTok{  min\_x }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C1, function(c) }\BuiltInTok{min}\NormalTok{(f1s[c,])))}
\NormalTok{  max\_x }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C1, function(c) }\BuiltInTok{max}\NormalTok{(f1s[c,])))}

\NormalTok{  min\_y }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C2, function(c) }\BuiltInTok{min}\NormalTok{(f2s[c,])))}
\NormalTok{  max\_y }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(sapply(}\DecValTok{1}\NormalTok{:C2, function(c) }\BuiltInTok{max}\NormalTok{(f2s[c,])))}

\NormalTok{  par(mfrow}\OperatorTok{=}\NormalTok{c(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), mar }\OperatorTok{=}\NormalTok{ c(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{))}

  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C1) \{}
\NormalTok{    plot(}\DecValTok{0}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"n"}\NormalTok{, main}\OperatorTok{=}\NormalTok{paste(}\StringTok{"Chain"}\NormalTok{, c),}
\NormalTok{         xlab}\OperatorTok{=}\NormalTok{display\_name1, xlim}\OperatorTok{=}\NormalTok{c(min\_x, max\_x),}
\NormalTok{         ylab}\OperatorTok{=}\NormalTok{display\_name2, ylim}\OperatorTok{=}\NormalTok{c(min\_y, max\_y))}
  
\NormalTok{    points(unlist(lapply(}\DecValTok{1}\NormalTok{:C1, function(c) f1s[c,])),}
\NormalTok{           unlist(lapply(}\DecValTok{1}\NormalTok{:C1, function(c) f2s[c,])),}
\NormalTok{           col}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{, pch}\OperatorTok{=}\DecValTok{16}\NormalTok{, cex}\OperatorTok{=}\FloatTok{1.0}\NormalTok{)}
\NormalTok{    points(f1s[c,], f2s[c,], col}\OperatorTok{=}\NormalTok{cmap, pch}\OperatorTok{=}\DecValTok{16}\NormalTok{, cex}\OperatorTok{=}\FloatTok{1.0}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{markov-chain-monte-carlo-estimation}{%
\section{Markov Chain Monte Carlo
Estimation}\label{markov-chain-monte-carlo-estimation}}

If none of the diagnostics indicate an obstruction to a Markov chain
Monte Carlo central limit theorem then we can construct expectation
value estimates and their standard errors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Evaluate an expectand at the states of a Markov chain ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of scalar Markov chain states }
\CommentTok{\#                with the first dimension indexing the Markov chains and }
\CommentTok{\#                the second dimension indexing the sequential states }
\CommentTok{\#                within each Markov chain.}
\CommentTok{\# @param expectand Scalar function to be applied to the Markov chain }
\CommentTok{\#                  states.}
\CommentTok{\# @return A two{-}dimensional array of expectand values with the }
\CommentTok{\#         first dimension indexing the Markov chains and the }
\CommentTok{\#         second dimension indexing the sequential states within }
\CommentTok{\#         each Markov chain.}
\NormalTok{pushforward\_chains }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples, expectand) \{}
  \BuiltInTok{apply}\NormalTok{(samples, }\DecValTok{2}\NormalTok{, expectand)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate expectand exectation value from a single Markov chain.}
\CommentTok{\# @param fs A one{-}dimensional array of sequential expectand values.}
\CommentTok{\# @return The Markov chain Monte Carlo estimate, its estimated standard }
\CommentTok{\#         error, and empirical effective sample size.}
\NormalTok{mcmc\_est }\OperatorTok{\textless{}{-}}\NormalTok{ function(fs) \{}
\NormalTok{  S }\OperatorTok{\textless{}{-}}\NormalTok{ length(fs)}
  \ControlFlowTok{if}\NormalTok{ (S }\OperatorTok{==} \DecValTok{1}\NormalTok{) \{}
    \ControlFlowTok{return}\NormalTok{(c(fs[}\DecValTok{1}\NormalTok{], }\DecValTok{0}\NormalTok{, NaN))}
\NormalTok{  \}}

\NormalTok{  summary }\OperatorTok{\textless{}{-}}\NormalTok{ welford\_summary(fs)}

  \ControlFlowTok{if}\NormalTok{ (summary[}\DecValTok{2}\NormalTok{] }\OperatorTok{==} \DecValTok{0}\NormalTok{) \{}
    \ControlFlowTok{return}\NormalTok{(c(summary[}\DecValTok{1}\NormalTok{], }\DecValTok{0}\NormalTok{, NaN))}
\NormalTok{  \}}

\NormalTok{  tau\_hat }\OperatorTok{\textless{}{-}}\NormalTok{ compute\_tau\_hat(fs)}
\NormalTok{  eess }\OperatorTok{\textless{}{-}}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
  \ControlFlowTok{return}\NormalTok{(c(summary[}\DecValTok{1}\NormalTok{], sqrt(summary[}\DecValTok{2}\NormalTok{] }\OperatorTok{/}\NormalTok{ eess), eess))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate expectand exectation value from a Markov chain ensemble.}
\CommentTok{\# @param samples A two{-}dimensional array of expectand values with the }
\CommentTok{\#                first dimension indexing the Markov chains and the }
\CommentTok{\#                second dimension indexing the sequential states within }
\CommentTok{\#                each Markov chain.}
\CommentTok{\# @return The ensemble Markov chain Monte Carlo estimate, its estimated}
\CommentTok{\#         standard error, and empirical effective sample size.}
\NormalTok{ensemble\_mcmc\_est }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    cat(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ (c(NaN, NaN, NaN))}
\NormalTok{  \}}
  
\NormalTok{  C }\OperatorTok{\textless{}{-}}\NormalTok{ dim(samples)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  chain\_ests }\OperatorTok{\textless{}{-}}\NormalTok{ lapply(}\DecValTok{1}\NormalTok{:C, function(c) mcmc\_est(samples[c,]))}
  
  \CommentTok{\# Total effective sample size}
\NormalTok{  total\_ess }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(sapply(chain\_ests, function(est) est[}\DecValTok{3}\NormalTok{]))}
  
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.nan(total\_ess)) \{}
\NormalTok{    m }\OperatorTok{\textless{}{-}}\NormalTok{ mean(sapply(chain\_ests, function(est) est[}\DecValTok{1}\NormalTok{]))}
\NormalTok{    se }\OperatorTok{\textless{}{-}}\NormalTok{ mean(sapply(chain\_ests, function(est) est[}\DecValTok{2}\NormalTok{]))}
    \ControlFlowTok{return}\NormalTok{ (c(m, se, NaN))}
\NormalTok{  \}}
  
  \CommentTok{\# Ensemble average weighted by effective sample size}
\NormalTok{  mean }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(sapply(chain\_ests,}
\NormalTok{                     function(est) est[}\DecValTok{3}\NormalTok{] }\OperatorTok{*}\NormalTok{ est[}\DecValTok{1}\NormalTok{])) }\OperatorTok{/}\NormalTok{ total\_ess}
  
  \CommentTok{\# Ensemble variance weighed by effective sample size}
  \CommentTok{\# including correction for the fact that individual Markov chain}
  \CommentTok{\# variances are defined relative to the individual mean estimators}
  \CommentTok{\# and not the ensemble mean estimator}
  \BuiltInTok{vars} \OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, C)}
  
  \ControlFlowTok{for}\NormalTok{ (c }\KeywordTok{in} \DecValTok{1}\NormalTok{:C) \{}
\NormalTok{    est }\OperatorTok{\textless{}{-}}\NormalTok{ chain\_ests[[c]]}
\NormalTok{    chain\_var }\OperatorTok{\textless{}{-}}\NormalTok{ est[}\DecValTok{3}\NormalTok{] }\OperatorTok{*}\NormalTok{ est[}\DecValTok{2}\NormalTok{]}\OperatorTok{**}\DecValTok{2}
\NormalTok{    var\_update }\OperatorTok{\textless{}{-}}\NormalTok{ (est[}\DecValTok{1}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ mean)}\OperatorTok{**}\DecValTok{2}
    \BuiltInTok{vars}\NormalTok{[c] }\OperatorTok{\textless{}{-}}\NormalTok{ est[}\DecValTok{3}\NormalTok{] }\OperatorTok{*}\NormalTok{ (var\_update }\OperatorTok{+}\NormalTok{ chain\_var)}
\NormalTok{  \}}
\NormalTok{  var }\OperatorTok{\textless{}{-}} \BuiltInTok{sum}\NormalTok{(}\BuiltInTok{vars}\NormalTok{) }\OperatorTok{/}\NormalTok{ total\_ess}
  
\NormalTok{  c(mean, sqrt(var }\OperatorTok{/}\NormalTok{ total\_ess), total\_ess)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In addition to examining the single expectation value of an expectand we
can also visualize the entire pushforward distribution of the expectand
by estimating the target probabilities in histogram bins.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Visualize pushforward distribution of a given expectand as a }
\CommentTok{\# histogram, using Markov chain Monte Carlo estimators to estimate the }
\CommentTok{\# output bin probabilities.  Bin probability estimator error is shown }
\CommentTok{\# in gray.}
\CommentTok{\# @param samples A two{-}dimensional array of expectand values with the }
\CommentTok{\#                first dimension indexing the Markov chains and the }
\CommentTok{\#                second dimension indexing the sequential states within }
\CommentTok{\#                each Markov chain.}
\CommentTok{\# @param B The number of histogram bins}
\CommentTok{\# @param display\_name Exectand name}
\CommentTok{\# @param flim Optional histogram range}
\CommentTok{\# @param baseline Optional baseline value for visual comparison}
\NormalTok{plot\_expectand\_pushforward }\OperatorTok{\textless{}{-}}\NormalTok{ function(samples, B, display\_name}\OperatorTok{=}\StringTok{"f"}\NormalTok{, }
\NormalTok{                                       flim}\OperatorTok{=}\NormalTok{NULL, baseline}\OperatorTok{=}\NormalTok{NULL) \{}
  \ControlFlowTok{if}\NormalTok{ (length(dim(samples)) }\OperatorTok{!=} \DecValTok{2}\NormalTok{) \{}
\NormalTok{    stop(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}samples\textasciigrave{} has the wrong dimension\textquotesingle{}}\NormalTok{)}
\NormalTok{  \}}
  
  \CommentTok{\# Automatically adjust histogram range to range of expectand values}
  \CommentTok{\# if range is not already set as an input variable}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is}\NormalTok{.null(flim)) \{}
\NormalTok{    min\_f }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(samples)}
\NormalTok{    max\_f }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(samples)}
    
    \CommentTok{\# Add bounding bins}
\NormalTok{    delta }\OperatorTok{\textless{}{-}}\NormalTok{ (max\_f }\OperatorTok{{-}}\NormalTok{ min\_f) }\OperatorTok{/}\NormalTok{ B}
\NormalTok{    min\_f }\OperatorTok{\textless{}{-}}\NormalTok{ min\_f }\OperatorTok{{-}}\NormalTok{ delta}
\NormalTok{    max\_f }\OperatorTok{\textless{}{-}}\NormalTok{ max\_f }\OperatorTok{+}\NormalTok{ delta}
\NormalTok{    flim }\OperatorTok{\textless{}{-}}\NormalTok{ c(min\_f, max\_f)}
    
\NormalTok{    bins }\OperatorTok{\textless{}{-}}\NormalTok{ seq(min\_f, max\_f, delta)}
\NormalTok{    B }\OperatorTok{\textless{}{-}}\NormalTok{ B }\OperatorTok{+} \DecValTok{2}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    delta }\OperatorTok{\textless{}{-}}\NormalTok{ (flim[}\DecValTok{2}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ flim[}\DecValTok{1}\NormalTok{]) }\OperatorTok{/}\NormalTok{ B}
\NormalTok{    bins }\OperatorTok{\textless{}{-}}\NormalTok{ seq(flim[}\DecValTok{1}\NormalTok{], flim[}\DecValTok{2}\NormalTok{], delta)}
\NormalTok{  \}}
  
  \CommentTok{\# Compute bin heights}
\NormalTok{  mean\_p }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, B)}
\NormalTok{  delta\_p }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{0}\NormalTok{, B)}
  
  \ControlFlowTok{for}\NormalTok{ (b }\KeywordTok{in} \DecValTok{1}\NormalTok{:B) \{}
    \CommentTok{\# Estimate bin probabilities}
\NormalTok{    bin\_indicator }\OperatorTok{\textless{}{-}}\NormalTok{ function(x) \{}
\NormalTok{      ifelse(bins[b] }\OperatorTok{\textless{}=}\NormalTok{ x }\OperatorTok{\&}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ bins[b }\OperatorTok{+} \DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{    \}}
\NormalTok{    indicator\_samples }\OperatorTok{\textless{}{-}}\NormalTok{ pushforward\_chains(samples, bin\_indicator)}
\NormalTok{    est }\OperatorTok{\textless{}{-}}\NormalTok{ ensemble\_mcmc\_est(indicator\_samples)}
    
    \CommentTok{\# Normalize bin probabilities by bin width to allow}
    \CommentTok{\# for direct comparison to probability density functions}
\NormalTok{    width }\OperatorTok{=}\NormalTok{ bins[b }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ bins[b]}
\NormalTok{    mean\_p[b] }\OperatorTok{=}\NormalTok{ est[}\DecValTok{1}\NormalTok{] }\OperatorTok{/}\NormalTok{ width}
\NormalTok{    delta\_p[b] }\OperatorTok{=}\NormalTok{ est[}\DecValTok{2}\NormalTok{] }\OperatorTok{/}\NormalTok{ width}
\NormalTok{  \}}
  
  \CommentTok{\# Plot histogram}
\NormalTok{  idx }\OperatorTok{\textless{}{-}}\NormalTok{ rep(}\DecValTok{1}\NormalTok{:B, each}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  x }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(}\DecValTok{1}\NormalTok{:length(idx), function(b) }\ControlFlowTok{if}\NormalTok{(b }\OperatorTok{\%\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{) bins[idx[b]]}
              \ControlFlowTok{else}\NormalTok{ bins[idx[b] }\OperatorTok{+} \DecValTok{1}\NormalTok{])}
\NormalTok{  lower\_inter }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(idx, function (n)}
    \BuiltInTok{max}\NormalTok{(mean\_p[n] }\OperatorTok{{-}} \DecValTok{2} \OperatorTok{*}\NormalTok{ delta\_p[n], }\DecValTok{0}\NormalTok{))}
\NormalTok{  upper\_inter }\OperatorTok{\textless{}{-}}\NormalTok{ sapply(idx, function (n)}
    \BuiltInTok{min}\NormalTok{(mean\_p[n] }\OperatorTok{+} \DecValTok{2} \OperatorTok{*}\NormalTok{ delta\_p[n], }\DecValTok{1} \OperatorTok{/}\NormalTok{ width))}
  
\NormalTok{  min\_y }\OperatorTok{\textless{}{-}} \BuiltInTok{min}\NormalTok{(lower\_inter)}
\NormalTok{  max\_y }\OperatorTok{\textless{}{-}} \BuiltInTok{max}\NormalTok{(}\FloatTok{1.05} \OperatorTok{*}\NormalTok{ upper\_inter)}
  
\NormalTok{  plot(}\DecValTok{1}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\StringTok{"n"}\NormalTok{, main}\OperatorTok{=}\StringTok{""}\NormalTok{,}
\NormalTok{       xlim}\OperatorTok{=}\NormalTok{flim, xlab}\OperatorTok{=}\NormalTok{display\_name,}
\NormalTok{       ylim}\OperatorTok{=}\NormalTok{c(min\_y, max\_y), ylab}\OperatorTok{=}\StringTok{""}\NormalTok{, yaxt}\OperatorTok{=}\StringTok{"n"}\NormalTok{)}
\NormalTok{  title(ylab}\OperatorTok{=}\StringTok{"Estimated Bin}\CharTok{\textbackslash{}n}\StringTok{Probabilities / Bin Width"}\NormalTok{, mgp}\OperatorTok{=}\NormalTok{c(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
  
\NormalTok{  polygon(c(x, rev(x)), c(lower\_inter, rev(upper\_inter)),}
\NormalTok{          col }\OperatorTok{=} \StringTok{"\#DDDDDD"}\NormalTok{, border }\OperatorTok{=}\NormalTok{ NA)}
\NormalTok{  lines(x, mean\_p[idx], col}\OperatorTok{=}\NormalTok{c\_dark, lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
  
  \CommentTok{\# Plot baseline if applicable}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is}\NormalTok{.null(baseline)) \{}
\NormalTok{    abline(v}\OperatorTok{=}\NormalTok{baseline, col}\OperatorTok{=}\StringTok{"white"}\NormalTok{, lty}\OperatorTok{=}\DecValTok{1}\NormalTok{, lwd}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
\NormalTok{    abline(v}\OperatorTok{=}\NormalTok{baseline, col}\OperatorTok{=}\StringTok{"black"}\NormalTok{, lty}\OperatorTok{=}\DecValTok{1}\NormalTok{, lwd}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{demonstration}{%
\section{Demonstration}\label{demonstration}}

Now let's put all of these analysis tools to use with an \texttt{rstan}
fit object.

First we setup our local \texttt{R} environment.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rstan)}
\FunctionTok{rstan\_options}\NormalTok{(}\AttributeTok{auto\_write =} \ConstantTok{TRUE}\NormalTok{)            }\CommentTok{\# Cache compiled Stan programs}
\FunctionTok{options}\NormalTok{(}\AttributeTok{mc.cores =}\NormalTok{ parallel}\SpecialCharTok{::}\FunctionTok{detectCores}\NormalTok{()) }\CommentTok{\# Parallelize chains}
\NormalTok{parallel}\SpecialCharTok{:::}\FunctionTok{setDefaultClusterOptions}\NormalTok{(}\AttributeTok{setup\_strategy =} \StringTok{"sequential"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Next we source all of these diagnostics into a local environment to
avoid any conflicts with other functions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util }\OtherTok{\textless{}{-}} \FunctionTok{new.env}\NormalTok{()}
\FunctionTok{source}\NormalTok{(}\StringTok{\textquotesingle{}stan\_utility\_rstan.R\textquotesingle{}}\NormalTok{, }\AttributeTok{local=}\NormalTok{util)}
\end{Highlighting}
\end{Shaded}

Then we can simulate some binary data from a logistic regression model.

\begin{codelisting}

\caption{\texttt{simu\_logistic\_reg.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{transformed data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} M = }\DecValTok{3}\NormalTok{;         }\CommentTok{// Number of covariates}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N = }\DecValTok{1000}\NormalTok{;      }\CommentTok{// Number of observations}
  
  \DataTypeTok{vector}\NormalTok{[M] x0 = [{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]\textquotesingle{}; }\CommentTok{// Covariate baseline}
  \DataTypeTok{vector}\NormalTok{[M] z0 = [{-}}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]\textquotesingle{}; }\CommentTok{// Latent functional behavior baseline}
  \DataTypeTok{real}\NormalTok{ gamma0 = {-}}\FloatTok{2.6}\NormalTok{;                      }\CommentTok{// True intercept}
  \DataTypeTok{vector}\NormalTok{[M] gamma1 = [}\FloatTok{0.2}\NormalTok{, {-}}\FloatTok{2.0}\NormalTok{, }\FloatTok{0.33}\NormalTok{]\textquotesingle{};   }\CommentTok{// True slopes}
  \DataTypeTok{matrix}\NormalTok{[M, M] gamma2 = [ [+}\FloatTok{0.40}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{, {-}}\FloatTok{0.20}\NormalTok{],}
\NormalTok{                          [{-}}\FloatTok{0.05}\NormalTok{, {-}}\FloatTok{1.00}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{],}
\NormalTok{                          [{-}}\FloatTok{0.20}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{, +}\FloatTok{0.50}\NormalTok{] ];}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \DataTypeTok{matrix}\NormalTok{[N, M] X; }\CommentTok{// Covariate design matrix}
  \DataTypeTok{real}\NormalTok{ y[N];      }\CommentTok{// Variates}

  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N) \{}
    \DataTypeTok{real}\NormalTok{ x2 = {-}}\DecValTok{5}\NormalTok{;}
    \ControlFlowTok{while}\NormalTok{ (x2 \textless{} x0[}\DecValTok{2}\NormalTok{] {-} }\DecValTok{4}\NormalTok{ || x2 \textgreater{} x0[}\DecValTok{2}\NormalTok{] + }\DecValTok{4}\NormalTok{)}
\NormalTok{      x2 = normal\_rng(x0[}\DecValTok{2}\NormalTok{], }\DecValTok{2}\NormalTok{);}
    
\NormalTok{    X[n, }\DecValTok{2}\NormalTok{] = x2;}
\NormalTok{    X[n, }\DecValTok{1}\NormalTok{] = normal\_rng(x0[}\DecValTok{1}\NormalTok{] + }\FloatTok{1.0}\NormalTok{ * cos(}\FloatTok{1.5}\NormalTok{ * (X[n, }\DecValTok{2}\NormalTok{] {-} x0[}\DecValTok{2}\NormalTok{])), }\FloatTok{0.3}\NormalTok{);}
\NormalTok{    X[n, }\DecValTok{3}\NormalTok{] = normal\_rng(x0[}\DecValTok{3}\NormalTok{] + }\FloatTok{0.76}\NormalTok{ * (X[n, }\DecValTok{1}\NormalTok{] {-} x0[}\DecValTok{1}\NormalTok{]), }\FloatTok{0.5}\NormalTok{);}

\NormalTok{    y[n] = bernoulli\_logit\_rng(  gamma0 }
\NormalTok{                               + (X[n] {-} z0\textquotesingle{}) * gamma1}
\NormalTok{                               + (X[n] {-} z0\textquotesingle{}) * gamma2 * (X[n] {-} z0\textquotesingle{})\textquotesingle{});}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simu }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/simu\_logistic\_reg.stan"}\NormalTok{,}
             \AttributeTok{iter=}\DecValTok{1}\NormalTok{, }\AttributeTok{warmup=}\DecValTok{0}\NormalTok{, }\AttributeTok{chains=}\DecValTok{1}\NormalTok{,}
             \AttributeTok{seed=}\DecValTok{4838282}\NormalTok{, }\AttributeTok{algorithm=}\StringTok{"Fixed\_param"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).
Chain 1: Iteration: 1 / 1 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 0 seconds (Warm-up)
Chain 1:                0 seconds (Sampling)
Chain 1:                0 seconds (Total)
Chain 1: 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(simu)}\SpecialCharTok{$}\NormalTok{X[}\DecValTok{1}\NormalTok{,,]}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(simu)}\SpecialCharTok{$}\NormalTok{y[}\DecValTok{1}\NormalTok{,]}

\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"M"} \OtherTok{=} \DecValTok{3}\NormalTok{, }\StringTok{"N"} \OtherTok{=} \DecValTok{1000}\NormalTok{, }\StringTok{"x0"} \OtherTok{=} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\StringTok{"X"} \OtherTok{=}\NormalTok{ X, }\StringTok{"y"} \OtherTok{=}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

We'll try to fit this model not with a constraint-respecting logistic
regression model but rather a constraint blaspheming linear probability
model. Importantly the resulting posterior density function is
discontinuous with configurations
\texttt{alpha\ +\ deltaX\ *\ beta\ \textgreater{}\ 0} resulting in
finite \texttt{bernoulli\_lpmf} outputs and those with
\texttt{alpha\ +\ deltaX\ *\ beta\ \textless{}=\ 0} resulting in minus
infinite outputs.

\begin{codelisting}

\caption{\texttt{bernoulli\_linear.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} M; }\CommentTok{// Number of covariates}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N; }\CommentTok{// Number of observations}
  
  \DataTypeTok{vector}\NormalTok{[M] x0;   }\CommentTok{// Covariate baselines}
  \DataTypeTok{matrix}\NormalTok{[N, M] X; }\CommentTok{// Covariate design matrix}
  
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} y[N]; }\CommentTok{// Variates}
\NormalTok{\}}

\KeywordTok{transformed data}\NormalTok{ \{}
  \DataTypeTok{matrix}\NormalTok{[N, M] deltaX;}
  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N) \{}
\NormalTok{    deltaX[n,] = X[n] {-} x0\textquotesingle{};}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ alpha;      }\CommentTok{// Intercept}
  \DataTypeTok{vector}\NormalTok{[M] beta;  }\CommentTok{// Linear slopes}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  alpha \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  beta \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}

  \CommentTok{// Vectorized observation model}
\NormalTok{  y \textasciitilde{} bernoulli(alpha + deltaX * beta);}
\NormalTok{\}}

\CommentTok{// Simulate a full observation from the current value of the parameters}
\KeywordTok{generated quantities}\NormalTok{ \{}
  \DataTypeTok{vector}\NormalTok{[N] p = alpha + deltaX * beta;}
  \DataTypeTok{int}\NormalTok{ y\_pred[N] = bernoulli\_rng(p);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

Because of this awkward constraint we have to carefully initialize our
Markov chains to satisfy the
\texttt{alpha\ +\ deltaX\ *\ beta\ \textgreater{}\ 0} constraint.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{48383499}\NormalTok{)}

\NormalTok{interval\_inits }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}

\ControlFlowTok{for}\NormalTok{ (c }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  beta }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{  alpha }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{  interval\_inits[[c]] }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"alpha"} \OtherTok{=}\NormalTok{ alpha, }\StringTok{"beta"} \OtherTok{=}\NormalTok{ beta)}
\NormalTok{\}}

\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{stan}\NormalTok{(}\AttributeTok{file=}\StringTok{"stan\_programs/bernoulli\_linear.stan"}\NormalTok{,}
            \AttributeTok{data=}\NormalTok{data, }\AttributeTok{seed=}\DecValTok{8438338}\NormalTok{,}
            \AttributeTok{warmup=}\DecValTok{1000}\NormalTok{, }\AttributeTok{iter=}\DecValTok{2024}\NormalTok{, }\AttributeTok{refresh=}\DecValTok{0}\NormalTok{,}
            \AttributeTok{init=}\NormalTok{interval\_inits)}
\end{Highlighting}
\end{Shaded}

Stan is able to run to completion, but just how useful are the Markov
chains that it generates?

Let's start with the Hamiltonian Monte Carlo diagnostics.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_hmc\_diagnostics}\NormalTok{(fit)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_hmc\_diagnostics}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Chain 1: 1022 of 1024 transitions (99.8%) diverged.

  Chain 2: 1014 of 1024 transitions (99.0%) diverged.

  Chain 3: 1015 of 1024 transitions (99.1%) diverged.

  Chain 4: 1013 of 1024 transitions (98.9%) diverged.
  Chain 4: Averge proxy acceptance statistic (0.629) is
           smaller than 90% of the target (0.801).

  Divergent Hamiltonian transitions result from unstable numerical
trajectories.  These instabilities are often due to degenerate target
geometry, especially "pinches".  If there are only a small number of
divergences then running with adept_delta larger than 0.801 may reduce
the instabilities at the cost of more expensive Hamiltonian
transitions.

  A small average proxy acceptance statistic indicates that the
adaptation of the numerical integrator step size failed to converge.
This is often due to discontinuous or imprecise gradients.
\end{verbatim}

Almost every transition across the four Markov chains resulted in a
divergence. This is due to the discontinuity in the linear probability
model as the sudden jump from a finite to a negative infinite target
density results in unstable numerical trajectories.

We also see the one of the Markov chains wasn't able to hit the step
size adaptation target. To see why let's dig into the adapted
configuration of the Hamiltonian Markov transition.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_inv\_metric}\NormalTok{(fit, }\DecValTok{75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\end{figure}

The problematic Markov chain also exhibits the most variation in its
inverse metric elements, which in this case is probably an artifact of
its warmup phase spending too much time close to a constraint boundary.
Artificially variable inverse metric elements frustrate numerical
integration which can then frustrate the integrator step size
adaptation.

Interestingly the adapted step sizes are nearly the same for all four
Markov chains. The lower average proxy acceptance statistic seen in the
fourth Markov chain is due entirely to the wonky inverse metric
adaptation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{display\_stepsizes}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Chain 1: Integrator Step Size = 0.022103
Chain 2: Integrator Step Size = 0.024148
Chain 3: Integrator Step Size = 0.037035
Chain 4: Integrator Step Size = 0.026320
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{display\_ave\_accept\_proxy}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Chain 1: Average proxy acceptance statistic = 0.766
Chain 2: Average proxy acceptance statistic = 0.814
Chain 3: Average proxy acceptance statistic = 0.729
Chain 4: Average proxy acceptance statistic = 0.629
\end{verbatim}

The different inverse metric results in different Hamiltonian dynamics.
In this case the dynamics driving the fourth Markov chain are not able
to explore as far as those in the other chains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_num\_leapfrogs\_by\_chain}\NormalTok{(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\end{figure}

Finally because nearly every transition is divergent we can't extract
much information from the divergent-labeled pairs plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{extract\_expectands}\NormalTok{(fit)}

\NormalTok{names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }
           \FunctionTok{sapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{data}\SpecialCharTok{$}\NormalTok{M, }\ControlFlowTok{function}\NormalTok{(m) }\FunctionTok{paste0}\NormalTok{(}\StringTok{\textquotesingle{}beta[\textquotesingle{}}\NormalTok{, m, }\StringTok{\textquotesingle{}]\textquotesingle{}}\NormalTok{)))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_div\_pairs}\NormalTok{(names, names, samples, diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

We can also color the divergent transitions by their numerical
trajectory lengths. On average transitions from shorter numerical
trajectories should be closer to the problematic behavior than
transitions from longer numerical trajectories. Because there are so
many divergent transitions here the point colors overlap and it's hard
to make too much out, but it does look like there may be a problematic
boundary. For example plot of \texttt{beta{[}2{]}} against
\texttt{beta{[}1{]}} is consistent with a boundary defined by \[
\beta_{1} + \beta_{2} = \mathrm{constant}.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_div\_pairs}\NormalTok{(names, names, samples, diagnostics, }\AttributeTok{plot\_mode=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\end{figure}

Having examined the Hamiltonian Monte Carlo diagnostics let's now look
through the expectand specific diagnostics. By default we'll look at the
parameter projection functions as well as all of the expectands defined
in the \texttt{generated\ quantities} block.

Because of the Hamiltonian Monte Carlo diagnostic failures I'm going to
limit the output just in case we have many failures for these
diagnostics as well.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{summarize\_expectand\_diagnostics}\NormalTok{(samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands alpha, beta[1], beta[2], beta[3], p[1], p[2], p[3],
p[4], p[5], p[6], p[7], p[8], p[9], p[10], p[11], p[12], p[13], p[14],
p[15], p[16], p[17], p[18], p[19], p[20], p[21], p[22], p[23], p[24],
p[25], p[26], p[27], p[28], p[29], p[30], p[31], p[32], p[33], p[34],
p[35], p[36], p[37], p[38], p[39], p[40], p[41], p[42], p[43], p[44],
p[45], p[46], p[47], p[48], p[49], p[50], p[51], p[52], p[53], p[54],
p[55], p[56], p[57], p[58], p[59], p[60], p[61], p[62], p[63], p[64],
p[65], p[66], p[67], p[68], p[69], p[70], p[71], p[72], p[73], p[74],
p[75], p[76], p[77], p[78], p[79], p[80], p[81], p[82], p[83], p[84],
p[85], p[86], p[87], p[88], p[89], p[90], p[91], p[92], p[93], p[94],
p[95], p[96], p[97], p[98], p[99], p[100], p[101], p[102], p[103],
p[104], p[105], p[106], p[107], p[108], p[109], p[110], p[111], p[112],
p[113], p[114], p[115], p[116], p[117], p[118], p[119], p[120], p[121],
p[122], p[123], p[124], p[125], p[126], p[127], p[128], p[129], p[130],
p[131], p[132], p[133], p[134], p[135], p[136], p[137], p[138], p[139],
p[140], p[141], p[142], p[143], p[144], p[145], p[146], p[147], p[148],
p[149], p[150], p[151], p[152], p[153], p[154], p[155], p[156], p[157],
p[158], p[159], p[160], p[161], p[162], p[163], p[164], p[165], p[166],
p[167], p[168], p[169], p[170], p[171], p[172], p[173], p[174], p[175],
p[176], p[177], p[178], p[179], p[180], p[181], p[182], p[183], p[184],
p[185], p[186], p[187], p[188], p[189], p[190], p[191], p[192], p[193],
p[194], p[195], p[196], p[197], p[198], p[199], p[200], p[201], p[202],
p[203], p[204], p[205], p[206], p[207], p[208], p[209], p[210], p[211],
p[212], p[213], p[214], p[215], p[216], p[217], p[218], p[219], p[220],
p[221], p[222], p[223], p[224], p[225], p[226], p[227], p[228], p[229],
p[230], p[231], p[232], p[233], p[234], p[235], p[236], p[237], p[238],
p[239], p[240], p[241], p[242], p[243], p[244], p[245], p[246], p[247],
p[248], p[249], p[250], p[251], p[252], p[253], p[254], p[255], p[256],
p[257], p[258], p[259], p[260], p[261], p[262], p[263], p[264], p[265],
p[266], p[267], p[268], p[269], p[270], p[271], p[272], p[273], p[274],
p[275], p[276], p[277], p[278], p[279], p[280], p[281], p[282], p[283],
p[284], p[285], p[286], p[287], p[288], p[289], p[290], p[291], p[292],
p[293], p[294], p[295], p[296], p[297], p[298], p[299], p[300], p[301],
p[302], p[303], p[304], p[305], p[306], p[307], p[308], p[309], p[310],
p[311], p[312], p[313], p[314], p[315], p[316], p[317], p[318], p[319],
p[320], p[321], p[322], p[323], p[324], p[325], p[326], p[327], p[328],
p[329], p[330], p[331], p[332], p[333], p[334], p[335], p[336], p[337],
p[338], p[339], p[340], p[341], p[342], p[343], p[344], p[345], p[346],
p[347], p[348], p[349], p[350], p[351], p[352], p[353], p[354], p[355],
p[356], p[357], p[358], p[359], p[360], p[361], p[362], p[363], p[364],
p[365], p[366], p[367], p[368], p[369], p[370], p[371], p[372], p[373],
p[374], p[375], p[376], p[377], p[378], p[379], p[380], p[381], p[382],
p[383], p[384], p[385], p[386], p[387], p[388], p[389], p[390], p[391],
p[392], p[393], p[394], p[395], p[396], p[397], p[398], p[399], p[400],
p[401], p[402], p[403], p[404], p[405], p[406], p[407], p[408], p[409],
p[410], p[411], p[412], p[413], p[414], p[415], p[416], p[417], p[418],
p[419], p[420], p[421], p[422], p[423], p[424], p[425], p[426], p[427],
p[428], p[429], p[430], p[431], p[432], p[433], p[434], p[435], p[436],
p[437], p[438], p[439], p[440], p[441], p[442], p[443], p[444], p[445],
p[446], p[447], p[448], p[449], p[450], p[451], p[452], p[453], p[454],
p[455], p[456], p[457], p[458], p[459], p[460], p[461], p[462], p[463],
p[464], p[465], p[466], p[467], p[468], p[469], p[470], p[471], p[472],
p[473], p[474], p[475], p[476], p[477], p[478], p[479], p[480], p[481],
p[482], p[483], p[484], p[485], p[486], p[487], p[488], p[489], p[490],
p[491], p[492], p[493], p[494], p[495], p[496], p[497], p[498], p[499],
p[500], p[501], p[502], p[503], p[504], p[505], p[506], p[507], p[508],
p[509], p[510], p[511], p[512], p[513], p[514], p[515], p[516], p[517],
p[518], p[519], p[520], p[521], p[522], p[523], p[524], p[525], p[526],
p[527], p[528], p[529], p[530], p[531], p[532], p[533], p[534], p[535],
p[536], p[537], p[538], p[539], p[540], p[541], p[542], p[543], p[544],
p[545], p[546], p[547], p[548], p[549], p[550], p[551], p[552], p[553],
p[554], p[555], p[556], p[557], p[558], p[559], p[560], p[561], p[562],
p[563], p[564], p[565], p[566], p[567], p[568], p[569], p[570], p[571],
p[572], p[573], p[574], p[575], p[576], p[577], p[578], p[579], p[580],
p[581], p[582], p[583], p[584], p[585], p[586], p[587], p[588], p[589],
p[590], p[591], p[592], p[593], p[594], p[595], p[596], p[597], p[598],
p[599], p[600], p[601], p[602], p[603], p[604], p[605], p[606], p[607],
p[608], p[609], p[610], p[611], p[612], p[613], p[614], p[615], p[616],
p[617], p[618], p[619], p[620], p[621], p[622], p[623], p[624], p[625],
p[626], p[627], p[628], p[629], p[630], p[631], p[632], p[633], p[634],
p[635], p[636], p[637], p[638], p[639], p[640], p[641], p[642], p[643],
p[644], p[645], p[646], p[647], p[648], p[649], p[650], p[651], p[652],
p[653], p[654], p[655], p[656], p[657], p[658], p[659], p[660], p[661],
p[662], p[663], p[664], p[665], p[666], p[667], p[668], p[669], p[670],
p[671], p[672], p[673], p[674], p[675], p[676], p[677], p[678], p[679],
p[680], p[681], p[682], p[683], p[684], p[685], p[686], p[687], p[688],
p[689], p[690], p[691], p[692], p[693], p[694], p[695], p[696], p[697],
p[698], p[699], p[700], p[701], p[702], p[703], p[704], p[705], p[706],
p[707], p[708], p[709], p[710], p[711], p[712], p[713], p[714], p[715],
p[716], p[717], p[718], p[719], p[720], p[721], p[722], p[723], p[724],
p[725], p[726], p[727], p[728], p[729], p[730], p[731], p[732], p[733],
p[734], p[735], p[736], p[737], p[738], p[739], p[740], p[741], p[742],
p[743], p[744], p[745], p[746], p[747], p[748], p[749], p[750], p[751],
p[752], p[753], p[754], p[755], p[756], p[757], p[758], p[759], p[760],
p[761], p[762], p[763], p[764], p[765], p[766], p[767], p[768], p[769],
p[770], p[771], p[772], p[773], p[774], p[775], p[776], p[777], p[778],
p[779], p[780], p[781], p[782], p[783], p[784], p[785], p[786], p[787],
p[788], p[789], p[790], p[791], p[792], p[793], p[794], p[795], p[796],
p[797], p[798], p[799], p[800], p[801], p[802], p[803], p[804], p[805],
p[806], p[807], p[808], p[809], p[810], p[811], p[812], p[813], p[814],
p[815], p[816], p[817], p[818], p[819], p[820], p[821], p[822], p[823],
p[824], p[825], p[826], p[827], p[828], p[829], p[830], p[831], p[832],
p[833], p[834], p[835], p[836], p[837], p[838], p[839], p[840], p[841],
p[842], p[843], p[844], p[845], p[846], p[847], p[848], p[849], p[850],
p[851], p[852], p[853], p[854], p[855], p[856], p[857], p[858], p[859],
p[860], p[861], p[862], p[863], p[864], p[865], p[866], p[867], p[868],
p[869], p[870], p[871], p[872], p[873], p[874], p[875], p[876], p[877],
p[878], p[879], p[880], p[881], p[882], p[883], p[884], p[885], p[886],
p[887], p[888], p[889], p[890], p[891], p[892], p[893], p[894], p[895],
p[896], p[897], p[898], p[899], p[900], p[901], p[902], p[903], p[904],
p[905], p[906], p[907], p[908], p[909], p[910], p[911], p[912], p[913],
p[914], p[915], p[916], p[917], p[918], p[919], p[920], p[921], p[922],
p[923], p[924], p[925], p[926], p[927], p[928], p[929], p[930], p[931],
p[932], p[933], p[934], p[935], p[936], p[937], p[938], p[939], p[940],
p[941], p[942], p[943], p[944], p[945], p[946], p[947], p[948], p[949],
p[950], p[951], p[952], p[953], p[954], p[955], p[956], p[957], p[958],
p[959], p[960], p[961], p[962], p[963], p[964], p[965], p[966], p[967],
p[968], p[969], p[970], p[971], p[972], p[973], p[974], p[975], p[976],
p[977], p[978], p[979], p[980], p[981], p[982], p[983], p[984], p[985],
p[986], p[987], p[988], p[989], p[990], p[991], p[992], p[993], p[994],
p[995], p[996], p[997], p[998], p[999], p[1000], y_pred[1], y_pred[2],
y_pred[3], y_pred[4], y_pred[5], y_pred[6], y_pred[7], y_pred[8],
y_pred[9], y_pred[10], y_pred[11], y_pred[12], y_pred[13], y_pred[14],
y_pred[15], y_pred[16], y_pred[17], y_pred[18], y_pred[19], y_pred[20],
y_pred[21], y_pred[22], y_pred[23], y_pred[24], y_pred[25], y_pred[26],
y_pred[27], y_pred[28], y_pred[29], y_pred[30], y_pred[31], y_pred[32],
y_pred[33], y_pred[34], y_pred[35], y_pred[36], y_pred[37], y_pred[38],
y_pred[39], y_pred[40], y_pred[41], y_pred[42], y_pred[43], y_pred[44],
y_pred[45], y_pred[46], y_pred[47], y_pred[48], y_pred[49], y_pred[50],
y_pred[51], y_pred[52], y_pred[53], y_pred[54], y_pred[55], y_pred[56],
y_pred[57], y_pred[58], y_pred[59], y_pred[60], y_pred[61], y_pred[62],
y_pred[63], y_pred[64], y_pred[65], y_pred[66], y_pred[67], y_pred[68],
y_pred[69], y_pred[70], y_pred[71], y_pred[72], y_pred[73], y_pred[74],
y_pred[75], y_pred[76], y_pred[77], y_pred[78], y_pred[79], y_pred[80],
y_pred[81], y_pred[82], y_pred[83], y_pred[84], y_pred[85], y_pred[86],
y_pred[87], y_pred[88], y_pred[89], y_pred[90], y_pred[91], y_pred[92],
y_pred[93], y_pred[94], y_pred[95], y_pred[96], y_pred[97], y_pred[98],
y_pred[99], y_pred[100], y_pred[101], y_pred[102], y_pred[103],
y_pred[104], y_pred[105], y_pred[106], y_pred[107], y_pred[108],
y_pred[109], y_pred[110], y_pred[111], y_pred[112], y_pred[113],
y_pred[114], y_pred[115], y_pred[116], y_pred[117], y_pred[118],
y_pred[119], y_pred[120], y_pred[121], y_pred[122], y_pred[123],
y_pred[124], y_pred[125], y_pred[126], y_pred[127], y_pred[128],
y_pred[129], y_pred[130], y_pred[131], y_pred[132], y_pred[133],
y_pred[134], y_pred[135], y_pred[136], y_pred[137], y_pred[138],
y_pred[139], y_pred[140], y_pred[141], y_pred[142], y_pred[143],
y_pred[144], y_pred[145], y_pred[146], y_pred[147], y_pred[148],
y_pred[149], y_pred[150], y_pred[151], y_pred[152], y_pred[153],
y_pred[154], y_pred[155], y_pred[156], y_pred[157], y_pred[158],
y_pred[159], y_pred[160], y_pred[161], y_pred[162], y_pred[163],
y_pred[164], y_pred[165], y_pred[166], y_pred[167], y_pred[168],
y_pred[169], y_pred[170], y_pred[171], y_pred[172], y_pred[173],
y_pred[174], y_pred[175], y_pred[176], y_pred[177], y_pred[178],
y_pred[179], y_pred[180], y_pred[181], y_pred[182], y_pred[183],
y_pred[184], y_pred[185], y_pred[186], y_pred[187], y_pred[188],
y_pred[189], y_pred[190], y_pred[191], y_pred[192], y_pred[193],
y_pred[194], y_pred[195], y_pred[196], y_pred[197], y_pred[198],
y_pred[199], y_pred[200], y_pred[201], y_pred[202], y_pred[203],
y_pred[204], y_pred[205], y_pred[206], y_pred[207], y_pred[208],
y_pred[209], y_pred[210], y_pred[211], y_pred[212], y_pred[213],
y_pred[214], y_pred[215], y_pred[216], y_pred[217], y_pred[218],
y_pred[219], y_pred[220], y_pred[221], y_pred[222], y_pred[223],
y_pred[224], y_pred[225], y_pred[226], y_pred[227], y_pred[228],
y_pred[229], y_pred[230], y_pred[231], y_pred[232], y_pred[233],
y_pred[234], y_pred[235], y_pred[236], y_pred[237], y_pred[238],
y_pred[239], y_pred[240], y_pred[241], y_pred[242], y_pred[243],
y_pred[244], y_pred[245], y_pred[246], y_pred[247], y_pred[248],
y_pred[249], y_pred[250], y_pred[251], y_pred[252], y_pred[253],
y_pred[254], y_pred[255], y_pred[256], y_pred[257], y_pred[258],
y_pred[259], y_pred[260], y_pred[261], y_pred[262], y_pred[263],
y_pred[264], y_pred[265], y_pred[266], y_pred[267], y_pred[268],
y_pred[269], y_pred[270], y_pred[271], y_pred[272], y_pred[273],
y_pred[274], y_pred[275], y_pred[276], y_pred[277], y_pred[278],
y_pred[279], y_pred[280], y_pred[281], y_pred[282], y_pred[283],
y_pred[284], y_pred[285], y_pred[286], y_pred[287], y_pred[288],
y_pred[289], y_pred[290], y_pred[291], y_pred[292], y_pred[293],
y_pred[294], y_pred[295], y_pred[296], y_pred[297], y_pred[298],
y_pred[299], y_pred[300], y_pred[301], y_pred[302], y_pred[303],
y_pred[304], y_pred[305], y_pred[306], y_pred[307], y_pred[308],
y_pred[309], y_pred[310], y_pred[311], y_pred[312], y_pred[313],
y_pred[314], y_pred[315], y_pred[316], y_pred[317], y_pred[318],
y_pred[319], y_pred[320], y_pred[321], y_pred[322], y_pred[323],
y_pred[324], y_pred[325], y_pred[326], y_pred[327], y_pred[328],
y_pred[329], y_pred[330], y_pred[331], y_pred[332], y_pred[333],
y_pred[334], y_pred[335], y_pred[336], y_pred[337], y_pred[338],
y_pred[339], y_pred[340], y_pred[341], y_pred[342], y_pred[343],
y_pred[344], y_pred[345], y_pred[346], y_pred[347], y_pred[348],
y_pred[349], y_pred[350], y_pred[351], y_pred[352], y_pred[353],
y_pred[354], y_pred[355], y_pred[356], y_pred[357], y_pred[358],
y_pred[359], y_pred[360], y_pred[361], y_pred[362], y_pred[363],
y_pred[364], y_pred[365], y_pred[366], y_pred[367], y_pred[368],
y_pred[369], y_pred[370], y_pred[371], y_pred[372], y_pred[373],
y_pred[374], y_pred[375], y_pred[376], y_pred[377], y_pred[378],
y_pred[379], y_pred[380], y_pred[381], y_pred[382], y_pred[383],
y_pred[384], y_pred[385], y_pred[386], y_pred[387], y_pred[388],
y_pred[389], y_pred[390], y_pred[391], y_pred[392], y_pred[393],
y_pred[394], y_pred[395], y_pred[396], y_pred[397], y_pred[398],
y_pred[399], y_pred[400], y_pred[401], y_pred[402], y_pred[403],
y_pred[404], y_pred[405], y_pred[406], y_pred[407], y_pred[408],
y_pred[409], y_pred[410], y_pred[411], y_pred[412], y_pred[413],
y_pred[414], y_pred[415], y_pred[416], y_pred[417], y_pred[418],
y_pred[419], y_pred[420], y_pred[421], y_pred[422], y_pred[423],
y_pred[424], y_pred[425], y_pred[426], y_pred[427], y_pred[428],
y_pred[429], y_pred[430], y_pred[431], y_pred[432], y_pred[433],
y_pred[434], y_pred[435], y_pred[436], y_pred[437], y_pred[438],
y_pred[439], y_pred[440], y_pred[441], y_pred[442], y_pred[443],
y_pred[444], y_pred[445], y_pred[446], y_pred[447], y_pred[448],
y_pred[449], y_pred[450], y_pred[451], y_pred[452], y_pred[453],
y_pred[454], y_pred[455], y_pred[456], y_pred[457], y_pred[458],
y_pred[459], y_pred[460], y_pred[461], y_pred[462], y_pred[463],
y_pred[464], y_pred[465], y_pred[466], y_pred[467], y_pred[468],
y_pred[469], y_pred[470], y_pred[471], y_pred[472], y_pred[473],
y_pred[474], y_pred[475], y_pred[476], y_pred[477], y_pred[478],
y_pred[479], y_pred[480], y_pred[481], y_pred[482], y_pred[483],
y_pred[484], y_pred[485], y_pred[486], y_pred[487], y_pred[488],
y_pred[489], y_pred[490], y_pred[491], y_pred[492], y_pred[493],
y_pred[494], y_pred[495], y_pred[496], y_pred[497], y_pred[498],
y_pred[499], y_pred[500], y_pred[501], y_pred[502], y_pred[503],
y_pred[504], y_pred[505], y_pred[506], y_pred[507], y_pred[508],
y_pred[509], y_pred[510], y_pred[511], y_pred[512], y_pred[513],
y_pred[514], y_pred[515], y_pred[516], y_pred[517], y_pred[518],
y_pred[519], y_pred[520], y_pred[521], y_pred[522], y_pred[523],
y_pred[524], y_pred[525], y_pred[526], y_pred[527], y_pred[528],
y_pred[529], y_pred[530], y_pred[531], y_pred[532], y_pred[533],
y_pred[534], y_pred[535], y_pred[536], y_pred[537], y_pred[538],
y_pred[539], y_pred[540], y_pred[541], y_pred[542], y_pred[543],
y_pred[544], y_pred[545], y_pred[546], y_pred[547], y_pred[548],
y_pred[549], y_pred[550], y_pred[551], y_pred[552], y_pred[553],
y_pred[554], y_pred[555], y_pred[556], y_pred[557], y_pred[558],
y_pred[559], y_pred[560], y_pred[561], y_pred[562], y_pred[563],
y_pred[564], y_pred[565], y_pred[566], y_pred[567], y_pred[568],
y_pred[569], y_pred[570], y_pred[571], y_pred[572], y_pred[573],
y_pred[574], y_pred[575], y_pred[576], y_pred[577], y_pred[578],
y_pred[579], y_pred[580], y_pred[581], y_pred[582], y_pred[583],
y_pred[584], y_pred[585], y_pred[586], y_pred[587], y_pred[588],
y_pred[589], y_pred[590], y_pred[591], y_pred[592], y_pred[593],
y_pred[594], y_pred[595], y_pred[596], y_pred[597], y_pred[598],
y_pred[599], y_pred[600], y_pred[601], y_pred[602], y_pred[603],
y_pred[604], y_pred[605], y_pred[606], y_pred[607], y_pred[608],
y_pred[609], y_pred[610], y_pred[611], y_pred[612], y_pred[613],
y_pred[614], y_pred[615], y_pred[616], y_pred[617], y_pred[618],
y_pred[619], y_pred[620], y_pred[621], y_pred[622], y_pred[623],
y_pred[624], y_pred[625], y_pred[626], y_pred[627], y_pred[628],
y_pred[629], y_pred[630], y_pred[631], y_pred[632], y_pred[633],
y_pred[634], y_pred[635], y_pred[636], y_pred[637], y_pred[638],
y_pred[639], y_pred[640], y_pred[641], y_pred[642], y_pred[643],
y_pred[644], y_pred[645], y_pred[646], y_pred[647], y_pred[648],
y_pred[649], y_pred[650], y_pred[651], y_pred[652], y_pred[653],
y_pred[654], y_pred[655], y_pred[656], y_pred[657], y_pred[658],
y_pred[659], y_pred[660], y_pred[661], y_pred[662], y_pred[663],
y_pred[664], y_pred[665], y_pred[666], y_pred[667], y_pred[668],
y_pred[669], y_pred[670], y_pred[671], y_pred[672], y_pred[673],
y_pred[674], y_pred[675], y_pred[676], y_pred[677], y_pred[678],
y_pred[679], y_pred[680], y_pred[681], y_pred[682], y_pred[683],
y_pred[684], y_pred[685], y_pred[686], y_pred[687], y_pred[688],
y_pred[689], y_pred[690], y_pred[691], y_pred[692], y_pred[693],
y_pred[694], y_pred[695], y_pred[696], y_pred[697], y_pred[698],
y_pred[699], y_pred[700], y_pred[701], y_pred[702], y_pred[703],
y_pred[704], y_pred[705], y_pred[706], y_pred[707], y_pred[708],
y_pred[709], y_pred[710], y_pred[711], y_pred[712], y_pred[713],
y_pred[714], y_pred[715], y_pred[716], y_pred[717], y_pred[718],
y_pred[719], y_pred[720], y_pred[721], y_pred[722], y_pred[723],
y_pred[724], y_pred[725], y_pred[726], y_pred[727], y_pred[728],
y_pred[729], y_pred[730], y_pred[731], y_pred[732], y_pred[733],
y_pred[734], y_pred[735], y_pred[736], y_pred[737], y_pred[738],
y_pred[739], y_pred[740], y_pred[741], y_pred[742], y_pred[743],
y_pred[744], y_pred[745], y_pred[746], y_pred[747], y_pred[748],
y_pred[749], y_pred[750], y_pred[751], y_pred[752], y_pred[753],
y_pred[754], y_pred[755], y_pred[756], y_pred[757], y_pred[758],
y_pred[759], y_pred[760], y_pred[761], y_pred[762], y_pred[763],
y_pred[764], y_pred[765], y_pred[766], y_pred[767], y_pred[768],
y_pred[769], y_pred[770], y_pred[771], y_pred[772], y_pred[773],
y_pred[774], y_pred[775], y_pred[776], y_pred[777], y_pred[778],
y_pred[779], y_pred[780], y_pred[781], y_pred[782], y_pred[783],
y_pred[784], y_pred[785], y_pred[786], y_pred[787], y_pred[788],
y_pred[789], y_pred[790], y_pred[791], y_pred[792], y_pred[793],
y_pred[794], y_pred[795], y_pred[796], y_pred[797], y_pred[798],
y_pred[799], y_pred[800], y_pred[801], y_pred[802], y_pred[803],
y_pred[804], y_pred[805], y_pred[806], y_pred[807], y_pred[808],
y_pred[809], y_pred[810], y_pred[811], y_pred[812], y_pred[813],
y_pred[814], y_pred[815], y_pred[816], y_pred[817], y_pred[818],
y_pred[819], y_pred[820], y_pred[821], y_pred[822], y_pred[823],
y_pred[824], y_pred[825], y_pred[826], y_pred[827], y_pred[828],
y_pred[829], y_pred[830], y_pred[831], y_pred[832], y_pred[833],
y_pred[834], y_pred[835], y_pred[836], y_pred[837], y_pred[838],
y_pred[839], y_pred[840], y_pred[841], y_pred[842], y_pred[843],
y_pred[844], y_pred[845], y_pred[846], y_pred[847], y_pred[848],
y_pred[849], y_pred[850], y_pred[851], y_pred[852], y_pred[853],
y_pred[854], y_pred[855], y_pred[856], y_pred[857], y_pred[858],
y_pred[859], y_pred[860], y_pred[861], y_pred[862], y_pred[863],
y_pred[864], y_pred[865], y_pred[866], y_pred[867], y_pred[868],
y_pred[869], y_pred[870], y_pred[871], y_pred[872], y_pred[873],
y_pred[874], y_pred[875], y_pred[876], y_pred[877], y_pred[878],
y_pred[879], y_pred[880], y_pred[881], y_pred[882], y_pred[883],
y_pred[884], y_pred[885], y_pred[886], y_pred[887], y_pred[888],
y_pred[889], y_pred[890], y_pred[891], y_pred[892], y_pred[893],
y_pred[894], y_pred[895], y_pred[896], y_pred[897], y_pred[898],
y_pred[899], y_pred[900], y_pred[901], y_pred[902], y_pred[903],
y_pred[904], y_pred[905], y_pred[906], y_pred[907], y_pred[908],
y_pred[909], y_pred[910], y_pred[911], y_pred[912], y_pred[913],
y_pred[914], y_pred[915], y_pred[916], y_pred[917], y_pred[918],
y_pred[919], y_pred[920], y_pred[921], y_pred[922], y_pred[923],
y_pred[924], y_pred[925], y_pred[926], y_pred[927], y_pred[928],
y_pred[929], y_pred[930], y_pred[931], y_pred[932], y_pred[933],
y_pred[934], y_pred[935], y_pred[936], y_pred[937], y_pred[938],
y_pred[939], y_pred[940], y_pred[941], y_pred[942], y_pred[943],
y_pred[944], y_pred[945], y_pred[946], y_pred[947], y_pred[948],
y_pred[949], y_pred[950], y_pred[951], y_pred[952], y_pred[953],
y_pred[954], y_pred[955], y_pred[956], y_pred[957], y_pred[958],
y_pred[959], y_pred[960], y_pred[961], y_pred[962], y_pred[963],
y_pred[964], y_pred[965], y_pred[966], y_pred[967], y_pred[968],
y_pred[969], y_pred[970], y_pred[971], y_pred[972], y_pred[973],
y_pred[974], y_pred[975], y_pred[976], y_pred[977], y_pred[978],
y_pred[979], y_pred[980], y_pred[981], y_pred[982], y_pred[983],
y_pred[984], y_pred[985], y_pred[986], y_pred[987], y_pred[988],
y_pred[989], y_pred[990], y_pred[991], y_pred[992], y_pred[993],
y_pred[994], y_pred[995], y_pred[996], y_pred[997], y_pred[998],
y_pred[999], y_pred[1000] triggered diagnostic warnings.

The expectands alpha, beta[1], beta[2], beta[3], p[1], p[2], p[3],
p[4], p[5], p[6], p[7], p[8], p[9], p[10], p[11], p[12], p[13], p[14],
p[15], p[16], p[17], p[18], p[19], p[20], p[21], p[22], p[23], p[24],
p[25], p[26], p[27], p[28], p[29], p[30], p[31], p[32], p[33], p[34],
p[35], p[37], p[38], p[39], p[40], p[41], p[42], p[43], p[44], p[45],
p[46], p[47], p[48], p[49], p[50], p[51], p[52], p[53], p[54], p[55],
p[56], p[57], p[58], p[59], p[60], p[61], p[62], p[63], p[64], p[65],
p[66], p[67], p[68], p[69], p[70], p[71], p[72], p[73], p[74], p[75],
p[76], p[77], p[78], p[79], p[80], p[81], p[82], p[83], p[84], p[85],
p[86], p[87], p[88], p[89], p[90], p[91], p[92], p[93], p[94], p[95],
p[96], p[97], p[98], p[99], p[100], p[101], p[102], p[103], p[104],
p[105], p[106], p[107], p[108], p[109], p[111], p[112], p[113], p[114],
p[115], p[116], p[118], p[120], p[121], p[122], p[123], p[124], p[125],
p[126], p[127], p[128], p[129], p[130], p[131], p[132], p[133], p[134],
p[135], p[136], p[137], p[138], p[139], p[140], p[141], p[142], p[143],
p[144], p[145], p[146], p[147], p[148], p[149], p[150], p[151], p[152],
p[153], p[154], p[155], p[156], p[157], p[158], p[159], p[160], p[161],
p[162], p[163], p[164], p[165], p[166], p[167], p[168], p[169], p[170],
p[171], p[172], p[173], p[174], p[175], p[176], p[177], p[179], p[180],
p[181], p[182], p[183], p[184], p[185], p[186], p[187], p[188], p[189],
p[190], p[191], p[192], p[193], p[194], p[195], p[196], p[197], p[198],
p[199], p[200], p[201], p[202], p[203], p[204], p[205], p[206], p[207],
p[208], p[209], p[210], p[211], p[212], p[213], p[214], p[215], p[216],
p[217], p[218], p[219], p[220], p[222], p[223], p[224], p[225], p[226],
p[227], p[228], p[229], p[230], p[231], p[232], p[233], p[234], p[235],
p[236], p[237], p[238], p[239], p[240], p[241], p[242], p[243], p[244],
p[245], p[246], p[248], p[249], p[250], p[251], p[252], p[253], p[254],
p[255], p[256], p[257], p[258], p[259], p[260], p[261], p[263], p[264],
p[265], p[266], p[267], p[268], p[269], p[270], p[271], p[272], p[273],
p[274], p[275], p[276], p[277], p[278], p[279], p[280], p[281], p[282],
p[283], p[284], p[285], p[286], p[287], p[288], p[289], p[290], p[291],
p[292], p[293], p[294], p[295], p[296], p[297], p[298], p[299], p[300],
p[301], p[302], p[303], p[304], p[305], p[306], p[307], p[308], p[309],
p[310], p[311], p[312], p[313], p[314], p[315], p[316], p[317], p[318],
p[319], p[320], p[321], p[322], p[323], p[324], p[325], p[326], p[327],
p[328], p[329], p[330], p[331], p[332], p[333], p[334], p[335], p[336],
p[337], p[338], p[339], p[340], p[341], p[342], p[343], p[344], p[345],
p[346], p[347], p[348], p[349], p[350], p[351], p[352], p[353], p[354],
p[356], p[357], p[358], p[359], p[360], p[361], p[362], p[363], p[364],
p[365], p[366], p[367], p[368], p[369], p[370], p[371], p[372], p[373],
p[374], p[375], p[376], p[377], p[378], p[379], p[380], p[381], p[382],
p[383], p[384], p[385], p[386], p[387], p[388], p[389], p[390], p[391],
p[392], p[393], p[394], p[395], p[396], p[397], p[398], p[399], p[400],
p[401], p[402], p[403], p[404], p[405], p[407], p[408], p[409], p[410],
p[411], p[412], p[413], p[414], p[415], p[416], p[417], p[418], p[419],
p[420], p[421], p[422], p[423], p[424], p[425], p[426], p[427], p[428],
p[429], p[430], p[431], p[432], p[433], p[434], p[435], p[436], p[437],
p[438], p[439], p[440], p[441], p[443], p[444], p[445], p[446], p[447],
p[448], p[449], p[450], p[451], p[452], p[453], p[454], p[455], p[456],
p[457], p[458], p[459], p[460], p[461], p[462], p[463], p[464], p[465],
p[466], p[467], p[468], p[469], p[470], p[471], p[472], p[473], p[474],
p[475], p[476], p[477], p[478], p[479], p[480], p[481], p[482], p[483],
p[484], p[485], p[486], p[487], p[488], p[489], p[490], p[491], p[492],
p[493], p[494], p[495], p[496], p[497], p[498], p[499], p[500], p[501],
p[502], p[503], p[504], p[505], p[506], p[507], p[508], p[509], p[510],
p[511], p[512], p[513], p[514], p[515], p[516], p[517], p[518], p[519],
p[520], p[521], p[522], p[523], p[524], p[525], p[526], p[527], p[528],
p[529], p[530], p[531], p[532], p[533], p[534], p[535], p[536], p[537],
p[539], p[540], p[541], p[542], p[543], p[544], p[545], p[546], p[547],
p[548], p[549], p[550], p[551], p[552], p[553], p[554], p[555], p[556],
p[557], p[558], p[559], p[561], p[562], p[563], p[564], p[565], p[566],
p[567], p[568], p[569], p[570], p[571], p[572], p[573], p[574], p[575],
p[576], p[577], p[578], p[579], p[580], p[581], p[582], p[583], p[584],
p[585], p[586], p[587], p[588], p[589], p[590], p[591], p[592], p[593],
p[594], p[595], p[596], p[597], p[598], p[599], p[600], p[601], p[602],
p[604], p[605], p[606], p[607], p[608], p[609], p[610], p[611], p[612],
p[613], p[614], p[615], p[616], p[617], p[618], p[619], p[620], p[621],
p[622], p[623], p[624], p[625], p[626], p[627], p[628], p[629], p[630],
p[631], p[632], p[633], p[634], p[635], p[636], p[637], p[638], p[639],
p[640], p[641], p[642], p[643], p[644], p[645], p[646], p[647], p[648],
p[649], p[650], p[651], p[652], p[653], p[654], p[655], p[656], p[657],
p[658], p[659], p[660], p[661], p[662], p[663], p[664], p[665], p[666],
p[667], p[668], p[669], p[670], p[671], p[672], p[673], p[674], p[675],
p[676], p[677], p[678], p[679], p[680], p[681], p[682], p[683], p[684],
p[685], p[686], p[687], p[688], p[689], p[690], p[691], p[692], p[693],
p[694], p[695], p[696], p[697], p[698], p[699], p[700], p[701], p[702],
p[703], p[704], p[705], p[706], p[707], p[708], p[709], p[710], p[711],
p[712], p[713], p[714], p[715], p[716], p[717], p[718], p[719], p[720],
p[721], p[722], p[723], p[724], p[725], p[726], p[727], p[728], p[729],
p[730], p[731], p[733], p[734], p[735], p[736], p[737], p[738], p[739],
p[740], p[741], p[742], p[743], p[744], p[745], p[746], p[747], p[748],
p[749], p[750], p[751], p[752], p[753], p[754], p[755], p[756], p[757],
p[758], p[759], p[760], p[761], p[762], p[763], p[764], p[765], p[766],
p[767], p[768], p[769], p[770], p[771], p[772], p[773], p[774], p[775],
p[776], p[777], p[778], p[779], p[780], p[781], p[782], p[783], p[784],
p[785], p[786], p[787], p[788], p[789], p[790], p[791], p[792], p[793],
p[794], p[795], p[796], p[797], p[798], p[799], p[801], p[802], p[803],
p[804], p[805], p[806], p[807], p[808], p[809], p[810], p[811], p[812],
p[813], p[814], p[815], p[816], p[817], p[818], p[819], p[820], p[821],
p[822], p[823], p[824], p[825], p[826], p[827], p[828], p[829], p[830],
p[831], p[832], p[833], p[834], p[835], p[836], p[837], p[838], p[839],
p[840], p[841], p[842], p[843], p[844], p[845], p[846], p[847], p[848],
p[849], p[850], p[852], p[853], p[854], p[855], p[856], p[857], p[858],
p[859], p[860], p[861], p[862], p[863], p[864], p[865], p[866], p[867],
p[868], p[870], p[871], p[872], p[873], p[874], p[875], p[876], p[877],
p[878], p[879], p[880], p[881], p[882], p[883], p[884], p[885], p[886],
p[887], p[888], p[889], p[890], p[891], p[892], p[893], p[894], p[895],
p[896], p[897], p[898], p[899], p[900], p[901], p[902], p[904], p[905],
p[906], p[907], p[908], p[909], p[910], p[911], p[912], p[913], p[914],
p[915], p[916], p[917], p[918], p[919], p[920], p[921], p[922], p[923],
p[924], p[925], p[926], p[927], p[928], p[929], p[930], p[931], p[932],
p[933], p[934], p[935], p[936], p[937], p[938], p[939], p[940], p[941],
p[942], p[943], p[944], p[945], p[946], p[947], p[948], p[949], p[950],
p[951], p[952], p[953], p[954], p[955], p[956], p[957], p[958], p[959],
p[960], p[961], p[962], p[963], p[964], p[965], p[966], p[967], p[968],
p[969], p[970], p[971], p[972], p[973], p[974], p[975], p[976], p[977],
p[978], p[979], p[980], p[981], p[982], p[983], p[984], p[985], p[986],
p[987], p[988], p[989], p[991], p[992], p[993], p[994], p[995], p[996],
p[997], p[998], p[999], p[1000] triggered hat{R} warnings.

Split Rhat larger than 1.1 suggests that at least one of the Markov
chains has not reached an equilibrium.

The expectands alpha, beta[1], beta[2], beta[3], p[1], p[2], p[3],
p[4], p[5], p[6], p[7], p[8], p[9], p[10], p[11], p[12], p[13], p[14],
p[15], p[16], p[17], p[18], p[19], p[20], p[21], p[22], p[23], p[24],
p[25], p[26], p[27], p[28], p[29], p[30], p[31], p[32], p[33], p[34],
p[35], p[36], p[37], p[38], p[39], p[40], p[41], p[42], p[43], p[44],
p[45], p[46], p[47], p[48], p[49], p[50], p[51], p[52], p[53], p[54],
p[55], p[56], p[57], p[58], p[59], p[60], p[61], p[62], p[63], p[64],
p[65], p[66], p[67], p[68], p[69], p[70], p[71], p[72], p[73], p[74],
p[75], p[76], p[77], p[78], p[79], p[80], p[81], p[82], p[83], p[84],
p[85], p[86], p[87], p[88], p[89], p[90], p[91], p[92], p[93], p[94],
p[95], p[96], p[97], p[98], p[99], p[100], p[101], p[102], p[103],
p[104], p[105], p[106], p[107], p[108], p[109], p[110], p[111], p[112],
p[113], p[114], p[115], p[116], p[117], p[118], p[119], p[120], p[121],
p[122], p[123], p[124], p[125], p[126], p[127], p[128], p[129], p[130],
p[131], p[132], p[133], p[134], p[135], p[136], p[137], p[138], p[139],
p[140], p[141], p[142], p[143], p[144], p[145], p[146], p[147], p[148],
p[149], p[150], p[151], p[152], p[153], p[154], p[155], p[156], p[157],
p[158], p[159], p[160], p[161], p[162], p[163], p[164], p[165], p[166],
p[167], p[168], p[169], p[170], p[171], p[172], p[173], p[174], p[175],
p[176], p[177], p[178], p[179], p[180], p[181], p[182], p[183], p[184],
p[185], p[186], p[187], p[188], p[189], p[190], p[191], p[192], p[193],
p[194], p[195], p[196], p[197], p[198], p[199], p[200], p[201], p[202],
p[203], p[204], p[205], p[206], p[207], p[208], p[209], p[210], p[211],
p[212], p[213], p[214], p[215], p[216], p[217], p[218], p[219], p[220],
p[221], p[222], p[223], p[224], p[225], p[226], p[227], p[228], p[229],
p[230], p[231], p[232], p[233], p[234], p[235], p[236], p[237], p[238],
p[239], p[240], p[241], p[242], p[243], p[244], p[245], p[246], p[247],
p[248], p[249], p[250], p[251], p[252], p[253], p[254], p[255], p[256],
p[257], p[258], p[259], p[260], p[261], p[262], p[263], p[264], p[265],
p[266], p[267], p[268], p[269], p[270], p[271], p[272], p[273], p[274],
p[275], p[276], p[277], p[278], p[279], p[280], p[281], p[282], p[283],
p[284], p[285], p[286], p[287], p[288], p[289], p[290], p[291], p[292],
p[293], p[294], p[295], p[296], p[297], p[298], p[299], p[300], p[301],
p[302], p[303], p[304], p[305], p[306], p[307], p[308], p[309], p[310],
p[311], p[312], p[313], p[314], p[315], p[316], p[317], p[318], p[319],
p[320], p[321], p[322], p[323], p[324], p[325], p[326], p[327], p[328],
p[329], p[330], p[331], p[332], p[333], p[334], p[335], p[336], p[337],
p[338], p[339], p[340], p[341], p[342], p[343], p[344], p[345], p[346],
p[347], p[348], p[349], p[350], p[351], p[352], p[353], p[354], p[355],
p[356], p[357], p[358], p[359], p[360], p[361], p[362], p[363], p[364],
p[365], p[366], p[367], p[368], p[369], p[370], p[371], p[372], p[373],
p[374], p[375], p[376], p[377], p[378], p[379], p[380], p[381], p[382],
p[383], p[384], p[385], p[386], p[387], p[388], p[389], p[390], p[391],
p[392], p[393], p[394], p[395], p[396], p[397], p[398], p[399], p[400],
p[401], p[402], p[403], p[404], p[405], p[406], p[407], p[408], p[409],
p[410], p[411], p[412], p[413], p[414], p[415], p[416], p[417], p[418],
p[419], p[420], p[421], p[422], p[423], p[424], p[425], p[426], p[427],
p[428], p[429], p[430], p[431], p[432], p[433], p[434], p[435], p[436],
p[437], p[438], p[439], p[440], p[441], p[442], p[443], p[444], p[445],
p[446], p[447], p[448], p[449], p[450], p[451], p[452], p[453], p[454],
p[455], p[456], p[457], p[458], p[459], p[460], p[461], p[462], p[463],
p[464], p[465], p[466], p[467], p[468], p[469], p[470], p[471], p[472],
p[473], p[474], p[475], p[476], p[477], p[478], p[479], p[480], p[481],
p[482], p[483], p[484], p[485], p[486], p[487], p[488], p[489], p[490],
p[491], p[492], p[493], p[494], p[495], p[496], p[497], p[498], p[499],
p[500], p[501], p[502], p[503], p[504], p[505], p[506], p[507], p[508],
p[509], p[510], p[511], p[512], p[513], p[514], p[515], p[516], p[517],
p[518], p[519], p[520], p[521], p[522], p[523], p[524], p[525], p[526],
p[527], p[528], p[529], p[530], p[531], p[532], p[533], p[534], p[535],
p[536], p[537], p[538], p[539], p[540], p[541], p[542], p[543], p[544],
p[545], p[546], p[547], p[548], p[549], p[550], p[551], p[552], p[553],
p[554], p[555], p[556], p[557], p[558], p[559], p[560], p[561], p[562],
p[563], p[564], p[565], p[566], p[567], p[568], p[569], p[570], p[571],
p[572], p[573], p[574], p[575], p[576], p[577], p[578], p[579], p[580],
p[581], p[582], p[583], p[584], p[585], p[586], p[587], p[588], p[589],
p[590], p[591], p[592], p[593], p[594], p[595], p[596], p[597], p[598],
p[599], p[600], p[601], p[602], p[603], p[604], p[605], p[606], p[607],
p[608], p[609], p[610], p[611], p[612], p[613], p[614], p[615], p[616],
p[617], p[618], p[619], p[620], p[621], p[622], p[623], p[624], p[625],
p[626], p[627], p[628], p[629], p[630], p[631], p[632], p[633], p[634],
p[635], p[636], p[637], p[638], p[639], p[640], p[641], p[642], p[643],
p[644], p[645], p[646], p[647], p[648], p[649], p[650], p[651], p[652],
p[653], p[654], p[655], p[656], p[657], p[658], p[659], p[660], p[661],
p[662], p[663], p[664], p[665], p[666], p[667], p[668], p[669], p[670],
p[671], p[672], p[673], p[674], p[675], p[676], p[677], p[678], p[679],
p[680], p[681], p[682], p[683], p[684], p[685], p[686], p[687], p[688],
p[689], p[690], p[691], p[692], p[693], p[694], p[695], p[696], p[697],
p[698], p[699], p[700], p[701], p[702], p[703], p[704], p[705], p[706],
p[707], p[708], p[709], p[710], p[711], p[712], p[713], p[714], p[715],
p[716], p[717], p[718], p[719], p[720], p[721], p[722], p[723], p[724],
p[725], p[726], p[727], p[728], p[729], p[730], p[731], p[732], p[733],
p[734], p[735], p[736], p[737], p[738], p[739], p[740], p[741], p[742],
p[743], p[744], p[745], p[746], p[747], p[748], p[749], p[750], p[751],
p[752], p[753], p[754], p[755], p[756], p[757], p[758], p[759], p[760],
p[761], p[762], p[763], p[764], p[765], p[766], p[767], p[768], p[769],
p[770], p[771], p[772], p[773], p[774], p[775], p[776], p[777], p[778],
p[779], p[780], p[781], p[782], p[783], p[784], p[785], p[786], p[787],
p[788], p[789], p[790], p[791], p[792], p[793], p[794], p[795], p[796],
p[797], p[798], p[799], p[800], p[801], p[802], p[803], p[804], p[805],
p[806], p[807], p[808], p[809], p[810], p[811], p[812], p[813], p[814],
p[815], p[816], p[817], p[818], p[819], p[820], p[821], p[822], p[823],
p[824], p[825], p[826], p[827], p[828], p[829], p[830], p[831], p[832],
p[833], p[834], p[835], p[836], p[837], p[838], p[839], p[840], p[841],
p[842], p[843], p[844], p[845], p[846], p[847], p[848], p[849], p[850],
p[851], p[852], p[853], p[854], p[855], p[856], p[857], p[858], p[859],
p[860], p[861], p[862], p[863], p[864], p[865], p[866], p[867], p[868],
p[869], p[870], p[871], p[872], p[873], p[874], p[875], p[876], p[877],
p[878], p[879], p[880], p[881], p[882], p[883], p[884], p[885], p[886],
p[887], p[888], p[889], p[890], p[891], p[892], p[893], p[894], p[895],
p[896], p[897], p[898], p[899], p[900], p[901], p[902], p[903], p[904],
p[905], p[906], p[907], p[908], p[909], p[910], p[911], p[912], p[913],
p[914], p[915], p[916], p[917], p[918], p[919], p[920], p[921], p[922],
p[923], p[924], p[925], p[926], p[927], p[928], p[929], p[930], p[931],
p[932], p[933], p[934], p[935], p[936], p[937], p[938], p[939], p[940],
p[941], p[942], p[943], p[944], p[945], p[946], p[947], p[948], p[949],
p[950], p[951], p[952], p[953], p[954], p[955], p[956], p[957], p[958],
p[959], p[960], p[961], p[962], p[963], p[964], p[965], p[966], p[967],
p[968], p[969], p[970], p[971], p[972], p[973], p[974], p[975], p[976],
p[977], p[978], p[979], p[980], p[981], p[982], p[983], p[984], p[985],
p[986], p[987], p[988], p[989], p[990], p[991], p[992], p[993], p[994],
p[995], p[996], p[997], p[998], p[999], p[1000] triggered hat{ESS}
warnings.

Small empirical effective sample sizes indicate strong empirical
autocorrelations in the realized Markov chains. If the empirical
effective sample size is too small then Markov chain Monte Carlo
estimation may be unreliable even when a central limit theorem holds.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clip\_output }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(output, head, tail) \{}
  \ControlFlowTok{for}\NormalTok{(l }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{head)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(output[l], }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{))}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"..........}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"..........}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"..........}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{  N }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(output)}
  \ControlFlowTok{for}\NormalTok{(l }\ControlFlowTok{in}\NormalTok{ (N }\SpecialCharTok{{-}}\NormalTok{ tail)}\SpecialCharTok{:}\NormalTok{N)}
    \FunctionTok{cat}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(output[l], }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{clip\_output}\NormalTok{(}\FunctionTok{capture.output}\NormalTok{(util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(samples)), }
            \DecValTok{27}\NormalTok{, }\DecValTok{21}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
alpha:
  Split hat{R} (1.575) exceeds 1.1!
  Chain 1: hat{ESS} (16.304) is smaller than desired (100)!
  Chain 2: hat{ESS} (16.147) is smaller than desired (100)!
  Chain 3: hat{ESS} (7.943) is smaller than desired (100)!
  Chain 4: hat{ESS} (6.556) is smaller than desired (100)!

beta[1]:
  Split hat{R} (1.428) exceeds 1.1!
  Chain 1: hat{ESS} (6.385) is smaller than desired (100)!
  Chain 2: hat{ESS} (10.338) is smaller than desired (100)!
  Chain 3: hat{ESS} (11.444) is smaller than desired (100)!
  Chain 4: hat{ESS} (12.705) is smaller than desired (100)!

beta[2]:
  Split hat{R} (1.420) exceeds 1.1!
  Chain 1: hat{ESS} (12.499) is smaller than desired (100)!
  Chain 2: hat{ESS} (26.170) is smaller than desired (100)!
  Chain 3: hat{ESS} (5.394) is smaller than desired (100)!
  Chain 4: hat{ESS} (5.913) is smaller than desired (100)!

beta[3]:
  Split hat{R} (1.679) exceeds 1.1!
  Chain 1: hat{ESS} (7.130) is smaller than desired (100)!
  Chain 2: hat{ESS} (5.677) is smaller than desired (100)!
  Chain 3: hat{ESS} (5.136) is smaller than desired (100)!
  Chain 4: hat{ESS} (13.012) is smaller than desired (100)!

..........
..........
..........

  Chain 1: Both left and right hat{xi}s are NaN!
  Chain 2: Both left and right hat{xi}s are NaN!
  Chain 3: Both left and right hat{xi}s are NaN!
  Chain 4: Both left and right hat{xi}s are NaN!

y_pred[1000]:
  Chain 1: Both left and right hat{xi}s are NaN!
  Chain 2: Both left and right hat{xi}s are NaN!
  Chain 3: Both left and right hat{xi}s are NaN!
  Chain 4: Both left and right hat{xi}s are NaN!


Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.

Split Rhat larger than 1.1 suggests that at least one of the Markov
chains has not reached an equilibrium.

Small empirical effective sample sizes indicate strong empirical
autocorrelations in the realized Markov chains. If the empirical
effective sample size is too small then Markov chain Monte Carlo
estimation may be unreliable even when a central limit theorem holds.
\end{verbatim}

Well that output restriction proved to be prescient as most of the
expectands are encountering problems; even this compact summary is
overwhelming. To avoid completely overwhelming ourselves let's focus on
the four parameter expectands.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_samples }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{filter\_expectands}\NormalTok{(samples, }
                                       \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{), }
                                       \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{check\_all\_expectand\_diagnostics}\NormalTok{(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
alpha:
  Split hat{R} (1.575) exceeds 1.1!
  Chain 1: hat{ESS} (16.304) is smaller than desired (100)!
  Chain 2: hat{ESS} (16.147) is smaller than desired (100)!
  Chain 3: hat{ESS} (7.943) is smaller than desired (100)!
  Chain 4: hat{ESS} (6.556) is smaller than desired (100)!

beta[1]:
  Split hat{R} (1.428) exceeds 1.1!
  Chain 1: hat{ESS} (6.385) is smaller than desired (100)!
  Chain 2: hat{ESS} (10.338) is smaller than desired (100)!
  Chain 3: hat{ESS} (11.444) is smaller than desired (100)!
  Chain 4: hat{ESS} (12.705) is smaller than desired (100)!

beta[2]:
  Split hat{R} (1.420) exceeds 1.1!
  Chain 1: hat{ESS} (12.499) is smaller than desired (100)!
  Chain 2: hat{ESS} (26.170) is smaller than desired (100)!
  Chain 3: hat{ESS} (5.394) is smaller than desired (100)!
  Chain 4: hat{ESS} (5.913) is smaller than desired (100)!

beta[3]:
  Split hat{R} (1.679) exceeds 1.1!
  Chain 1: hat{ESS} (7.130) is smaller than desired (100)!
  Chain 2: hat{ESS} (5.677) is smaller than desired (100)!
  Chain 3: hat{ESS} (5.136) is smaller than desired (100)!
  Chain 4: hat{ESS} (13.012) is smaller than desired (100)!


Split Rhat larger than 1.1 suggests that at least one of the Markov
chains has not reached an equilibrium.

Small empirical effective sample sizes indicate strong empirical
autocorrelations in the realized Markov chains. If the empirical
effective sample size is too small then Markov chain Monte Carlo
estimation may be unreliable even when a central limit theorem holds.
\end{verbatim}

All four parameter expectands exhibit split \(\hat{R}\) warnings and low
empirical effective sample size warnings. The question is whether or not
the split \(\hat{R}\) warnings indicate quasistationarity or just
insufficient exploration.

Motivated by the small effective sample size estimates let's look at the
empirical correlograms for each parameter expectand.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_empirical\_correlogram}\NormalTok{(samples[[}\StringTok{"alpha"}\NormalTok{]], }\DecValTok{300}\NormalTok{,}
                                \AttributeTok{rho\_lim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{), }\StringTok{"alpha"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_empirical\_correlogram}\NormalTok{(samples[[}\StringTok{"beta[1]"}\NormalTok{]], }\DecValTok{300}\NormalTok{,}
                                \AttributeTok{rho\_lim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{), }\StringTok{"beta[1]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_empirical\_correlogram}\NormalTok{(samples[[}\StringTok{"beta[2]"}\NormalTok{]], }\DecValTok{300}\NormalTok{,}
                                \AttributeTok{rho\_lim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{), }\StringTok{"beta[2]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_empirical\_correlogram}\NormalTok{(samples[[}\StringTok{"beta[3]"}\NormalTok{]], }\DecValTok{300}\NormalTok{,}
                                \AttributeTok{rho\_lim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{), }\StringTok{"beta[3]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-18-1.pdf}

}

\end{figure}

Regardless of whether or not these Markov chains are stationary they are
extremely autocorrelated. Assuming stationarity we don't start to forget
the beginning of each Markov chain until we've worked through almost all
of the total length, leaving the equivalent of only one independent
sample across each chain.

This is consistent with the constraint violations breaking the coherent,
gradient-driven exploration of Hamiltonian Monte Carlo so that the
Markov chains devolve into diffuse random walks. Indeed looking at the
chain-separated pairs plots we see the spatial color continuity
characteristic of a random walk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_pairs\_by\_chain}\NormalTok{(samples[[}\StringTok{"alpha"}\NormalTok{]], }\StringTok{"alpha"}\NormalTok{, }
\NormalTok{                         samples[[}\StringTok{"beta[2]"}\NormalTok{]], }\StringTok{"beta[2]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-19-1.pdf}

}

\end{figure}

To more quantitatively blame the large split \(\hat{R}\)s on these
strong autocorrelations we can plot the split \(\hat{R}\) from each
expectand against the corresponding empirical effective sample size.
Specifically for each expectand we plot split \(\hat{R}\) against the
smallest empirical effective sample size amongst the four Markov chains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rhats }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_split\_rhats}\NormalTok{(samples)}
\NormalTok{min\_eesss }\OtherTok{\textless{}{-}}\NormalTok{ util}\SpecialCharTok{$}\FunctionTok{compute\_min\_eesss}\NormalTok{(samples)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(rhats, min\_eesss,}
     \AttributeTok{col=}\NormalTok{c\_dark, }\AttributeTok{pch=}\DecValTok{16}\NormalTok{, }\AttributeTok{cex=}\FloatTok{0.8}\NormalTok{,}
     \AttributeTok{xlab=}\StringTok{"Split Rhat"}\NormalTok{, }\AttributeTok{xlim=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.95}\NormalTok{, }\DecValTok{2}\NormalTok{),}
     \AttributeTok{ylab=}\StringTok{"Empirical Effective}\SpecialCharTok{\textbackslash{}n}\StringTok{Sample Size"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{60}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-20-1.pdf}

}

\end{figure}

Every expectand with a large split \(\hat{R}\)s also exhibits a
particularly small minimum empirical effective sample size, confirming
that the latter are likely due to our Markov chains not containing
enough information.

If we are sloppy, ignore these diagnostics, and assume that all of our
Markov chain Monte Carlo estimators are accurate then we are quickly
mislead about the actual behavior of the posterior distribution. One way
to guard against this sloppiness is to always accompany a Markov chain
Monte Carlo estimator with an estimated error. Even if that error is
inaccurate it can sometimes communicate underlying problems.

For example let's look at a pushforward histogram for each parameter
with light gray bands visualizing the standard error around the bin
probability estimates in dark red.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"alpha"}\NormalTok{]], }\DecValTok{25}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"alpha"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[1]"}\NormalTok{]], }\DecValTok{25}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[1]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[2]"}\NormalTok{]], }\DecValTok{25}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[2]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[3]"}\NormalTok{]], }\DecValTok{25}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[3]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-21-1.pdf}

}

\end{figure}

If we look at the central estimates alone we might convince ourselves of
all kinds of interesting structure. For example potential multi-modality
in \texttt{alpha} and \texttt{beta{[}2{]}} and platykurticity in
\texttt{beta{[}1{]}} and \texttt{beta{[}3{]}}. These structures,
however, are all within the scope of the relatively large standard error
bands which suggests that they are all consistent with estimator noise.

Reducing the number of bins decreases the relative standard errors but
at the same time many of the visual artifacts recede.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{mar =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"alpha"}\NormalTok{]], }\DecValTok{10}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"alpha"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[1]"}\NormalTok{]], }\DecValTok{10}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[1]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[2]"}\NormalTok{]], }\DecValTok{10}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[2]"}\NormalTok{)}
\NormalTok{util}\SpecialCharTok{$}\FunctionTok{plot\_expectand\_pushforward}\NormalTok{(samples[[}\StringTok{"beta[3]"}\NormalTok{]], }\DecValTok{10}\NormalTok{, }
                                \AttributeTok{display\_name=}\StringTok{"beta[3]"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{mcmc_diagnostics_rstan_files/figure-pdf/unnamed-chunk-22-1.pdf}

}

\end{figure}

When the bin indicator functions enjoy Markov chain Monte Carlo central
limit theorems these standard error bands allow us to discriminate
between meaningful structure and accidental artifacts regardless of the
histogram binning. Even if central limit theorems don't hold the error
bands provide one more way that we can potentially diagnose
untrustworthy computation.

\hypertarget{license}{%
\section*{License}\label{license}}
\addcontentsline{toc}{section}{License}

The code in this case study is copyrighted by Michael Betancourt and
licensed under the new BSD (3-clause) license:

https://opensource.org/licenses/BSD-3-Clause

The text and figures in this case study are copyrighted by Michael
Betancourt and licensed under the CC BY-NC 4.0 license:

https://creativecommons.org/licenses/by-nc/4.0/

\hypertarget{original-computing-environment}{%
\section*{Original Computing
Environment}\label{original-computing-environment}}
\addcontentsline{toc}{section}{Original Computing Environment}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{writeLines}\NormalTok{(}\FunctionTok{readLines}\NormalTok{(}\FunctionTok{file.path}\NormalTok{(}\FunctionTok{Sys.getenv}\NormalTok{(}\StringTok{"HOME"}\NormalTok{), }\StringTok{".R/Makevars"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
CC=clang

CXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration
CXX=clang++ -arch x86_64 -ftemplate-depth-256

CXX14FLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function -Wno-macro-redefined -Wno-unneeded-internal-declaration -Wno-unknown-pragmas
CXX14=clang++ -arch x86_64 -ftemplate-depth-256
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
R version 4.3.2 (2023-10-31)
Platform: x86_64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.2

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Vancouver
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] colormap_0.1.4      rstan_2.32.3        StanHeaders_2.26.28

loaded via a namespace (and not attached):
 [1] gtable_0.3.4       jsonlite_1.8.8     compiler_4.3.2     Rcpp_1.0.11       
 [5] stringr_1.5.1      parallel_4.3.2     gridExtra_2.3      scales_1.3.0      
 [9] yaml_2.3.8         fastmap_1.1.1      ggplot2_3.4.4      R6_2.5.1          
[13] curl_5.2.0         knitr_1.45         tibble_3.2.1       munsell_0.5.0     
[17] pillar_1.9.0       rlang_1.1.2        utf8_1.2.4         V8_4.4.1          
[21] stringi_1.8.3      inline_0.3.19      xfun_0.41          RcppParallel_5.1.7
[25] cli_3.6.2          magrittr_2.0.3     digest_0.6.33      grid_4.3.2        
[29] lifecycle_1.0.4    vctrs_0.6.5        evaluate_0.23      glue_1.6.2        
[33] QuickJSR_1.0.8     codetools_0.2-19   stats4_4.3.2       pkgbuild_1.4.3    
[37] fansi_1.0.6        colorspace_2.1-0   rmarkdown_2.25     matrixStats_1.2.0 
[41] tools_4.3.2        loo_2.6.0          pkgconfig_2.0.3    htmltools_0.5.7   
\end{verbatim}



\end{document}
