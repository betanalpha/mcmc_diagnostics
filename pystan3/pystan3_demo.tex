% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Stan

Program}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Markov Chain Monte Carlo Diagnostics},
  pdfauthor={Michael Betancourt},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Markov Chain Monte Carlo Diagnostics}
\author{Michael Betancourt}
\date{2023-01-01}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}
In this short note I will preview the new suite of Markov chain Monte
Carlo analysis tools that I will be introducing more formally in
upcoming writing. These tools largely focus on diagnostics but there are
also a few that cover Markov chain Monte Carlo estimation assuming a
central limit theorem.

We'll start with diagnostics specific to Hamiltonian Monte Carlo then
consider more generic diagnostics that consider each expectand of
interest one at a time. Finally we'll look at a way to visualize
one-dimensional pushforward distributions using Markov chain Monte Carlo
to estimate bin probabilities.

\section{Extraction}\label{extraction}

Starting in version 3 \texttt{PyStan} stores all outputs, including the
Markov chain Monte Carlo samples and diagnostics, together in a single
array that can be accessed from the \texttt{\_draws} member of a
\texttt{StanFit} object. The variable names are stored separately in
various \texttt{*\_param\_names} member variables. The raw output from
each Markov chain is also saved in a binary format that can be accessed
with the \texttt{stan\_outputs} member variable.

To facilitate the analysis of Stan output I've included my own custom
extract functions that format the sample and diagnostic outputs into
dictionaries, with one key for each expectand or Hamiltonian Monte Carlo
diagnostic. The elements themselves are two-dimensional arrays with the
first index denoting the individual Markov chains and the second index
denoting the iterations within an individual Markov chain.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract unpermuted expectand values from a StanFit object and format}
\CommentTok{\# them for convenient access}
\CommentTok{\# @param stan\_fit A StanFit object}
\CommentTok{\# @return A dictionary of two{-}dimensional arrays for each expectand in}
\CommentTok{\#         the StanFit object.  The first dimension of each element}
\CommentTok{\#         indexes the Markov chains and the second dimension indexes the}
\CommentTok{\#         sequential states within each Markov chain.}
\KeywordTok{def}\NormalTok{ extract\_expectand\_vals(stan\_fit):}
\NormalTok{  nom\_params }\OperatorTok{=}\NormalTok{ stan\_fit.\_draws}
\NormalTok{  offset }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(stan\_fit.sample\_and\_sampler\_param\_names)}
  
\NormalTok{  base\_names }\OperatorTok{=}\NormalTok{ stan\_fit.constrained\_param\_names}
\NormalTok{  formatted\_names }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ base\_name }\KeywordTok{in}\NormalTok{ base\_names:}
\NormalTok{    name }\OperatorTok{=}\NormalTok{ re.sub(}\StringTok{\textquotesingle{}\textbackslash{}.\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}[\textquotesingle{}}\NormalTok{, base\_name, count}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{    name }\OperatorTok{=}\NormalTok{ re.sub(}\StringTok{\textquotesingle{}\textbackslash{}.\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{, name)}
    \ControlFlowTok{if} \StringTok{\textquotesingle{}[\textquotesingle{}} \KeywordTok{in}\NormalTok{ name:}
\NormalTok{      name }\OperatorTok{+=} \StringTok{\textquotesingle{}]\textquotesingle{}}
\NormalTok{    formatted\_names.append(name)}

\NormalTok{  params }\OperatorTok{=}\NormalTok{ \{ name: numpy.transpose(nom\_params[k }\OperatorTok{+}\NormalTok{ offset,:,:])}
             \ControlFlowTok{for}\NormalTok{ k, name }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(formatted\_names) \}}
  \ControlFlowTok{return}\NormalTok{ params}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract Hamiltonian Monte Carlo diagnostics values from a StanFit}
\CommentTok{\# object and format them for convenient access}
\CommentTok{\# @param stan\_fit A StanFit object}
\CommentTok{\# @return A dictionary of two{-}dimensional arrays for each expectand in}
\CommentTok{\#         the StanFit object.  The first dimension of each element}
\CommentTok{\#         indexes the Markov chains and the second dimension indexes the}
\CommentTok{\#         sequential states within each Markov chain.}
\KeywordTok{def}\NormalTok{ extract\_hmc\_diagnostics(stan\_fit):}
\NormalTok{  d\_names }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}treedepth\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{,}
             \StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}energy\_\_\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{ ]}
  \ControlFlowTok{for}\NormalTok{ dn }\KeywordTok{in}\NormalTok{ d\_names:}
    \ControlFlowTok{if}\NormalTok{ dn }\KeywordTok{not} \KeywordTok{in}\NormalTok{ stan\_fit.sample\_and\_sampler\_param\_names:}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Diagnostic variable }\SpecialCharTok{\{}\NormalTok{dn}\SpecialCharTok{\}}\SpecialStringTok{ not found in stan\_fit.\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{return}

\NormalTok{  d\_idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ dn }\KeywordTok{in}\NormalTok{ d\_names}
             \ControlFlowTok{for}\NormalTok{ idx, sn}
             \KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(stan\_fit.sample\_and\_sampler\_param\_names)}
             \ControlFlowTok{if}\NormalTok{ sn }\OperatorTok{==}\NormalTok{ dn ]}
  
\NormalTok{  params }\OperatorTok{=}\NormalTok{ \{ name: numpy.transpose(stan\_fit.\_draws[idx,:,:])}
           \ControlFlowTok{for}\NormalTok{ idx, name }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(d\_idxs, d\_names) \}}
  \ControlFlowTok{return}\NormalTok{ params}
\end{Highlighting}
\end{Shaded}

If users are able to modify these functions to accept the output from
other interfaces to Stan and return the same output format then all of
the following functions will be immediately available. That is all
except for the \texttt{plot\_inv\_metric} function which does require a
separate function for extracting adaptation information.

\section{Hamiltonian Monte Carlo
Diagnostics}\label{hamiltonian-monte-carlo-diagnostics}

Hamiltonian Monte Carlo introduces a suite of powerful diagnostics that
can identify obstructions to Markov chain Monte Carlo central limit
theorems. These diagnostics are not only extremely sensitive but also
probe the behavior of the entire Markov chain state instead of the
projections of that state through single expectands.

\subsection{Check Hamiltonian Monte Carlo
Diagnostics}\label{check-hamiltonian-monte-carlo-diagnostics}

All of our diagnostics are assembled in this single
\texttt{check\_all\_hmc\_diagnostics} function.

The first diagnostic looks for unstable numerical Hamiltonian
trajectories, or divergences. These unstable trajectories are known to
obstruct typical central limit theorem conditions. Divergences arise
when the target distribution is compressed into a narrow region; this
forces the Hamiltonian dynamics to accelerate which makes them more
difficult to accurately simulate.

Increasing \texttt{delta} will on average result in a less aggressive
step size optimization that in some cases may improve the stability of
the numerical integration but at the cost of longer, and hence more
expensive, numerical Hamiltonian trajectories. In most cases, however,
the only productive way to avoid divergences is to reparameterize the
ambient space to decompress these pinches in the target distribution.

Stan's Hamiltonian Monte Carlo sampler expands the length of the
numerical Hamiltonian trajectories dynamically to maximize the
efficiency of the exploration. That length, however, is capped at
\(2^{\text{max\_treedepth}}\) steps to prevent trajectories from growing
without bound.

When numerical Hamiltonian trajectories are long but finite this
truncation will limit the computational efficiency. Increasing
\texttt{max\_treedepth} allow the trajectories to expand further. While
the resulting trajectories will be more expensive that added cost will
be more than made up for by increased computational efficiency.

The energy fraction of missing information, or E-FMI, quantifies how
well the Hamiltonian dynamics are able to explore the target
distribution. If the E-FMI is too small then even the exact Hamiltonian
trajectories will be limited to confined regions of the ambient space
and full exploration will be possible only with the momenta resampling
between trajectories. In this case the Markov chain exploration devolves
into less efficient, diffusive behavior where Markov chain Monte Carlo
estimation is fragile at best.

This confinement is caused by certain geometries in the target
distribution, most commonly a funnel geometry where some subset of
parameters shrink together as another parameter ranges across its
typical values. The only way to avoid these problems is to identify the
problematic geometry and then find a reparameterization of the ambient
space that transforms the geometry into something more pleasant.

Finally the average proxy accept statistic is a summary for Stan's step
size adaptation. During warmup the integrator step size is dynamically
tuned until this statistic achieves the target value which defaults to
\(0.801\). Because this adaptation is stochastic the realized average
during the main sampling phase can often vary between \(0.75\) and
\(0.85\).

So long as the target distribution is sufficiently well-behaved then the
adaptation should always converge to that target, at least for long
enough warmup periods. Small averages indicate some obstruction to the
adaptation, for example discontinuities in the target distribution or
inaccurate gradient evaluations.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check all Hamiltonian Monte Carlo Diagnostics}
\CommentTok{\# for an ensemble of Markov chains}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\CommentTok{\# @param adapt\_target Target acceptance proxy statistic for step size}
\CommentTok{\#                     adaptation.}
\CommentTok{\# @param max\_treedepth The maximum numerical trajectory treedepth}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_all\_hmc\_diagnostics(diagnostics,}
\NormalTok{                              adapt\_target}\OperatorTok{=}\FloatTok{0.801}\NormalTok{,}
\NormalTok{                              max\_treedepth}\OperatorTok{=}\DecValTok{10}\NormalTok{,}
\NormalTok{                              max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check all Hamiltonian Monte Carlo diagnostics for an}
\CommentTok{     ensemble of Markov chains"""}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_divergence\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_treedepth\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_efmi\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_accept\_warning }\OperatorTok{=} \VariableTok{True}
  
\NormalTok{  messages }\OperatorTok{=}\NormalTok{ []}
  
\NormalTok{  C }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{].shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{].shape[}\DecValTok{1}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    local\_messages }\OperatorTok{=}\NormalTok{ []}
    
    \CommentTok{\# Check for divergences}
\NormalTok{    n\_div }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(diagnostics[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{][c])}
    
    \ControlFlowTok{if}\NormalTok{ n\_div }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      no\_divergence\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      local\_messages.append(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{n\_div}\SpecialCharTok{:.0f\}}\SpecialStringTok{ of }\SpecialCharTok{\{}\NormalTok{S}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
                            \SpecialStringTok{f\textquotesingle{}transitions (}\SpecialCharTok{\{}\NormalTok{n\_div }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{) diverged.\textquotesingle{}}\NormalTok{)}
    
    \CommentTok{\# Check for tree depth saturation}
\NormalTok{    n\_tds }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{([ td }\OperatorTok{\textgreater{}=}\NormalTok{ max\_treedepth }
                  \ControlFlowTok{for}\NormalTok{ td }\KeywordTok{in}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}treedepth\_\_\textquotesingle{}}\NormalTok{][c] ])}
    
    \ControlFlowTok{if}\NormalTok{ n\_tds }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      no\_treedepth\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      local\_messages.append(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{n\_tds}\SpecialCharTok{:.0f\}}\SpecialStringTok{ of }\SpecialCharTok{\{}\NormalTok{S}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
                            \SpecialStringTok{f\textquotesingle{}transitions (}\SpecialCharTok{\{}\NormalTok{n\_tds }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{) saturated \textquotesingle{}}
                            \SpecialStringTok{f\textquotesingle{}the maximum treedepth of }\SpecialCharTok{\{}\NormalTok{max\_treedepth}\SpecialCharTok{\}}\SpecialStringTok{.\textquotesingle{}}\NormalTok{)}
    
    \CommentTok{\# Check the energy fraction of missing information (E{-}FMI)}
\NormalTok{    energies }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}energy\_\_\textquotesingle{}}\NormalTok{][c]}
\NormalTok{    numer }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{( [ (energies[i] }\OperatorTok{{-}}\NormalTok{ energies[i }\OperatorTok{{-}} \DecValTok{1}\NormalTok{])}\OperatorTok{**}\DecValTok{2} 
                   \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(energies)) ] ) }\OperatorTok{/}\NormalTok{ S}
\NormalTok{    denom }\OperatorTok{=}\NormalTok{ numpy.var(energies)}
    \ControlFlowTok{if}\NormalTok{ numer }\OperatorTok{/}\NormalTok{ denom }\OperatorTok{\textless{}} \FloatTok{0.2}\NormalTok{:}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      no\_efmi\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      local\_messages.append(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: \textquotesingle{}}
                            \SpecialStringTok{f\textquotesingle{}E{-}FMI = }\SpecialCharTok{\{}\NormalTok{numer }\OperatorTok{/}\NormalTok{ denom}\SpecialCharTok{:.3f\}}\SpecialStringTok{.\textquotesingle{}}\NormalTok{)}
    
    \CommentTok{\# Check convergence of the stepsize adaptation}
\NormalTok{    ave\_accept\_proxy }\OperatorTok{=}\NormalTok{ numpy.mean(diagnostics[}\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{][c])}
    \ControlFlowTok{if}\NormalTok{ ave\_accept\_proxy }\OperatorTok{\textless{}} \FloatTok{0.9} \OperatorTok{*}\NormalTok{ adapt\_target:}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      no\_accept\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      local\_message }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Average proxy acceptance \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}statistic (}\SpecialCharTok{\{}\NormalTok{ave\_accept\_proxy}\SpecialCharTok{:.3f\}}\SpecialStringTok{) is smaller \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}than 90\% of the target (}\SpecialCharTok{\{}\NormalTok{adapt\_target}\SpecialCharTok{:.3f\}}\SpecialStringTok{).\textquotesingle{}}\NormalTok{)}
\NormalTok{      local\_message }\OperatorTok{=}\NormalTok{ textwrap.wrap(local\_message, max\_width)}
\NormalTok{      local\_messages }\OperatorTok{+=}\NormalTok{ local\_message}
    
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(local\_messages) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      messages.append(local\_messages)}
\NormalTok{      messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \ControlFlowTok{if}\NormalTok{ no\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}All Hamiltonian Monte Carlo diagnostics are consistent \textquotesingle{}}
            \StringTok{\textquotesingle{}with accurate Markov chain Monte Carlo.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    messages.append(desc)}
\NormalTok{    messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_divergence\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Divergent Hamiltonian transitions result from \textquotesingle{}}
            \StringTok{\textquotesingle{}unstable numerical trajectories.  These \textquotesingle{}}
            \StringTok{\textquotesingle{}instabilities are often due to degenerate target \textquotesingle{}}
            \StringTok{\textquotesingle{}geometry, especially "pinches".  If there are \textquotesingle{}}
            \StringTok{\textquotesingle{}only a small number of divergences then running \textquotesingle{}}
            \StringTok{\textquotesingle{}with adept\_delta larger \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}than }\SpecialCharTok{\{}\NormalTok{adapt\_target}\SpecialCharTok{:.3f\}}\SpecialStringTok{ may reduce the \textquotesingle{}}
            \StringTok{\textquotesingle{}instabilities at the cost of more expensive \textquotesingle{}}
            \StringTok{\textquotesingle{}Hamiltonian transitions.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    messages.append(desc)}
\NormalTok{    messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_treedepth\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Numerical trajectories that saturate the \textquotesingle{}}
            \StringTok{\textquotesingle{}maximum treedepth have terminated prematurely.  \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}Increasing max\_depth above }\SpecialCharTok{\{}\NormalTok{max\_treedepth}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
            \StringTok{\textquotesingle{}should result in more expensive, but more \textquotesingle{}}
            \StringTok{\textquotesingle{}efficient, Hamiltonian transitions.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    messages.append(desc)}
\NormalTok{    messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_efmi\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}E{-}FMI below 0.2 arise when a funnel{-}like geometry \textquotesingle{}}
            \StringTok{\textquotesingle{}obstructs how effectively Hamiltonian trajectories \textquotesingle{}}
            \StringTok{\textquotesingle{}can explore the target distribution.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    messages.append(desc)}
\NormalTok{    messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_accept\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}A small average proxy acceptance statistic \textquotesingle{}}
            \StringTok{\textquotesingle{}indicates that the adaptation of the numerical \textquotesingle{}}
            \StringTok{\textquotesingle{}integrator step size failed to converge.  This is \textquotesingle{}}
            \StringTok{\textquotesingle{}often due to discontinuous or imprecise \textquotesingle{}}
            \StringTok{\textquotesingle{}gradients.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    messages.append(desc)}
\NormalTok{    messages.append([}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{])}
  
  \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join([ }\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(m) }\ControlFlowTok{for}\NormalTok{ m }\KeywordTok{in}\NormalTok{ messages ]))}
\end{Highlighting}
\end{Shaded}

\subsection{Integrator Inverse Metric
Elements}\label{integrator-inverse-metric-elements}

Diagnostic failures indicate the presence of problems but only hint at
the nature of those problems. In order to resolve the underlying
problems we need to investigate them beyond these hints. Fortunately
Hamiltonian Monte Carlo provides a wealth of additional information that
can assist.

First we can look at the inverse metric adaptation in each of the Markov
chains. Inconsistencies in the adapted inverse metric elements across
the Markov chains are due to the individual chains encountering
different behaviors during warmup.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot outcome of inverse metric adaptation}
\CommentTok{\# @param stan\_fit A StanFit object}
\CommentTok{\# @params B The number of bins for the inverse metric element histograms.}
\KeywordTok{def}\NormalTok{ plot\_inv\_metric(stan\_fit, B}\OperatorTok{=}\DecValTok{25}\NormalTok{):}
  \CommentTok{"""Plot outcome of inverse metric adaptation"""}
  
\NormalTok{  C }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(stan\_fit.stan\_outputs)}
\NormalTok{  stepsize\_header }\OperatorTok{=} \StringTok{b\textquotesingle{}["Adaptation terminated"]\}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}
\NormalTok{  inv\_metric\_header }\OperatorTok{=} \StringTok{b\textquotesingle{}["Diagonal elements of inverse mass matrix:"]\}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}
  
\NormalTok{  stepsizes }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  inv\_metric\_elems }\OperatorTok{=}\NormalTok{ []}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    first\_split }\OperatorTok{=}\NormalTok{ stan\_fit.stan\_outputs[c].partition(stepsize\_header)[}\DecValTok{2}\NormalTok{]}
\NormalTok{    stepsize\_info }\OperatorTok{=}\NormalTok{ first\_split.partition(}\StringTok{b\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)[}\DecValTok{0}\NormalTok{]}
\NormalTok{    stepsizes.append(}\BuiltInTok{float}\NormalTok{(}\BuiltInTok{eval}\NormalTok{(stepsize\_info)[}\StringTok{\textquotesingle{}values\textquotesingle{}}\NormalTok{][}\DecValTok{0}\NormalTok{].split(}\StringTok{\textquotesingle{} = \textquotesingle{}}\NormalTok{)[}\DecValTok{1}\NormalTok{]))}

\NormalTok{    first\_split }\OperatorTok{=}\NormalTok{ stan\_fit.stan\_outputs[c].partition(inv\_metric\_header)[}\DecValTok{2}\NormalTok{]}
\NormalTok{    inv\_metric\_str }\OperatorTok{=}\NormalTok{ first\_split.partition(}\StringTok{b\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)[}\DecValTok{0}\NormalTok{]}
\NormalTok{    inv\_metric\_dict }\OperatorTok{=} \BuiltInTok{eval}\NormalTok{(inv\_metric\_str)[}\StringTok{\textquotesingle{}values\textquotesingle{}}\NormalTok{][}\DecValTok{0}\NormalTok{].split(}\StringTok{\textquotesingle{}, \textquotesingle{}}\NormalTok{)}
\NormalTok{    inv\_metric\_elems.append([ }\BuiltInTok{float}\NormalTok{(x) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ inv\_metric\_dict ])}

\NormalTok{  min\_elem }\OperatorTok{=} \BuiltInTok{min}\NormalTok{([ }\BuiltInTok{min}\NormalTok{(a) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ inv\_metric\_elems ])}
\NormalTok{  max\_elem }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(a) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ inv\_metric\_elems ])}
  
\NormalTok{  delta }\OperatorTok{=}\NormalTok{ (max\_elem }\OperatorTok{{-}}\NormalTok{ min\_elem) }\OperatorTok{/}\NormalTok{ B}
\NormalTok{  min\_elem }\OperatorTok{=}\NormalTok{ min\_elem }\OperatorTok{{-}}\NormalTok{ delta}
\NormalTok{  max\_elem }\OperatorTok{=}\NormalTok{ max\_elem }\OperatorTok{+}\NormalTok{ delta}
\NormalTok{  bins }\OperatorTok{=}\NormalTok{ numpy.arange(min\_elem, max\_elem }\OperatorTok{+}\NormalTok{ delta, delta)}
\NormalTok{  B }\OperatorTok{=}\NormalTok{ B }\OperatorTok{+} \DecValTok{2}
  
\NormalTok{  max\_y }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(numpy.histogram(a, bins}\OperatorTok{=}\NormalTok{bins)[}\DecValTok{0}\NormalTok{])}
                \ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ inv\_metric\_elems ])}
  
\NormalTok{  idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(B) }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
\NormalTok{  xs }\OperatorTok{=}\NormalTok{ [ bins[idx }\OperatorTok{+}\NormalTok{ delta] }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(B) }\ControlFlowTok{for}\NormalTok{ delta }\KeywordTok{in}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]]}
  
\NormalTok{  N\_plots }\OperatorTok{=}\NormalTok{ C}
\NormalTok{  N\_cols }\OperatorTok{=} \DecValTok{2}
\NormalTok{  N\_rows }\OperatorTok{=}\NormalTok{ math.ceil(N\_plots }\OperatorTok{/}\NormalTok{ N\_cols)}
\NormalTok{  f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(N\_rows, N\_cols, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}
\NormalTok{  k }\OperatorTok{=} \DecValTok{0}
  
\NormalTok{  sci\_formatter }\OperatorTok{=}\NormalTok{ matplotlib.ticker.FuncFormatter(}\KeywordTok{lambda}\NormalTok{ x,}
\NormalTok{                                                  lim: }\SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{x}\SpecialCharTok{:.1e\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    counts }\OperatorTok{=}\NormalTok{ numpy.histogram(inv\_metric\_elems[c], bins}\OperatorTok{=}\NormalTok{bins)[}\DecValTok{0}\NormalTok{]}
\NormalTok{    ys }\OperatorTok{=}\NormalTok{ counts[idxs]}
  
\NormalTok{    idx1 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{//}\NormalTok{ N\_cols}
\NormalTok{    idx2 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{\%}\NormalTok{ N\_cols}
\NormalTok{    k }\OperatorTok{+=} \DecValTok{1}
  
\NormalTok{    axarr[idx1, idx2].plot(xs, ys, dark)}
\NormalTok{    axarr[idx1, idx2].set\_title(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{(Stepsize\textquotesingle{}}
                                \SpecialStringTok{f\textquotesingle{} = }\SpecialCharTok{\{}\NormalTok{stepsizes[c]}\SpecialCharTok{:.3e\}}\SpecialStringTok{)\textquotesingle{}}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_xlabel(}\StringTok{"Inverse Metric Elements"}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_xlim([min\_elem, max\_elem])}
\NormalTok{    axarr[idx1, idx2].get\_xaxis().set\_major\_formatter(sci\_formatter)}
\NormalTok{    axarr[idx1, idx2].set\_ylabel(}\StringTok{""}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].get\_yaxis().set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_ylim([}\DecValTok{0}\NormalTok{, }\FloatTok{1.05} \OperatorTok{*}\NormalTok{ max\_y])}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"left"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
  
\NormalTok{  plot.show()}
\end{Highlighting}
\end{Shaded}

Note that the adaptation information may be accessed differently in
other Stan interfaces, in which case this function would have to be
modified accordingly.

\subsection{Integrator Step Sizes}\label{integrator-step-sizes}

The other product of Stan's adaptation is the step size of the numerical
integrator used to build the numerical Hamiltonian trajectories. As with
the inverse metric elements heterogeneity in the adapted values across
the Markov chains indicates that the Markov chains encountered
substantially different behavior during warmup.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display adapted symplectic integrator step sizes}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\KeywordTok{def}\NormalTok{ display\_stepsizes(diagnostics):}
  \CommentTok{"""Display adapted symplectic integrator step sizes"""}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

\NormalTok{  stepsizes }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{]}
\NormalTok{  C }\OperatorTok{=}\NormalTok{ stepsizes.shape[}\DecValTok{0}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    stepsize }\OperatorTok{=}\NormalTok{ stepsizes[c, }\DecValTok{1}\NormalTok{]}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Integrator Step Size = }\SpecialCharTok{\{}\NormalTok{stepsize}\SpecialCharTok{:.2e\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Numerical Trajectory
Lengths}\label{numerical-trajectory-lengths}

We can see the consequence of the adapted step sizes by looking at the
numerical trajectories generated for each Hamiltonian Markov transition.
The longer these trajectories the more degenerate the target
distribution, and the more expensive it is to explore.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display symplectic integrator trajectory lengths}
\CommentTok{\# @ax Matplotlib axis object}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\CommentTok{\# @param nlim Optional histogram range}
\KeywordTok{def}\NormalTok{ plot\_num\_leapfrogs(ax, diagnostics, nlim}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
  \CommentTok{"""Display symplectic integrator trajectory lengths"""}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

\NormalTok{  lengths }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{]}
  
\NormalTok{  C }\OperatorTok{=}\NormalTok{ lengths.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  colors }\OperatorTok{=}\NormalTok{ [dark\_highlight, dark, mid\_highlight, mid, light\_highlight]}
  
\NormalTok{  vals\_counts }\OperatorTok{=}\NormalTok{ [ numpy.unique(lengths[c], return\_counts}\OperatorTok{=}\VariableTok{True}\NormalTok{) }
                  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C) ] }
\NormalTok{  max\_n }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(a[}\DecValTok{0}\NormalTok{]) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ vals\_counts ]).astype(numpy.int64) }\OperatorTok{+} \DecValTok{1}
\NormalTok{  max\_counts }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(a[}\DecValTok{1}\NormalTok{]) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ vals\_counts ])}
  
  \ControlFlowTok{if}\NormalTok{ nlim }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{    nlim }\OperatorTok{=}\NormalTok{ [}\FloatTok{0.5}\NormalTok{, max\_n }\OperatorTok{+} \FloatTok{0.5}\NormalTok{]}
  
\NormalTok{  idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_n) }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
\NormalTok{  xs }\OperatorTok{=}\NormalTok{ [ idx }\OperatorTok{+}\NormalTok{ delta }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_n) }\ControlFlowTok{for}\NormalTok{ delta }\KeywordTok{in}\NormalTok{ [}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{]]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    counts }\OperatorTok{=}\NormalTok{ numpy.histogram(lengths[c], }
\NormalTok{                             bins}\OperatorTok{=}\NormalTok{numpy.arange(}\FloatTok{0.5}\NormalTok{, max\_n }\OperatorTok{+} \FloatTok{1.5}\NormalTok{, }\DecValTok{1}\NormalTok{))[}\DecValTok{0}\NormalTok{]}
\NormalTok{    ys }\OperatorTok{=}\NormalTok{ counts[idxs]}
    
\NormalTok{    ax.plot(xs, ys, colors[c])}
  
\NormalTok{  ax.set\_xlabel(}\StringTok{"Numerical Trajectory Lengths"}\NormalTok{)}
\NormalTok{  ax.set\_xlim(nlim)}
\NormalTok{  ax.set\_ylabel(}\StringTok{""}\NormalTok{)}
\NormalTok{  ax.get\_yaxis().set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{  ax.set\_ylim([}\DecValTok{0}\NormalTok{, }\FloatTok{1.1} \OperatorTok{*}\NormalTok{ max\_counts])}
\NormalTok{  ax.spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{  ax.spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display symplectic integrator trajectory lengths by Markov chain}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\KeywordTok{def}\NormalTok{ plot\_num\_leapfrogs\_by\_chain(diagnostics):}
  \CommentTok{"""Display symplectic integrator trajectory lengths"""}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

\NormalTok{  lengths }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{]}
\NormalTok{  C }\OperatorTok{=}\NormalTok{ lengths.shape[}\DecValTok{0}\NormalTok{]}
  
\NormalTok{  vals\_counts }\OperatorTok{=}\NormalTok{ [ numpy.unique(lengths[c], return\_counts}\OperatorTok{=}\VariableTok{True}\NormalTok{) }
                  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C) ] }
\NormalTok{  max\_n }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(a[}\DecValTok{0}\NormalTok{]) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ vals\_counts ]).astype(numpy.int64)}
\NormalTok{  max\_counts }\OperatorTok{=} \BuiltInTok{max}\NormalTok{([ }\BuiltInTok{max}\NormalTok{(a[}\DecValTok{1}\NormalTok{]) }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ vals\_counts ])}
  
\NormalTok{  idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_n) }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
\NormalTok{  xs }\OperatorTok{=}\NormalTok{ [ idx }\OperatorTok{+}\NormalTok{ delta }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_n) }\ControlFlowTok{for}\NormalTok{ delta }\KeywordTok{in}\NormalTok{ [}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{]]}
  
\NormalTok{  N\_plots }\OperatorTok{=}\NormalTok{ C}
\NormalTok{  N\_cols }\OperatorTok{=} \DecValTok{2}
\NormalTok{  N\_rows }\OperatorTok{=}\NormalTok{ math.ceil(N\_plots }\OperatorTok{/}\NormalTok{ N\_cols)}
\NormalTok{  f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(N\_rows, N\_cols, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}
\NormalTok{  k }\OperatorTok{=} \DecValTok{0}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    counts }\OperatorTok{=}\NormalTok{ numpy.histogram(lengths[c], }
\NormalTok{                             bins}\OperatorTok{=}\NormalTok{numpy.arange(}\FloatTok{0.5}\NormalTok{, max\_n }\OperatorTok{+} \FloatTok{1.5}\NormalTok{, }\DecValTok{1}\NormalTok{))[}\DecValTok{0}\NormalTok{]}
\NormalTok{    ys }\OperatorTok{=}\NormalTok{ counts[idxs]}
    
\NormalTok{    eps }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}stepsize\_\_\textquotesingle{}}\NormalTok{][c][}\DecValTok{0}\NormalTok{]}
    
\NormalTok{    idx1 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{//}\NormalTok{ N\_cols}
\NormalTok{    idx2 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{\%}\NormalTok{ N\_cols}
\NormalTok{    k }\OperatorTok{+=} \DecValTok{1}
    
\NormalTok{    axarr[idx1, idx2].plot(xs, ys, dark)}
\NormalTok{    axarr[idx1, idx2].set\_title(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{(Stepsize = }\SpecialCharTok{\{}\NormalTok{eps}\SpecialCharTok{:.3e\}}\SpecialStringTok{)\textquotesingle{}}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_xlabel(}\StringTok{"Numerical Trajectory Lengths"}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_xlim([}\FloatTok{0.5}\NormalTok{, max\_n }\OperatorTok{+} \FloatTok{0.5}\NormalTok{])}
\NormalTok{    axarr[idx1, idx2].set\_ylabel(}\StringTok{""}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].get\_yaxis().set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_ylim([}\DecValTok{0}\NormalTok{, }\FloatTok{1.1} \OperatorTok{*}\NormalTok{ max\_counts])}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
  
\NormalTok{  plot.show()}
\end{Highlighting}
\end{Shaded}

\subsection{Average Proxy Acceptance
Statistic}\label{average-proxy-acceptance-statistic}

When the different adaptation outcomes are due to problematic behaviors
encountered during warmup then it the average proxy acceptance
statistics should also vary across the Markov chains.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Display empirical average of the proxy acceptance statistic across}
\CommentTok{\# each Markov chain}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\KeywordTok{def}\NormalTok{ display\_ave\_accept\_proxy(diagnostics):}
  \CommentTok{"""Display empirical average of the proxy acceptance statistic}
\CommentTok{     across each Markov chain"""}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

\NormalTok{  proxy\_stats }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}accept\_stat\_\_\textquotesingle{}}\NormalTok{]}
\NormalTok{  C }\OperatorTok{=}\NormalTok{ proxy\_stats.shape[}\DecValTok{0}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    proxy\_stat }\OperatorTok{=}\NormalTok{ numpy.mean(proxy\_stats[c,:])}
    \BuiltInTok{print}\NormalTok{(  }\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Average proxy acceptance \textquotesingle{}}
          \OperatorTok{+} \SpecialStringTok{f\textquotesingle{}statistic = }\SpecialCharTok{\{}\NormalTok{proxy\_stat}\SpecialCharTok{:.3f\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Divergence-Labeled Pairs
Plot}\label{divergence-labeled-pairs-plot}

One of the most powerful features of divergent transitions is that they
not only indicate problematic geometry but also provide some spatial
information on the source of that problematic geometry. In particular
the states generated from unstable numerical Hamiltonian trajectories
will tend to be closer to the problematic geometry than those from
stable trajectories.

Consequently if we plot the states from divergent and non-divergent
transitions separately then we should see the divergent states
concentrate towards the problematic behavior. The high-dimensional
states themselves can be visualized with pairs plots.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Apply transformation identity, log, or logit transformation to}
\CommentTok{\# named values and flatten the output.  Transformation defaults to}
\CommentTok{\# identity if name is not included in \textasciigrave{}transforms\textasciigrave{} dictionary.  A}
\CommentTok{\# ValueError is thrown if values are not properly constrained.}
\CommentTok{\# @param name Expectand name.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\CommentTok{\# @param transforms A dictionary with expectand names for keys and}
\CommentTok{\#                   transformation flags for values.}
\CommentTok{\# @return The transformed expectand name and a one{-}dimensional array of}
\CommentTok{\#         flattened transformation outputs.}
\KeywordTok{def}\NormalTok{ apply\_transform(name, expectand\_vals\_dict, transforms):}
\NormalTok{  t }\OperatorTok{=}\NormalTok{ transforms.get(name, }\DecValTok{0}\NormalTok{)}
\NormalTok{  transformed\_name }\OperatorTok{=} \StringTok{""}
\NormalTok{  transformed\_vals }\OperatorTok{=} \DecValTok{0}
  \ControlFlowTok{if}\NormalTok{ t }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
\NormalTok{    transformed\_name }\OperatorTok{=}\NormalTok{ name}
\NormalTok{    transformed\_vals }\OperatorTok{=}\NormalTok{ expectand\_vals\_dict[name].flatten()}
  \ControlFlowTok{elif}\NormalTok{ t }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \ControlFlowTok{if}\NormalTok{ numpy.amin(expectand\_vals\_dict[name]) }\OperatorTok{\textless{}=} \DecValTok{0}\NormalTok{:}
      \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}Log transform requested for expectand \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{name}\SpecialCharTok{\}}\SpecialStringTok{ but expectand values are not strictly \textquotesingle{}} 
                        \StringTok{\textquotesingle{}positive.\textquotesingle{}}\NormalTok{)}
\NormalTok{    transformed\_name }\OperatorTok{=} \SpecialStringTok{f\textquotesingle{}log(}\SpecialCharTok{\{}\NormalTok{name}\SpecialCharTok{\}}\SpecialStringTok{)\textquotesingle{}}
\NormalTok{    transformed\_vals }\OperatorTok{=}\NormalTok{ [ math.log(x) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}
\NormalTok{                         expectand\_vals\_dict[name].flatten() ]}
  \ControlFlowTok{elif}\NormalTok{ t }\OperatorTok{==} \DecValTok{2}\NormalTok{:}
    \ControlFlowTok{if}\NormalTok{ (   numpy.amin(expectand\_vals\_dict[name]) }\OperatorTok{\textless{}=} \DecValTok{0}
        \KeywordTok{or}\NormalTok{ numpy.amax(expectand\_vals\_dict[name]) }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{):}
      \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}Logit transform requested for expectand \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{name}\SpecialCharTok{\}}\SpecialStringTok{ but expectand values are not strictly \textquotesingle{}}
                        \StringTok{\textquotesingle{}confined to the unit interval.\textquotesingle{}}\NormalTok{)}
\NormalTok{    transformed\_name }\OperatorTok{=} \SpecialStringTok{f\textquotesingle{}logit(}\SpecialCharTok{\{}\NormalTok{name}\SpecialCharTok{\}}\SpecialStringTok{)\textquotesingle{}}
\NormalTok{    transformed\_vals }\OperatorTok{=}\NormalTok{ [ math.log(x }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ x)) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}
\NormalTok{                         expectand\_vals\_dict[name].flatten() ]}
  \ControlFlowTok{return}\NormalTok{ transformed\_name, transformed\_vals}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot pairwise scatter plots with non{-}divergent and divergent}
\CommentTok{\# transitions separated by color}
\CommentTok{\# @param x\_names A list of expectand names to be plotted on the x axis.}
\CommentTok{\# @param y\_names A list of expectand names to be plotted on the y axis.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\CommentTok{\# @param diagnostics A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                    each expectand.  The first dimension of each}
\CommentTok{\#                    element indexes the Markov chains and the}
\CommentTok{\#                    second dimension indexes the sequential}
\CommentTok{\#                    states within each Markov chain.}
\CommentTok{\# @param xlim       Optional global x{-}axis bounds for all pair plots.}
\CommentTok{\#                   Defaults to dynamic bounds for each pair plot.}
\CommentTok{\# @param ylim       Optional global y{-}axis bounds for all pair plots.}
\CommentTok{\#                   Defaults to dynamic bounds for each pair plot.}
\CommentTok{\# @param transforms An optional dictionary with expectand names for keys}
\CommentTok{\#                   and transformation flags for values.  Valid flags}
\CommentTok{\#                   are}
\CommentTok{\#                     0: identity}
\CommentTok{\#                     1: log}
\CommentTok{\#                     2: logit}
\CommentTok{\#                   Defaults to empty dictionary.}
\CommentTok{\# @params plot\_mode Optional plotting style configuration:}
\CommentTok{\#                     0: Non{-}divergent transitions are plotted in}
\CommentTok{\#                        transparent red while divergent transitions are}
\CommentTok{\#                        plotted in transparent green.}
\CommentTok{\#                     1: Non{-}divergent transitions are plotted in gray}
\CommentTok{\#                        while divergent transitions are plotted in}
\CommentTok{\#                        different shades of teal depending on the}
\CommentTok{\#                        trajectory length.  Transitions from shorter}
\CommentTok{\#                        trajectories should cluster somewhat closer to}
\CommentTok{\#                        the neighborhoods with problematic geometries.}
\CommentTok{\#                   Defaults to 0.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ plot\_div\_pairs(x\_names, y\_names, expectand\_vals\_dict,}
\NormalTok{                   diagnostics, transforms}\OperatorTok{=}\NormalTok{\{\},}
\NormalTok{                   xlim}\OperatorTok{=}\VariableTok{None}\NormalTok{, ylim}\OperatorTok{=}\VariableTok{None}\NormalTok{, }
\NormalTok{                   plot\_mode}\OperatorTok{=}\DecValTok{0}\NormalTok{, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Plot pairwise scatter plots with non{-}divergent and divergent }
\CommentTok{     transitions separated by color"""}
  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(x\_names, }\BuiltInTok{list}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{((}\StringTok{\textquotesingle{}Input variable \textasciigrave{}x\_names\textasciigrave{} is not a list.\textquotesingle{}}\NormalTok{))}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(y\_names, }\BuiltInTok{list}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{((}\StringTok{\textquotesingle{}Input variable \textasciigrave{}y\_names\textasciigrave{} is not a list.\textquotesingle{}}\NormalTok{))}
    
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}
\NormalTok{  validate\_dict\_of\_arrays(diagnostics, }\StringTok{\textquotesingle{}diagnostics\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(transforms, }\BuiltInTok{dict}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}transforms\textasciigrave{} is not a dictionary.\textquotesingle{}}\NormalTok{)}
  
  \CommentTok{\# Check transform flags}
  \ControlFlowTok{for}\NormalTok{ t\_name, t\_value }\KeywordTok{in}\NormalTok{ transforms.items():}
    \ControlFlowTok{if}\NormalTok{ t\_value }\OperatorTok{\textless{}} \DecValTok{0} \KeywordTok{or}\NormalTok{ t\_value }\OperatorTok{\textgreater{}} \DecValTok{2}\NormalTok{:}
\NormalTok{      desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The transform flag }\SpecialCharTok{\{}\NormalTok{t\_value}\SpecialCharTok{\}}\SpecialStringTok{ for \textquotesingle{}}
              \SpecialStringTok{f\textquotesingle{}expectand }\SpecialCharTok{\{}\NormalTok{t\_name}\SpecialCharTok{\}}\SpecialStringTok{ is invalid.  \textquotesingle{}}
              \StringTok{\textquotesingle{}Plot will default to no tranformation.\textquotesingle{}}\NormalTok{)}
\NormalTok{      desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
      \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}

  \CommentTok{\# Check plot mode}
  \ControlFlowTok{if}\NormalTok{ plot\_mode }\OperatorTok{\textless{}} \DecValTok{0} \KeywordTok{or}\NormalTok{ plot\_mode }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Invalid \textasciigrave{}plot mode\textasciigrave{} value }\SpecialCharTok{\{}\NormalTok{plot\_mode}\SpecialCharTok{\}}\SpecialStringTok{.\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{return}
    
  \CommentTok{\# Transform expectand values}
\NormalTok{  transformed\_vals }\OperatorTok{=}\NormalTok{ \{\}}
  
\NormalTok{  transformed\_x\_names }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ x\_names:}
    \ControlFlowTok{try}\NormalTok{: }
\NormalTok{      t\_name, t\_vals }\OperatorTok{=}\NormalTok{ apply\_transform(name,}
\NormalTok{                                       expectand\_vals\_dict,}
\NormalTok{                                       transforms)}
    \ControlFlowTok{except} \PreprocessorTok{ValueError} \ImportTok{as}\NormalTok{ error:}
\NormalTok{      desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(error, max\_width)}
      \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
      \ControlFlowTok{return}
    
\NormalTok{    transformed\_x\_names.append(t\_name)}
    \ControlFlowTok{if}\NormalTok{ t\_name }\KeywordTok{not} \KeywordTok{in}\NormalTok{ transformed\_vals:}
\NormalTok{      transformed\_vals[t\_name] }\OperatorTok{=}\NormalTok{ t\_vals}
      
\NormalTok{  transformed\_y\_names }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ y\_names:}
    \ControlFlowTok{try}\NormalTok{: }
\NormalTok{      t\_name, t\_vals }\OperatorTok{=}\NormalTok{ apply\_transform(name,}
\NormalTok{                                       expectand\_vals\_dict,}
\NormalTok{                                       transforms)}
    \ControlFlowTok{except} \PreprocessorTok{ValueError} \ImportTok{as}\NormalTok{ error:}
\NormalTok{      desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(error, max\_width)}
      \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
\NormalTok{    transformed\_y\_names.append(t\_name)}
    \ControlFlowTok{if}\NormalTok{ t\_name }\KeywordTok{not} \KeywordTok{in}\NormalTok{ transformed\_vals:}
\NormalTok{      transformed\_vals[t\_name] }\OperatorTok{=}\NormalTok{ t\_vals}
      
  \CommentTok{\# Create pairs of transformed expectands, dropping duplicates}
\NormalTok{  pairs }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ x\_name }\KeywordTok{in}\NormalTok{ transformed\_x\_names:}
    \ControlFlowTok{for}\NormalTok{ y\_name }\KeywordTok{in}\NormalTok{ transformed\_y\_names:}
      \ControlFlowTok{if}\NormalTok{ x\_name }\OperatorTok{==}\NormalTok{ y\_name: }
        \ControlFlowTok{continue}
      \ControlFlowTok{if}\NormalTok{ [x\_name, y\_name] }\KeywordTok{in}\NormalTok{ pairs }\KeywordTok{or}\NormalTok{ [y\_name, x\_name] }\KeywordTok{in}\NormalTok{ pairs: }
        \ControlFlowTok{continue}
\NormalTok{      pairs.append([x\_name, y\_name])}
  
  \CommentTok{\# Extract diagnostic information}
\NormalTok{  divergences }\OperatorTok{=}\NormalTok{ diagnostics[}\StringTok{\textquotesingle{}divergent\_\_\textquotesingle{}}\NormalTok{].flatten()}
  
  \ControlFlowTok{if}\NormalTok{ plot\_mode }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \ControlFlowTok{if} \BuiltInTok{sum}\NormalTok{(divergences) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      div\_nlfs }\OperatorTok{=}\NormalTok{ [ x }\ControlFlowTok{for}\NormalTok{ x, d }\KeywordTok{in}
                   \BuiltInTok{zip}\NormalTok{(diagnostics[}\StringTok{\textquotesingle{}n\_leapfrog\_\_\textquotesingle{}}\NormalTok{].flatten(),}
\NormalTok{                       divergences)}
                   \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{==} \DecValTok{1}\NormalTok{  ]}
\NormalTok{      max\_nlf }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(div\_nlfs)}
\NormalTok{      nom\_colors }\OperatorTok{=}\NormalTok{ [light\_teal, mid\_teal, dark\_teal]}
\NormalTok{      cmap }\OperatorTok{=}\NormalTok{ LinearSegmentedColormap.from\_list(}\StringTok{"teals"}\NormalTok{, nom\_colors,}
\NormalTok{                                               N}\OperatorTok{=}\NormalTok{max\_nlf)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{      div\_nlfs }\OperatorTok{=}\NormalTok{ []}
\NormalTok{      nom\_colors }\OperatorTok{=}\NormalTok{ [light\_teal, mid\_teal, dark\_teal]}
\NormalTok{      cmap }\OperatorTok{=}\NormalTok{ LinearSegmentedColormap.from\_list(}\StringTok{"teals"}\NormalTok{, nom\_colors,}
\NormalTok{                                               N}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
  
  \CommentTok{\# Set plot layout dynamically}
\NormalTok{  N\_pairs }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(pairs)}
  
  \ControlFlowTok{if}\NormalTok{ N\_pairs }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
\NormalTok{    N\_cols }\OperatorTok{=} \DecValTok{1}
\NormalTok{    N\_rows }\OperatorTok{=} \DecValTok{1}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    N\_cols }\OperatorTok{=} \DecValTok{3}
\NormalTok{    N\_rows }\OperatorTok{=}\NormalTok{ math.ceil(N\_pairs }\OperatorTok{/}\NormalTok{ N\_cols)}
    
  \ControlFlowTok{if}\NormalTok{ N\_rows }\OperatorTok{\textgreater{}} \DecValTok{3}\NormalTok{:}
\NormalTok{    N\_rows }\OperatorTok{=} \DecValTok{3}
    
  \CommentTok{\# Plot}
\NormalTok{  k }\OperatorTok{=} \DecValTok{0}
  
  \ControlFlowTok{for}\NormalTok{ pair }\KeywordTok{in}\NormalTok{ pairs:}
    \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
\NormalTok{      f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(N\_rows, N\_cols, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{,}
\NormalTok{                               squeeze}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
      
\NormalTok{    x\_name }\OperatorTok{=}\NormalTok{ pair[}\DecValTok{0}\NormalTok{]}
\NormalTok{    x\_nondiv\_vals }\OperatorTok{=}\NormalTok{ [ x }\ControlFlowTok{for}\NormalTok{ x, d }\KeywordTok{in}
                      \BuiltInTok{zip}\NormalTok{(transformed\_vals[x\_name], divergences)}
                      \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{==} \DecValTok{0}\NormalTok{  ]}
\NormalTok{    x\_div\_vals    }\OperatorTok{=}\NormalTok{ [ x }\ControlFlowTok{for}\NormalTok{ x, d }\KeywordTok{in}
                      \BuiltInTok{zip}\NormalTok{(transformed\_vals[x\_name], divergences)}
                      \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{==} \DecValTok{1}\NormalTok{  ]}
    
    \ControlFlowTok{if}\NormalTok{ xlim }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{      xmin }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(numpy.concatenate((x\_nondiv\_vals, x\_div\_vals)))}
\NormalTok{      xmax }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(numpy.concatenate((x\_nondiv\_vals, x\_div\_vals)))}
\NormalTok{      local\_xlim }\OperatorTok{=}\NormalTok{ [xmin, xmax]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{      local\_xlim }\OperatorTok{=}\NormalTok{ xlim}
    
\NormalTok{    y\_name }\OperatorTok{=}\NormalTok{ pair[}\DecValTok{1}\NormalTok{]}
\NormalTok{    y\_nondiv\_vals }\OperatorTok{=}\NormalTok{ [ y }\ControlFlowTok{for}\NormalTok{ y, d }\KeywordTok{in}
                      \BuiltInTok{zip}\NormalTok{(transformed\_vals[y\_name], divergences)}
                      \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{==} \DecValTok{0}\NormalTok{  ]}
\NormalTok{    y\_div\_vals    }\OperatorTok{=}\NormalTok{ [ y }\ControlFlowTok{for}\NormalTok{ y, d }\KeywordTok{in}
                      \BuiltInTok{zip}\NormalTok{(transformed\_vals[y\_name], divergences)}
                      \ControlFlowTok{if}\NormalTok{ d }\OperatorTok{==} \DecValTok{1}\NormalTok{  ]}
    
    \ControlFlowTok{if}\NormalTok{ ylim }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{      ymin }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(numpy.concatenate((y\_nondiv\_vals, y\_div\_vals)))}
\NormalTok{      ymax }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(numpy.concatenate((y\_nondiv\_vals, y\_div\_vals)))}
\NormalTok{      local\_ylim }\OperatorTok{=}\NormalTok{ [ymin, ymax]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{      local\_ylim }\OperatorTok{=}\NormalTok{ ylim}
     
\NormalTok{    idx1 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{//}\NormalTok{ N\_cols}
\NormalTok{    idx2 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{\%}\NormalTok{ N\_cols}
    
    \ControlFlowTok{if}\NormalTok{ plot\_mode }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
\NormalTok{      axarr[idx1, idx2].scatter(x\_nondiv\_vals, y\_nondiv\_vals, s}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{                                color}\OperatorTok{=}\NormalTok{dark\_highlight, alpha}\OperatorTok{=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{      axarr[idx1, idx2].scatter(x\_div\_vals, y\_div\_vals, s}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{                                color}\OperatorTok{=}\StringTok{"\#00FF00"}\NormalTok{, alpha}\OperatorTok{=}\FloatTok{0.25}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ plot\_mode }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
\NormalTok{      axarr[idx1, idx2].scatter(x\_nondiv\_vals, y\_nondiv\_vals,}
\NormalTok{                                s}\OperatorTok{=}\DecValTok{5}\NormalTok{, color}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{)}
      \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(x\_div\_vals) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        axarr[idx1, idx2].scatter(x\_div\_vals, y\_div\_vals, s}\OperatorTok{=}\DecValTok{5}\NormalTok{,}
\NormalTok{                                  cmap}\OperatorTok{=}\NormalTok{cmap, c}\OperatorTok{=}\NormalTok{div\_nlfs)}
                                
\NormalTok{    axarr[idx1, idx2].set\_xlabel(x\_name)}
\NormalTok{    axarr[idx1, idx2].set\_xlim(local\_xlim)}
\NormalTok{    axarr[idx1, idx2].set\_ylabel(y\_name)}
\NormalTok{    axarr[idx1, idx2].set\_ylim(local\_ylim)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
    
\NormalTok{    k }\OperatorTok{+=} \DecValTok{1}
    \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{==}\NormalTok{ N\_rows }\OperatorTok{*}\NormalTok{ N\_cols:}
      \CommentTok{\# Flush current plot}
\NormalTok{      plot.show()}
\NormalTok{      k }\OperatorTok{=} \DecValTok{0}
  
  \CommentTok{\# Turn off any remaining subplots}
  \ControlFlowTok{if}\NormalTok{ k }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{: }
    \ControlFlowTok{for}\NormalTok{ kk }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(k, N\_rows }\OperatorTok{*}\NormalTok{ N\_cols):}
\NormalTok{      idx1 }\OperatorTok{=}\NormalTok{ kk }\OperatorTok{//}\NormalTok{ N\_cols}
\NormalTok{      idx2 }\OperatorTok{=}\NormalTok{ kk }\OperatorTok{\%}\NormalTok{ N\_cols}
\NormalTok{      axarr[idx1, idx2].axis(}\StringTok{\textquotesingle{}off\textquotesingle{}}\NormalTok{)}
\NormalTok{    plot.show()}
\end{Highlighting}
\end{Shaded}

\section{Expectand Diagnostic
Functions}\label{expectand-diagnostic-functions}

The Hamiltonian Monte Carlo diagnostics exploited the particular
structure of the Hamiltonian Markov transition. For a general Markov
transition we don't have any particular structure to exploit, and hence
limited diagnostic options. In this general setting we have to
investigate the behavior of not the entire state but instead particular
expectands of interest.

\subsection{xihat}\label{xihat}

A Markov chain Monte Carlo central limit theorem cannot exist for the
expectand \(f : X \rightarrow \mathbb{R}\) unless both
\(\mathbb{E}_{\pi}[f]\) and \(\mathbb{E}_{\pi}[f^{2}]\) are finite, in
which case we say that the expectand is sufficiently integrable.
Moreover the smaller the following moments the faster the central limit
theorem will kick in.

\(\hat{\xi}\) uses the tail behavior of a realized Markov chain to
estimate the integrability of an expectand. More specifically
\(\hat{\xi}\) estimates the shape of a general Pareto density function
from non-central values of the expectand.\\
If the tail behavior were exactly general Pareto then the larger the
shape parameter \(\xi\) the fewer moments of the distribution will be
well-defined. Formally the \(m\)th-order moment is well-defined only if
\[
m < \frac{1}{\xi}.
\]

For example with \(\xi = 0.9\) the expectation \(\mathbb{E}_{\pi}[f]\)
is finite but \(\mathbb{E}_{\pi}[f^{2}]\) is not. Similarly for
\(\xi = 0.4\) the expectations \(\mathbb{E}_{\pi}[f]\) and
\(\mathbb{E}_{\pi}[f^{2}]\) are finite but the third-order moment
\(\mathbb{E}_{\pi}[f^{3}]\) is not.

The estimator \(\hat{\xi}\) is constructed from the smallest and largest
values of an expectand evaluated across a realized Markov chain, where
the smallest and largest values are separated from the central values
using a heuristic. Because \(\hat{\xi}\) only estimates the tail shape I
require a conservative threshold of \(\hat{\xi} \ge 0.25\) for the
diagnostic warning to be triggered.

If the expectand output is bounded then the lower and upper tail might
consist of the same value. In this case the \(\hat{\xi}\) estimator is
poorly-behaved, but the boundedness also guarantees that moments of all
orders exist. To make this diagnostic as robust as possible
\(\hat{\xi}\) will return \(-2\) in these cases to avoid the diagnostic
threshold.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute hat\{xi\}, an estimate for the shape of a generalized Pareto}
\CommentTok{\# distribution from a sample of positive values using the method}
\CommentTok{\# introduced in "A New and Efficient Estimation Method for the}
\CommentTok{\# Generalized Pareto Distribution" by Zhang and Stephens}
\CommentTok{\# https://doi.org/10.1198/tech.2009.08017.}
\CommentTok{\#}
\CommentTok{\# Within the generalized Pareto distribution family all moments up to}
\CommentTok{\# the mth order are finite if and only if}
\CommentTok{\#  xi \textless{} 1 / m.}
\CommentTok{\#}
\CommentTok{\# @params vals A one{-}dimensional array of positive values.}
\CommentTok{\# @return Shape parameter estimate.}
\KeywordTok{def}\NormalTok{ compute\_xi\_hat(vals):}
  \CommentTok{"""Compute empirical Pareto shape configuration for a positive sample"""}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals)}
\NormalTok{  sorted\_vals }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(vals)}
  
  \ControlFlowTok{if}\NormalTok{ sorted\_vals[}\DecValTok{0}\NormalTok{] }\OperatorTok{==}\NormalTok{ sorted\_vals[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]:}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{2}
  
  \ControlFlowTok{if}\NormalTok{ (sorted\_vals[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Sequence values must be positive."}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ math.nan}
  
  \CommentTok{\# Estimate 25\% quantile}
\NormalTok{  q }\OperatorTok{=}\NormalTok{ sorted\_vals[math.floor(}\FloatTok{0.25} \OperatorTok{*}\NormalTok{ N }\OperatorTok{+} \FloatTok{0.5}\NormalTok{)]}
  \ControlFlowTok{if}\NormalTok{ q }\OperatorTok{==}\NormalTok{ sorted\_vals[}\DecValTok{0}\NormalTok{]:}
    \ControlFlowTok{return} \OperatorTok{{-}}\DecValTok{2}
    
  \CommentTok{\# Heuristic Pareto configuration}
\NormalTok{  M }\OperatorTok{=} \DecValTok{20} \OperatorTok{+}\NormalTok{ math.floor(math.sqrt(N))}
  
\NormalTok{  b\_hat\_vec }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ M}
\NormalTok{  log\_w\_vec }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ M}
  
  \ControlFlowTok{for}\NormalTok{ m }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(M):}
\NormalTok{    b\_hat\_vec[m] }\OperatorTok{=}   \DecValTok{1} \OperatorTok{/}\NormalTok{ sorted\_vals[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\OperatorTok{\textbackslash{}}
                   \OperatorTok{+}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ math.sqrt(M }\OperatorTok{/}\NormalTok{ (m }\OperatorTok{+} \FloatTok{0.5}\NormalTok{))) }\OperatorTok{/}\NormalTok{ (}\DecValTok{3} \OperatorTok{*}\NormalTok{ q)}
    \ControlFlowTok{if}\NormalTok{ b\_hat\_vec[m] }\OperatorTok{!=} \DecValTok{0}\NormalTok{:}
\NormalTok{      xi\_hat }\OperatorTok{=}\NormalTok{ numpy.mean( [ math.log(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ b\_hat\_vec[m] }\OperatorTok{*}\NormalTok{ f) }
                             \ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ sorted\_vals ] )}
\NormalTok{      log\_w\_vec[m] }\OperatorTok{=}\NormalTok{ N }\OperatorTok{*}\NormalTok{ (   math.log(}\OperatorTok{{-}}\NormalTok{b\_hat\_vec[m] }\OperatorTok{/}\NormalTok{ xi\_hat) }
                           \OperatorTok{{-}}\NormalTok{ xi\_hat }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{      log\_w\_vec[m] }\OperatorTok{=} \DecValTok{0}

  \CommentTok{\# Remove terms that don\textquotesingle{}t contribute to improve numerical stability }
  \CommentTok{\# of average}
\NormalTok{  log\_w\_vec }\OperatorTok{=}\NormalTok{ [ lw }\ControlFlowTok{for}\NormalTok{ lw }\KeywordTok{in}\NormalTok{ log\_w\_vec }\ControlFlowTok{if}\NormalTok{ lw }\OperatorTok{!=} \DecValTok{0}\NormalTok{ ]}
\NormalTok{  b\_hat\_vec }\OperatorTok{=}\NormalTok{ [ b }\ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in}\NormalTok{ b\_hat\_vec }\ControlFlowTok{if}\NormalTok{ b }\OperatorTok{!=} \DecValTok{0}\NormalTok{ ]}

\NormalTok{  max\_log\_w }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(log\_w\_vec)}
\NormalTok{  b\_hat }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{( [ b }\OperatorTok{*}\NormalTok{ math.exp(lw }\OperatorTok{{-}}\NormalTok{ max\_log\_w) }
               \ControlFlowTok{for}\NormalTok{ b, lw }\KeywordTok{in} \BuiltInTok{zip}\NormalTok{(b\_hat\_vec, log\_w\_vec) ] ) }\OperatorTok{/\textbackslash{}}
          \BuiltInTok{sum}\NormalTok{( [ math.exp(lw }\OperatorTok{{-}}\NormalTok{ max\_log\_w) }\ControlFlowTok{for}\NormalTok{ lw }\KeywordTok{in}\NormalTok{ log\_w\_vec ] )}

  \ControlFlowTok{return}\NormalTok{ numpy.mean( [ math.log(}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ b\_hat }\OperatorTok{*}\NormalTok{ f) }\ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ sorted\_vals ] )}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical generalized Pareto shape for upper and lower tails}
\CommentTok{\# for an arbitrary sample of expectand values, ignoring any}
\CommentTok{\# autocorrelation between the values.}
\CommentTok{\# @param vals A one{-}dimensional array of expectand values.}
\CommentTok{\# @return Left and right shape estimators.}
\KeywordTok{def}\NormalTok{ compute\_tail\_xi\_hats(vals):}
  \CommentTok{"""Compute empirical Pareto shape configuration for upper and lower tails"""}
\NormalTok{  v\_center }\OperatorTok{=}\NormalTok{ numpy.median(vals)}
  
  \CommentTok{\# Isolate lower and upper tails which can be adequately modeled by a }
  \CommentTok{\# generalized Pareto shape for sufficiently well{-}behaved distributions}
\NormalTok{  vals\_left }\OperatorTok{=}\NormalTok{ [ math.fabs(v }\OperatorTok{{-}}\NormalTok{ v\_center) }\ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vals }\ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textless{}=}\NormalTok{ v\_center ]}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals\_left)}
\NormalTok{  M }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(}\BuiltInTok{min}\NormalTok{(}\FloatTok{0.2} \OperatorTok{*}\NormalTok{ N, }\DecValTok{3} \OperatorTok{*} \DecValTok{3} \OperatorTok{*}\NormalTok{ math.sqrt(N)))}
\NormalTok{  vals\_left }\OperatorTok{=}\NormalTok{ vals\_left[M:N]}
  
\NormalTok{  vals\_right }\OperatorTok{=}\NormalTok{ [ v }\OperatorTok{{-}}\NormalTok{ v\_center }\ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vals }\ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textgreater{}}\NormalTok{ v\_center ]}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals\_right)}
\NormalTok{  M }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(}\BuiltInTok{min}\NormalTok{(}\FloatTok{0.2} \OperatorTok{*}\NormalTok{ N, }\DecValTok{3} \OperatorTok{*} \DecValTok{3} \OperatorTok{*}\NormalTok{ math.sqrt(N)))}
\NormalTok{  vals\_right }\OperatorTok{=}\NormalTok{ vals\_right[M:N]}
  
  \CommentTok{\# Default to NaN if left tail is ill{-}defined}
\NormalTok{  xi\_hat\_left }\OperatorTok{=}\NormalTok{ math.nan}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(vals\_left) }\OperatorTok{\textgreater{}} \DecValTok{40}\NormalTok{:}
\NormalTok{    xi\_hat\_left }\OperatorTok{=}\NormalTok{ compute\_xi\_hat(vals\_left)}
  
  \CommentTok{\# Default to NaN if right tail is ill{-}defined}
\NormalTok{  xi\_hat\_right }\OperatorTok{=}\NormalTok{ math.nan}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(vals\_right) }\OperatorTok{\textgreater{}} \DecValTok{40}\NormalTok{:}
\NormalTok{    xi\_hat\_right }\OperatorTok{=}\NormalTok{ compute\_xi\_hat(vals\_right)}
    
  \ControlFlowTok{return}\NormalTok{ [xi\_hat\_left, xi\_hat\_right]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check upper and lower tail behavior of a given expectand output}
\CommentTok{\# ensemble.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_tail\_xi\_hats(expectand\_vals, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check empirical Pareto shape configuration for upper and lower }
\CommentTok{     tails of a given expectand output ensemble"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    xi\_hats }\OperatorTok{=}\NormalTok{ compute\_tail\_xi\_hats(expectand\_vals[c,:])}
\NormalTok{    xi\_hat\_threshold }\OperatorTok{=} \FloatTok{0.25}
    \ControlFlowTok{if}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{0}\NormalTok{]) }\KeywordTok{and}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{1}\NormalTok{]):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Both left and right tail \textquotesingle{}}
            \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{s are Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{0}\NormalTok{]):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Left tail \textquotesingle{}}
            \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{ is Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{1}\NormalTok{]):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Right tail \textquotesingle{}}
            \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{ is Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }
         \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Both left and right tail \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{s (}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{0}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{, \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceed \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold }
          \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Right tail hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{ \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceeds \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }
          \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Left tail hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{ \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{0}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceeds \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ no\_warning:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Expectand appears to be sufficiently integrable.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}  Large tail xi\_hats suggest that the expectand might\textquotesingle{}}
            \StringTok{\textquotesingle{}not be sufficiently integrable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

\subsection{Frozen Chains}\label{frozen-chains}

Another sign of problems is when all evaluations of an expectand are
constant. This could be due to the Markov chain being stuck at a single
state or just that the pushforward distribution of the expectand
concentrates on a single value. We can't distinguish between these
possibilities without more information, but we can signal a constant
expectand by looking at its empirical variance.

Here we'll use a Welford accumulator to compute the empirical variance
of the expectand values in a single sweep.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical mean and variance of a given sequence with a single}
\CommentTok{\# pass using Welford accumulators.}
\CommentTok{\# @params vals A one{-}dimensional array of sequential expectand values.}
\CommentTok{\# @return The empirical mean and variance.}
\KeywordTok{def}\NormalTok{ welford\_summary(vals):}
  \CommentTok{"""Welford accumulator for empirical mean and variance of a}
\CommentTok{     given sequence"""}
\NormalTok{  mean }\OperatorTok{=} \DecValTok{0}
\NormalTok{  var }\OperatorTok{=} \DecValTok{0}
  
  \ControlFlowTok{for}\NormalTok{ n, v }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(vals):}
\NormalTok{    delta }\OperatorTok{=}\NormalTok{ v }\OperatorTok{{-}}\NormalTok{ mean}
\NormalTok{    mean }\OperatorTok{+=}\NormalTok{ delta }\OperatorTok{/}\NormalTok{ (n }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{    var }\OperatorTok{+=}\NormalTok{ delta }\OperatorTok{*}\NormalTok{ (v }\OperatorTok{{-}}\NormalTok{ mean)}
    
\NormalTok{  var }\OperatorTok{/=}\NormalTok{ (}\BuiltInTok{len}\NormalTok{(vals) }\OperatorTok{{-}} \DecValTok{1}\NormalTok{)}
  
  \ControlFlowTok{return}\NormalTok{ [mean, var]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check expectand output ensemble for vanishing empirical variance.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_variances(expectand\_vals, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check expectand output ensemble for vanishing empirical variance"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    var }\OperatorTok{=}\NormalTok{ welford\_summary(expectand\_vals[c,:])[}\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{if}\NormalTok{ var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{True}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Expectand is constant.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if}\NormalTok{ no\_warning:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}Expectand is varying in all Markov chains.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}  If the expectand is not expected (haha) to be \textquotesingle{}}
            \StringTok{\textquotesingle{}constant then the Markov transitions are misbehaving.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

\subsection{Split Rhat}\label{split-rhat}

One of the key features of Markov chain equilibrium is that the
distribution of Markov chain realizations is independent of the
initialization. In particular the expectand evaluations from any
equilibrated Markov chain should be statistically equivalent to any
other. Even more the evaluations across any subset of Markov chain
states should be equivalent.

The split \(\hat{R}\) statistic quantifies the heterogeneity in the
expectand evaluations across an ensemble of Markov chains, each of which
has been split in half. Mathematically split \(\hat{R}\) is similar to
analysis of variance in that compares the empirical variance of the
average expectand values in each chain half to the average of the
empirical variances in each chain half; the key difference is that split
\(\hat{R}\) transforms this ratio so that in equilibrium the statistic
decays towards \(1\) from above.

When split \(\hat{R}\) is much larger than \(1\) the expectand
evaluations across each Markov chain halves are not consistent with each
other. This could be because the Markov chains have not converged to the
same typical set or because they have not yet expanded into that typical
set.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Split a sequence of expectand values in half to create an initial and}
\CommentTok{\# terminal Markov chains}
\CommentTok{\# @params chain A sequence of expectand values derived from a single}
\CommentTok{\#               Markov chain.}
\CommentTok{\# @return Two subsequences of expectand values.}
\KeywordTok{def}\NormalTok{ split\_chain(chain):}
  \CommentTok{"""Split a Markov chain into initial and terminal Markov chains"""}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(chain)}
\NormalTok{  M }\OperatorTok{=}\NormalTok{ N }\OperatorTok{//} \DecValTok{2}
  \ControlFlowTok{return}\NormalTok{ [ chain[}\DecValTok{0}\NormalTok{:M], chain[M:N] ]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute split hat\{R\} for the expectand values across a Markov chain}
\CommentTok{\# ensemble.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @return Split Rhat estimate.}
\KeywordTok{def}\NormalTok{ compute\_split\_rhat(expectand\_vals):}
  \CommentTok{"""Compute split hat\{R\} for an expectand output ensemble across}
\CommentTok{     a collection of Markov chains"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  split\_chain\_vals }\OperatorTok{=}\NormalTok{ [ c }\ControlFlowTok{for}\NormalTok{ chain\_vals }\KeywordTok{in}\NormalTok{ expectand\_vals}
                       \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ split\_chain(chain\_vals) ]}
\NormalTok{  N\_chains }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(split\_chain\_vals)}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{([ }\BuiltInTok{len}\NormalTok{(vals) }\ControlFlowTok{for}\NormalTok{ vals }\KeywordTok{in}\NormalTok{ split\_chain\_vals ])}
  
\NormalTok{  means }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ N\_chains}
  \BuiltInTok{vars} \OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ N\_chains}
  
  \ControlFlowTok{for}\NormalTok{ c, vals }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(split\_chain\_vals):}
\NormalTok{    summary }\OperatorTok{=}\NormalTok{ welford\_summary(vals)}
\NormalTok{    means[c] }\OperatorTok{=}\NormalTok{ summary[}\DecValTok{0}\NormalTok{]}
    \BuiltInTok{vars}\NormalTok{[c] }\OperatorTok{=}\NormalTok{ summary[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  total\_mean }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(means) }\OperatorTok{/}\NormalTok{ N\_chains}
\NormalTok{  W }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(}\BuiltInTok{vars}\NormalTok{) }\OperatorTok{/}\NormalTok{ N\_chains}
\NormalTok{  B }\OperatorTok{=}\NormalTok{ N }\OperatorTok{*} \BuiltInTok{sum}\NormalTok{([ (mean }\OperatorTok{{-}}\NormalTok{ total\_mean)}\OperatorTok{**}\DecValTok{2} \OperatorTok{/}\NormalTok{ (N\_chains }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) }
                \ControlFlowTok{for}\NormalTok{ mean }\KeywordTok{in}\NormalTok{ means ])}
  
\NormalTok{  rhat }\OperatorTok{=}\NormalTok{ math.nan}
  \ControlFlowTok{if} \BuiltInTok{abs}\NormalTok{(W) }\OperatorTok{\textgreater{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{    rhat }\OperatorTok{=}\NormalTok{ math.sqrt( (N }\OperatorTok{{-}} \DecValTok{1} \OperatorTok{+}\NormalTok{ B }\OperatorTok{/}\NormalTok{ W) }\OperatorTok{/}\NormalTok{ N )}
  
  \ControlFlowTok{return}\NormalTok{ rhat}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute split hat\{R\} for all input expectands}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\KeywordTok{def}\NormalTok{ compute\_split\_rhats(expectand\_vals\_dict):}
  \CommentTok{"""Compute split hat\{R\} for all expectand output ensembles across}
\CommentTok{     a collection of Markov chains"""}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}
    
\NormalTok{  rhats }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict:}
\NormalTok{    expectand\_vals }\OperatorTok{=}\NormalTok{ expectand\_vals\_dict[name]}
\NormalTok{    rhats.append(compute\_split\_rhat(expectand\_vals))}
  
  \ControlFlowTok{return}\NormalTok{ rhats}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check split hat\{R\} across a given expectand output ensemble.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_rhat(expectand\_vals, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check split hat\{R\} for all expectand output ensembles across}
\CommentTok{     a collection of Markov chains"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
    
\NormalTok{  rhat }\OperatorTok{=}\NormalTok{ compute\_split\_rhat(expectand\_vals)}

\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
  
  \ControlFlowTok{if}\NormalTok{ math.isnan(rhat):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}All Markov chains appear to be frozen.\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{elif}\NormalTok{ rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Split hat}\CharTok{\{\{}\SpecialStringTok{R}\CharTok{\}\}}\SpecialStringTok{ is }\SpecialCharTok{\{}\NormalTok{rhat}\SpecialCharTok{:.3f\}}\SpecialStringTok{.\textquotesingle{}}\NormalTok{)}
\NormalTok{    no\_warning }\OperatorTok{=} \VariableTok{False}

  \ControlFlowTok{if}\NormalTok{ no\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Markov chain behavior is consistent with equilibrium.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Split hat}\SpecialCharTok{\{R\}}\StringTok{ larger than 1.1 suggests that at least one \textquotesingle{}}
            \StringTok{\textquotesingle{}of the Markov chains has not reached an equilibrium.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

\subsection{Integrated Autocorrelation
Time}\label{integrated-autocorrelation-time}

The information about the target distribution encoded within a Markov
chain, and hence the potential precision of Markov chain Monte Carlo
estimators, is limited by the autocorrelation of the internal states.
Assuming equilibrium we can estimate the stationary autocorrelations
between the outputs of a given expectand from the realized Markov chain
and then combine them into an estimate of the integrated autocorrelation
time \(\hat{\tau}[f]\).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical integrated autocorrelation time, \textbackslash{}hat\{tau\}, for a}
\CommentTok{\# sequence of expectand values.}
\CommentTok{\# @param vals A one{-}dimensional array of expectand values.}
\CommentTok{\# @return Left and right shape estimators.}
\KeywordTok{def}\NormalTok{ compute\_tau\_hat(vals):}
  \CommentTok{"""Compute empirical integrated autocorrelation time for a sequence"""}
  \CommentTok{\# Compute empirical autocorrelations}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals)}
\NormalTok{  m, v }\OperatorTok{=}\NormalTok{ welford\_summary(vals)}
\NormalTok{  zs }\OperatorTok{=}\NormalTok{ [ val }\OperatorTok{{-}}\NormalTok{ m }\ControlFlowTok{for}\NormalTok{ val }\KeywordTok{in}\NormalTok{ vals ]}
  
  \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
    \ControlFlowTok{return}\NormalTok{ math.inf}
  
\NormalTok{  B }\OperatorTok{=} \DecValTok{2}\OperatorTok{**}\NormalTok{math.ceil(math.log2(N)) }\CommentTok{\# Next power of 2 after N}
\NormalTok{  zs\_buff }\OperatorTok{=}\NormalTok{ zs }\OperatorTok{+}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ (B }\OperatorTok{{-}}\NormalTok{ N)}
  
\NormalTok{  Fs }\OperatorTok{=}\NormalTok{ numpy.fft.fft(zs\_buff)}
\NormalTok{  Ss }\OperatorTok{=}\NormalTok{ numpy.}\BuiltInTok{abs}\NormalTok{(Fs)}\OperatorTok{**}\DecValTok{2}
\NormalTok{  Rs }\OperatorTok{=}\NormalTok{ numpy.fft.ifft(Ss)}

\NormalTok{  acov\_buff }\OperatorTok{=}\NormalTok{ numpy.real(Rs)}
\NormalTok{  rhos }\OperatorTok{=}\NormalTok{ acov\_buff[}\DecValTok{0}\NormalTok{:N] }\OperatorTok{/}\NormalTok{ acov\_buff[}\DecValTok{0}\NormalTok{]}
  
  \CommentTok{\# Drop last lag if (L + 1) is odd so that the lag pairs are complete}
\NormalTok{  L }\OperatorTok{=}\NormalTok{ N}
  \ControlFlowTok{if}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{:}
\NormalTok{    L }\OperatorTok{=}\NormalTok{ L }\OperatorTok{{-}} \DecValTok{1}
  
  \CommentTok{\# Number of lag pairs}
\NormalTok{  P }\OperatorTok{=}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{//} \DecValTok{2}
  
  \CommentTok{\# Construct asymptotic correlation from initial monotone sequence}
\NormalTok{  old\_pair\_sum }\OperatorTok{=}\NormalTok{ rhos[}\DecValTok{0}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{1}\NormalTok{]}
  \ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, P):}
\NormalTok{    current\_pair\_sum }\OperatorTok{=}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{+} \DecValTok{1}\NormalTok{]}
    
    \ControlFlowTok{if}\NormalTok{ current\_pair\_sum }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      rho\_sum }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(rhos[}\DecValTok{1}\NormalTok{:(}\DecValTok{2} \OperatorTok{*}\NormalTok{ p)])}
      
      \ControlFlowTok{if}\NormalTok{ rho\_sum }\OperatorTok{\textless{}=} \OperatorTok{{-}}\FloatTok{0.25}\NormalTok{:}
\NormalTok{        rho\_sum }\OperatorTok{=} \OperatorTok{{-}}\FloatTok{0.25}
      
\NormalTok{      asymp\_corr }\OperatorTok{=} \FloatTok{1.0} \OperatorTok{+} \DecValTok{2} \OperatorTok{*}\NormalTok{ rho\_sum}
      \ControlFlowTok{return}\NormalTok{ asymp\_corr}
    
    \ControlFlowTok{if}\NormalTok{ current\_pair\_sum }\OperatorTok{\textgreater{}}\NormalTok{ old\_pair\_sum:}
\NormalTok{      current\_pair\_sum }\OperatorTok{=}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p]     }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}

    \CommentTok{\# if p == P:}
      \CommentTok{\# throw some kind of error when autocorrelation}
      \CommentTok{\# sequence doesn\textquotesingle{}t get terminated}
    
\NormalTok{    old\_pair\_sum }\OperatorTok{=}\NormalTok{ current\_pair\_sum}

\end{Highlighting}
\end{Shaded}

This, estimate, however, can be unreliable if the Markov chains have not
had sufficient time to explore. In my experience a good rule of thumb is
that the empirical integrated autocorrelation time has cannot be larger
than five times the number of total iterations, \[
\hat{\tau}[f] < 5 \cdot N.
\] Equivalently the incremental empirical integrated autocorrelation
time cannot be larger than five, \[
\frac{ \hat{\tau}[f] }{N} < 5.
\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check the incremental empirical integrated autocorrelation time for}
\CommentTok{\# all the given expectand values.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_inc\_tau\_hat(expectand\_vals, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check that the incremental empirical integrated autocorrelation}
\CommentTok{     time of the given expectand values is sufficiently large."""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}

\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{1}\NormalTok{]}

  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(expectand\_vals[c,:])}
\NormalTok{    inc\_tau\_hat }\OperatorTok{=}\NormalTok{ tau\_hat }\OperatorTok{/}\NormalTok{ S}
    \ControlFlowTok{if}\NormalTok{ inc\_tau\_hat }\OperatorTok{\textgreater{}} \DecValTok{5}\NormalTok{:}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: The incremental empirical integrated \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}autocorrelation time }\SpecialCharTok{\{}\NormalTok{inc\_tau\_hat }\SpecialCharTok{:.3f\}}\SpecialStringTok{ is too large.\textquotesingle{}}\NormalTok{)}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}

  \ControlFlowTok{if}\NormalTok{ no\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}The incremental empirical integrated autocorrelation \textquotesingle{}}
            \StringTok{\textquotesingle{}time is small enough for the empirical autocorrelation \textquotesingle{}}
            \StringTok{\textquotesingle{}estimates to be reliable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}If the incremental empirical integrated autocorrelation \textquotesingle{}}
            \StringTok{\textquotesingle{}times are too large then the Markov \textquotesingle{}}
            \StringTok{\textquotesingle{}chains have not explored long enough for the \textquotesingle{}}
            \StringTok{\textquotesingle{}autocorrelation estimates to be reliable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

The integrated autocorrelation times moderates the asymptotic variance
of well-behaved Markov chain Monte Carlo estimators through the
effective sample size, \[
\text{ESS}[f] = \frac{N}{\tau[f]},
\] or in practice the empirical effective sample size that we estimate
from the realized Markov chains, \[
\hat{\text{ESS}[f]} = \frac{N}{\hat{\tau}[f]}.
\] The effective sample size can be interpreted as how large of an
ensemble of exact samples we would need to achieve the same estimator
error for the particular expectand of interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute the minimum empirical effective sample size, or \textbackslash{}hat\{ESS\},}
\CommentTok{\# across the Markov chains for the given expectands.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\KeywordTok{def}\NormalTok{ compute\_min\_ess\_hats(expectand\_vals\_dict):}
  \CommentTok{"""Compute the minimum empirical integrated autocorrelation time}
\CommentTok{     across a collection of Markov chains for all expectand output}
\CommentTok{     ensembles"""}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}
      
\NormalTok{  min\_ess\_hats }\OperatorTok{=}\NormalTok{ []}
  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict:}
\NormalTok{    expectand\_vals }\OperatorTok{=}\NormalTok{ expectand\_vals\_dict[name]}
\NormalTok{    C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{    S }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
    
\NormalTok{    ess\_hats }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*} \DecValTok{4}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{      tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(expectand\_vals[c,:])}
\NormalTok{      ess\_hats[c] }\OperatorTok{=}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
    
\NormalTok{    min\_ess\_hats.append(}\BuiltInTok{min}\NormalTok{(ess\_hats))}
  
  \ControlFlowTok{return}\NormalTok{ min\_ess\_hats}
\end{Highlighting}
\end{Shaded}

Assuming stationarity we can use the empirical effective sample size to
estimate the Markov chain Monte Carlo standard error for any
well-behaved expectand estimator \[
\hat{f} \approx \mathbb{E}_{\pi}[f].
\] The necessary effective sample size depends on the precision required
for a given Markov chain Monte Carlo estimator. This can vary not only
from analysis to analysis but also between multiple expectands within a
single analysis. That said an effective sample size of \(100\) is more
than sufficient for most applications and provides a useful rule of
thumb. In some applications even smaller effective sample sizes can
yield sufficiently precise Markov chain Monte Carlo estimators.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check the empirical effective sample size \textbackslash{}hat\{ESS\} for the given}
\CommentTok{\# expectand values.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param min\_ess\_hat\_per\_chain The minimum empirical effective sample}
\CommentTok{\#                              size before a warning message is passed.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_ess\_hat(expectand\_vals,}
\NormalTok{                  min\_ess\_hat\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                  max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check the empirical effective sample size for all expectand }
\CommentTok{     output ensembles"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  no\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{1}\NormalTok{]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(expectand\_vals[c,:])}
\NormalTok{    ess\_hat }\OperatorTok{=}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
    \ControlFlowTok{if}\NormalTok{ ess\_hat }\OperatorTok{\textless{}}\NormalTok{ min\_ess\_hat\_per\_chain:}
      \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: The empirical effective sample size \textquotesingle{}}
            \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{ess\_hat }\SpecialCharTok{:.1f\}}\SpecialStringTok{ is too small.\textquotesingle{}}\NormalTok{)}
\NormalTok{      no\_warning }\OperatorTok{=} \VariableTok{False}
  
  \ControlFlowTok{if}\NormalTok{ no\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Assuming that a central limit theorem holds the \textquotesingle{}}
            \StringTok{\textquotesingle{}empirical effective sample size is large enough \textquotesingle{}}
            \StringTok{\textquotesingle{}for Markov chain Monte Carlo estimation to be\textquotesingle{}}
            \StringTok{\textquotesingle{}reasonably precise.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Small empirical effective sample sizes result in \textquotesingle{}}
            \StringTok{\textquotesingle{}imprecise Markov chain Monte Carlo estimators.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

For example empirical effective sample sizes can provide a useful way to
distinguish if some diagnostic failures are due to Markov chains that
are just too short or more persistent problems.

\subsection{All Expectand Diagnostics}\label{all-expectand-diagnostics}

In practice we have no reason not to check all of these diagnostics at
once for each expectand of interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Check all expectand{-}specific diagnostics.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\CommentTok{\# @param min\_ess\_hat\_per\_chain The minimum empirical effective sample}
\CommentTok{\#                              size before a warning message is passed.}
\CommentTok{\# @param exclude\_zvar Binary variable to exclude all expectands with}
\CommentTok{\#                     vanishing empirical variance from other diagnostic}
\CommentTok{\#                     checks.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ check\_all\_expectand\_diagnostics(expectand\_vals\_dict,}
\NormalTok{                                    min\_ess\_hat\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                                    exclude\_zvar}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                                    max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Check all expectand diagnostics"""}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{True} 
\NormalTok{  no\_zvar\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_rhat\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_inc\_tau\_hat\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{  no\_ess\_hat\_warning }\OperatorTok{=} \VariableTok{True}
  
\NormalTok{  message }\OperatorTok{=} \StringTok{""}
  
  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict:}
\NormalTok{    expectand\_vals }\OperatorTok{=}\NormalTok{ expectand\_vals\_dict[name]}
\NormalTok{    C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{    S }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{1}\NormalTok{]}
    
\NormalTok{    local\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{    local\_message }\OperatorTok{=}\NormalTok{ name }\OperatorTok{+} \StringTok{\textquotesingle{}:}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}
  
    \ControlFlowTok{if}\NormalTok{ exclude\_zvar:}
      \CommentTok{\# Check zero variance across all Markov chains for exclusion}
\NormalTok{      any\_zvar }\OperatorTok{=} \VariableTok{False}
      \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{        var }\OperatorTok{=}\NormalTok{ welford\_summary(expectand\_vals[c,:])[}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{          any\_zvar }\OperatorTok{=} \VariableTok{True}
      
      \ControlFlowTok{if}\NormalTok{ any\_zvar:}
        \ControlFlowTok{continue}
    
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
      \CommentTok{\# Check tail xi\_hats in each Markov chain}
\NormalTok{      xi\_hats }\OperatorTok{=}\NormalTok{ compute\_tail\_xi\_hats(expectand\_vals[c,:])}
\NormalTok{      xi\_hat\_threshold }\OperatorTok{=} \FloatTok{0.25}
      \ControlFlowTok{if}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{0}\NormalTok{]) }\KeywordTok{and}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{1}\NormalTok{]):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Both left and right tail \textquotesingle{}}
                          \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{s are Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{elif}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{0}\NormalTok{]):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Left tail \textquotesingle{}}
                          \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{ is Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{elif}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{1}\NormalTok{]):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Right tail \textquotesingle{}}
                          \StringTok{\textquotesingle{}hat}\SpecialCharTok{\{\{}\StringTok{xi}\SpecialCharTok{\}\}}\StringTok{ is Nan.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{if}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }
          \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Both left and right tail \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{s (}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{0}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{, \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceed \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{elif}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold }
            \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Right tail hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{ \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceeds \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
      \ControlFlowTok{elif}\NormalTok{ (    xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold }
            \KeywordTok{and}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{        no\_xi\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Left tail hat}\CharTok{\{\{}\SpecialStringTok{xi}\CharTok{\}\}}\SpecialStringTok{ \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{xi\_hats[}\DecValTok{0}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceeds \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{xi\_hat\_threshold}\SpecialCharTok{\}}\SpecialStringTok{.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
      
      \CommentTok{\# Check empirical variance in each Markov chain}
\NormalTok{      var }\OperatorTok{=}\NormalTok{ welford\_summary(expectand\_vals[c,:])[}\DecValTok{1}\NormalTok{]}
      \ControlFlowTok{if}\NormalTok{ var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{        no\_zvar\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Expectand exhibits \textquotesingle{}}
                          \StringTok{\textquotesingle{}vanishing empirical variance.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
    
    \CommentTok{\# Check split Rhat across Markov chains}
\NormalTok{    rhat }\OperatorTok{=}\NormalTok{ compute\_split\_rhat(expectand\_vals)}

    \ControlFlowTok{if}\NormalTok{ math.isnan(rhat):}
\NormalTok{      local\_message }\OperatorTok{+=} \StringTok{\textquotesingle{}  Split hat}\SpecialCharTok{\{R\}}\StringTok{ is ill{-}defined.}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}
    \ControlFlowTok{elif}\NormalTok{ rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{:}
\NormalTok{      no\_rhat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{      local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{      local\_message }\OperatorTok{+=} \SpecialStringTok{f\textquotesingle{}  Split hat}\CharTok{\{\{}\SpecialStringTok{R}\CharTok{\}\}}\SpecialStringTok{ (}\SpecialCharTok{\{}\NormalTok{rhat}\SpecialCharTok{:.3f\}}\SpecialStringTok{) exceeds 1.1.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}

    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{      tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(expectand\_vals[c,:])}

      \CommentTok{\# Check incremental empirical integrated autocorrelation time}
\NormalTok{      inc\_tau\_hat }\OperatorTok{=}\NormalTok{ tau\_hat }\OperatorTok{/}\NormalTok{ S}
      \ControlFlowTok{if}\NormalTok{ inc\_tau\_hat }\OperatorTok{\textgreater{}} \DecValTok{5}\NormalTok{:}
\NormalTok{        no\_inc\_tau\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: Incremental hat}\CharTok{\{\{}\SpecialStringTok{tau}\CharTok{\}\}}\SpecialStringTok{ \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{inc\_tau\_hat}\SpecialCharTok{:.1f\}}\SpecialStringTok{) is too large.}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
      \CommentTok{\# Check empirical effective sample size}
\NormalTok{      ess\_hat }\OperatorTok{=}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
      \ControlFlowTok{if}\NormalTok{ ess\_hat }\OperatorTok{\textless{}}\NormalTok{ min\_ess\_hat\_per\_chain:}
\NormalTok{        no\_ess\_hat\_warning }\OperatorTok{=} \VariableTok{False}
\NormalTok{        local\_warning }\OperatorTok{=} \VariableTok{True}
\NormalTok{        local\_message }\OperatorTok{+=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}  Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{: hat}\CharTok{\{\{}\SpecialStringTok{ESS}\CharTok{\}\}}\SpecialStringTok{ (}\SpecialCharTok{\{}\NormalTok{ess\_hat}\SpecialCharTok{:.1f\}}\SpecialStringTok{) \textquotesingle{}}
                          \StringTok{\textquotesingle{}is smaller than desired \textquotesingle{}}
                          \SpecialStringTok{f\textquotesingle{}(}\SpecialCharTok{\{}\NormalTok{min\_ess\_hat\_per\_chain}\SpecialCharTok{:.0f\}}\SpecialStringTok{).}\CharTok{\textbackslash{}n}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
    
    \ControlFlowTok{if}\NormalTok{ local\_warning:}
\NormalTok{      message }\OperatorTok{+=}\NormalTok{ local\_message }\OperatorTok{+} \StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}
  
  \ControlFlowTok{if}\NormalTok{ (    no\_xi\_hat\_warning }\KeywordTok{and}\NormalTok{ no\_zvar\_warning}
      \KeywordTok{and}\NormalTok{ no\_rhat\_warning   }\KeywordTok{and}\NormalTok{ no\_inc\_tau\_hat\_warning}
      \KeywordTok{and}\NormalTok{ no\_ess\_hat\_warning):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}All expectands checked appear to be behaving well enough \textquotesingle{}}
            \StringTok{\textquotesingle{}for reliable Markov chain Monte Carlo estimation.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    \ControlFlowTok{return}
  
  \BuiltInTok{print}\NormalTok{(message)}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_xi\_hat\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Large tail hat}\SpecialCharTok{\{xi\}}\StringTok{s suggest that the expectand \textquotesingle{}}
            \StringTok{\textquotesingle{}might not be sufficiently integrable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_zvar\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}If the expectands are not constant then zero empirical \textquotesingle{}}
            \StringTok{\textquotesingle{}variance suggests that the Markov transitions may be \textquotesingle{}}
            \StringTok{\textquotesingle{}misbehaving.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_rhat\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Split Rhat larger than 1.1 suggests that at least one of \textquotesingle{}}
            \StringTok{\textquotesingle{}the Markov chains has not reached an equilibrium.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}

  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_inc\_tau\_hat\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}If the incremental empirical integrated autocorrelation \textquotesingle{}}
            \StringTok{\textquotesingle{}times are too large then the Markov \textquotesingle{}}
            \StringTok{\textquotesingle{}chains have not explored long enough for the \textquotesingle{}}
            \StringTok{\textquotesingle{}autocorrelation estimates to be reliable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  
  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ no\_ess\_hat\_warning:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Small empirical effective sample sizes result in \textquotesingle{}}
            \StringTok{\textquotesingle{}imprecise Markov chain Monte Carlo estimators.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
  \ControlFlowTok{return}
\end{Highlighting}
\end{Shaded}

That said for particularly problematic fits the output from checking all
of the expectands can be overwhelming. In cases where that may be a risk
we can summarize the output more compactly.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Summary all expectand{-}specific diagnostics.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\CommentTok{\# @param min\_ess\_hat\_per\_chain The minimum empirical effective sample}
\CommentTok{\#                              size before a warning message is passed.}
\CommentTok{\# @param exclude\_zvar Binary variable to exclude all expectands with}
\CommentTok{\#                     vanishing empirical variance from other diagnostic}
\CommentTok{\#                     checks.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\KeywordTok{def}\NormalTok{ summarize\_expectand\_diagnostics(expectand\_vals\_dict,}
\NormalTok{                                    min\_ess\_hat\_per\_chain}\OperatorTok{=}\DecValTok{100}\NormalTok{,}
\NormalTok{                                    exclude\_zvar}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                                    max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
  \CommentTok{"""Summarize expectand diagnostics"""}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}

\NormalTok{  failed\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  failed\_xi\_hat\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  failed\_zvar\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  failed\_rhat\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  failed\_inc\_tau\_hat\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  failed\_ess\_hat\_names }\OperatorTok{=}\NormalTok{ []}

  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict:}
\NormalTok{    expectand\_vals }\OperatorTok{=}\NormalTok{ expectand\_vals\_dict[name]}
\NormalTok{    C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{    S }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{1}\NormalTok{]}
    
    \ControlFlowTok{if}\NormalTok{ exclude\_zvar:}
      \CommentTok{\# Check zero variance across all Markov chains for exclusion}
\NormalTok{      any\_zvar }\OperatorTok{=} \VariableTok{False}
      \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{        var }\OperatorTok{=}\NormalTok{ welford\_summary(expectand\_vals[c,:])[}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{          any\_zvar }\OperatorTok{=} \VariableTok{True}
      \ControlFlowTok{if}\NormalTok{ any\_zvar:}
        \ControlFlowTok{continue}
    
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
      \CommentTok{\# Check tail xi\_hats in each Markov chain}
\NormalTok{      xi\_hats }\OperatorTok{=}\NormalTok{ compute\_tail\_xi\_hats(expectand\_vals[c,:])}
\NormalTok{      xi\_hat\_threshold }\OperatorTok{=} \FloatTok{0.25}
      \ControlFlowTok{if}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{0}\NormalTok{]) }\KeywordTok{or}\NormalTok{ math.isnan(xi\_hats[}\DecValTok{1}\NormalTok{]):}
\NormalTok{        failed\_names.append(name)}
\NormalTok{        failed\_xi\_hat\_names.append(name)}
      \ControlFlowTok{if}\NormalTok{ (   xi\_hats[}\DecValTok{0}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold}
          \KeywordTok{or}\NormalTok{ xi\_hats[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=}\NormalTok{ xi\_hat\_threshold):}
\NormalTok{        failed\_names.append(name)}
\NormalTok{        failed\_xi\_hat\_names.append(name)}
    
      \CommentTok{\# Check empirical variance in each Markov chain}
\NormalTok{      var }\OperatorTok{=}\NormalTok{ welford\_summary(expectand\_vals[c,:])[}\DecValTok{1}\NormalTok{]}
      \ControlFlowTok{if}\NormalTok{ var }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
\NormalTok{        failed\_names.append(name)}
\NormalTok{        failed\_zvar\_names.append(name)}
    
    \CommentTok{\# Check split Rhat across Markov chains}
\NormalTok{    rhat }\OperatorTok{=}\NormalTok{ compute\_split\_rhat(expectand\_vals)}
    
    \ControlFlowTok{if}\NormalTok{ math.isnan(rhat):}
\NormalTok{      failed\_names.append(name)}
\NormalTok{      failed\_rhat\_names.append(name)}
    \ControlFlowTok{elif}\NormalTok{ rhat }\OperatorTok{\textgreater{}} \FloatTok{1.1}\NormalTok{:}
\NormalTok{      failed\_names.append(name)}
\NormalTok{      failed\_rhat\_names.append(name)}
    
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{      tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(expectand\_vals[c,:])}

      \CommentTok{\# Check incremental empirical integrated autocorrelation time}
\NormalTok{      inc\_tau\_hat }\OperatorTok{=}\NormalTok{ tau\_hat }\OperatorTok{/}\NormalTok{ S}
      \ControlFlowTok{if}\NormalTok{ inc\_tau\_hat }\OperatorTok{\textgreater{}} \DecValTok{5}\NormalTok{:}
\NormalTok{        failed\_names.append(name)}
\NormalTok{        failed\_inc\_tau\_hat\_names.append(name)}

      \CommentTok{\# Check empirical effective sample size}
\NormalTok{      ess\_hat }\OperatorTok{=}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
      
      \ControlFlowTok{if}\NormalTok{ ess\_hat }\OperatorTok{\textless{}}\NormalTok{ min\_ess\_hat\_per\_chain:}
\NormalTok{        failed\_names.append(name)}
\NormalTok{        failed\_ess\_hat\_names.append(name)}
  
\NormalTok{  failed\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered diagnostic warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}All expectands checked appear to be behaving well enough \textquotesingle{}}
            \StringTok{\textquotesingle{}for reliable Markov chain Monte Carlo estimation.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  
\NormalTok{  failed\_xi\_hat\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_xi\_hat\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_xi\_hat\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_xi\_hat\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered tail hat}\SpecialCharTok{\{xi\}}\StringTok{ warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}  Large tail hat}\SpecialCharTok{\{xi\}}\StringTok{s suggest that the expectand \textquotesingle{}}
            \StringTok{\textquotesingle{}might not be sufficiently integrable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
  
\NormalTok{  failed\_zvar\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_zvar\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_zvar\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_zvar\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered zero variance warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}  If the expectands are not constant then zero empirical\textquotesingle{}}
            \StringTok{\textquotesingle{} variance suggests that the Markov\textquotesingle{}}
            \StringTok{\textquotesingle{} transitions may be misbehaving.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
      
\NormalTok{  failed\_rhat\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_rhat\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_rhat\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_rhat\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered hat}\SpecialCharTok{\{R\}}\StringTok{ warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}  Split Rhat larger than 1.1 suggests that at \textquotesingle{}}
            \StringTok{\textquotesingle{}least one of the Markov chains has not reached \textquotesingle{}}
            \StringTok{\textquotesingle{}an equilibrium.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}

\NormalTok{  failed\_inc\_tau\_hat\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_inc\_tau\_hat\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_inc\_tau\_hat\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_rhat\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered incremental hat}\SpecialCharTok{\{tau\}}\StringTok{ warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}

\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}If the incremental empirical integrated autocorrelation \textquotesingle{}}
            \StringTok{\textquotesingle{}times per iteration are too large then the Markov \textquotesingle{}}
            \StringTok{\textquotesingle{}chains have not explored long enough for the \textquotesingle{}}
            \StringTok{\textquotesingle{}autocorrelation estimates to be reliable.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}

\NormalTok{  failed\_ess\_hat\_names }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(numpy.unique(failed\_ess\_hat\_names))}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(failed\_ess\_hat\_names):}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(failed\_ess\_hat\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
             \StringTok{\textquotesingle{}triggered hat}\SpecialCharTok{\{ESS\}}\StringTok{ warnings.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
    
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ (}\StringTok{\textquotesingle{}Small empirical effective sample sizes result in \textquotesingle{}}
            \StringTok{\textquotesingle{}imprecise Markov chain Monte Carlo estimators.\textquotesingle{}}\NormalTok{)}
\NormalTok{    desc }\OperatorTok{=}\NormalTok{ textwrap.wrap(desc, max\_width)}
\NormalTok{    desc.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(desc))}
\end{Highlighting}
\end{Shaded}

Alternatively we might filter the expectands, keeping only those of
immediate interest.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Filter \textasciigrave{}expectand\_vals\_dict\textasciigrave{} by name.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays for}
\CommentTok{\#                            each expectand.  The first dimension of}
\CommentTok{\#                            each element indexes the Markov chains and}
\CommentTok{\#                            the second dimension indexes the sequential}
\CommentTok{\#                            states within each Markov chain.}
\CommentTok{\# @param requested\_names List of expectand names to keep.}
\CommentTok{\# @param check\_arrays Binary variable indicating whether or not}
\CommentTok{\#                     requested names should be expanded to array}
\CommentTok{\#                     components.}
\CommentTok{\# @param max\_width Maximum line width for printing}
\CommentTok{\# @return A dictionary of two{-}dimensional arrays for each requested}
\CommentTok{\#         expectand.}
\KeywordTok{def}\NormalTok{ filter\_expectands(expectand\_vals\_dict, requested\_names,}
\NormalTok{                      check\_arrays}\OperatorTok{=}\VariableTok{False}\NormalTok{, max\_width}\OperatorTok{=}\DecValTok{72}\NormalTok{):}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(requested\_names) }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}requested\_names\textasciigrave{} \textquotesingle{}}
                     \StringTok{\textquotesingle{}must be non{-}empty.\textquotesingle{}}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ check\_arrays }\KeywordTok{is} \VariableTok{True}\NormalTok{:}
\NormalTok{    good\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    bad\_names }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ requested\_names:}
      \CommentTok{\# Search for array suffix}
\NormalTok{      array\_names }\OperatorTok{=}\NormalTok{ [ key }\ControlFlowTok{for}\NormalTok{ key }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict.keys()}
                      \ControlFlowTok{if}\NormalTok{ re.match(}\StringTok{\textquotesingle{}\^{}\textquotesingle{}} \OperatorTok{+}\NormalTok{ name }\OperatorTok{+} \StringTok{\textquotesingle{}\textbackslash{}[\textquotesingle{}}\NormalTok{, key) ]}
      \CommentTok{\# Append array names, if found}
      \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(array\_names) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        good\_names }\OperatorTok{+=}\NormalTok{ array\_names}
      \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ name }\KeywordTok{in}\NormalTok{ expectand\_vals\_dict.keys():}
          \CommentTok{\# Append bare name, if found}
\NormalTok{          good\_names.append(name)}
        \ControlFlowTok{else}\NormalTok{:}
          \CommentTok{\# Add to list of bad names}
\NormalTok{          bad\_names.append(name)}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    bad\_names }\OperatorTok{=} \OperatorTok{\textbackslash{}}
      \BuiltInTok{set}\NormalTok{(requested\_names).difference(expectand\_vals\_dict.keys())}
\NormalTok{    good\_names }\OperatorTok{=} \OperatorTok{\textbackslash{}}
      \BuiltInTok{set}\NormalTok{(requested\_names).intersection(expectand\_vals\_dict.keys())}
    
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(bad\_names) }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{    message }\OperatorTok{=}\NormalTok{ (}\SpecialStringTok{f\textquotesingle{}The expectands }\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(bad\_names)}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
               \StringTok{\textquotesingle{}were not found in the \textasciigrave{}expectand\_vals\_dict\textasciigrave{} \textquotesingle{}}
               \StringTok{\textquotesingle{}object and will be ignored.}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    message }\OperatorTok{=}\NormalTok{ textwrap.wrap(message, max\_width)}
\NormalTok{    message.append(}\StringTok{\textquotesingle{} \textquotesingle{}}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}}\CharTok{\textbackslash{}n}\StringTok{\textquotesingle{}}\NormalTok{.join(message))}
  
  \ControlFlowTok{return}\NormalTok{ \{ name: expectand\_vals\_dict[name] }\ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ good\_names \}}
\end{Highlighting}
\end{Shaded}

\subsection{Empirical Autocorrelation
Visualization}\label{empirical-autocorrelation-visualization}

If we encounter large empirical integrated autocorrelation times, or
small estimated effective sample sizes, then we may want to follow up
with the empirical autocorrelations themselves. An empirical correlogram
provides a useful visualization of these estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compute empirical autocorrelations for a given Markov chain sequence}
\CommentTok{\# @parmas vals A one{-}dimensional array of sequential expectand values.}
\CommentTok{\# @return A one{-}dimensional array of empirical autocorrelations at each}
\CommentTok{\#         lag up to the length of the sequence.}
\KeywordTok{def}\NormalTok{ compute\_rhos(vals):}
  \CommentTok{"""Visualize empirical autocorrelations for a given sequence"""}
  \CommentTok{\# Compute empirical autocorrelations}
\NormalTok{  N }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals)}
\NormalTok{  m, v }\OperatorTok{=}\NormalTok{ welford\_summary(vals)}
\NormalTok{  zs }\OperatorTok{=}\NormalTok{ [ val }\OperatorTok{{-}}\NormalTok{ m }\ControlFlowTok{for}\NormalTok{ val }\KeywordTok{in}\NormalTok{ vals ]}
  
  \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{:}
    \ControlFlowTok{return}\NormalTok{ [}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\NormalTok{ N}
  
\NormalTok{  B }\OperatorTok{=} \DecValTok{2}\OperatorTok{**}\NormalTok{math.ceil(math.log2(N)) }\CommentTok{\# Next power of 2 after N}
\NormalTok{  zs\_buff }\OperatorTok{=}\NormalTok{ zs }\OperatorTok{+}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ (B }\OperatorTok{{-}}\NormalTok{ N)}
  
\NormalTok{  Fs }\OperatorTok{=}\NormalTok{ numpy.fft.fft(zs\_buff)}
\NormalTok{  Ss }\OperatorTok{=}\NormalTok{ numpy.}\BuiltInTok{abs}\NormalTok{(Fs)}\OperatorTok{**}\DecValTok{2}
\NormalTok{  Rs }\OperatorTok{=}\NormalTok{ numpy.fft.ifft(Ss)}
  
\NormalTok{  acov\_buff }\OperatorTok{=}\NormalTok{ numpy.real(Rs)}
\NormalTok{  rhos }\OperatorTok{=}\NormalTok{ acov\_buff[}\DecValTok{0}\NormalTok{:N] }\OperatorTok{/}\NormalTok{ acov\_buff[}\DecValTok{0}\NormalTok{]}
  
  \CommentTok{\# Drop last lag if (L + 1) is odd so that the lag pairs are complete}
\NormalTok{  L }\OperatorTok{=}\NormalTok{ N}
  \ControlFlowTok{if}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{\%} \DecValTok{2} \OperatorTok{==} \DecValTok{1}\NormalTok{:}
\NormalTok{    L }\OperatorTok{=}\NormalTok{ L }\OperatorTok{{-}} \DecValTok{1}
  
  \CommentTok{\# Number of lag pairs}
\NormalTok{  P }\OperatorTok{=}\NormalTok{ (L }\OperatorTok{+} \DecValTok{1}\NormalTok{) }\OperatorTok{//} \DecValTok{2}
  
  \CommentTok{\# Construct asymptotic correlation from initial monotone sequence}
\NormalTok{  old\_pair\_sum }\OperatorTok{=}\NormalTok{ rhos[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2}\NormalTok{]}
\NormalTok{  max\_L }\OperatorTok{=}\NormalTok{ N}
  
  \ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, P):}
\NormalTok{    current\_pair\_sum }\OperatorTok{=}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p] }\OperatorTok{+}\NormalTok{ rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{+} \DecValTok{1}\NormalTok{]}
    
    \ControlFlowTok{if}\NormalTok{ current\_pair\_sum }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{:}
\NormalTok{      max\_L }\OperatorTok{=} \DecValTok{2} \OperatorTok{*}\NormalTok{ p}
\NormalTok{      rhos[max\_L:N] }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ (N }\OperatorTok{{-}}\NormalTok{ max\_L)}
      \ControlFlowTok{break}
    
    \ControlFlowTok{if}\NormalTok{ current\_pair\_sum }\OperatorTok{\textgreater{}}\NormalTok{ old\_pair\_sum:}
\NormalTok{      current\_pair\_sum }\OperatorTok{=}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p]     }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
\NormalTok{      rhos[}\DecValTok{2} \OperatorTok{*}\NormalTok{ p }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ old\_pair\_sum}
    
    \CommentTok{\# if p == P:}
      \CommentTok{\# throw some kind of error when autocorrelation}
      \CommentTok{\# sequence doesn\textquotesingle{}t get terminated}
    
\NormalTok{    old\_pair\_sum }\OperatorTok{=}\NormalTok{ current\_pair\_sum}
  
  \ControlFlowTok{return}\NormalTok{ rhos}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot empirical correlograms for a given expectand across a Markov}
\CommentTok{\# chain ensemble.}
\CommentTok{\# @ax Matplotlib axis object}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param max\_L Maximum autocorrelation lag}
\CommentTok{\# @param rho\_lim Plotting range of autocorrelation values}
\CommentTok{\# @display\_name Name of expectand}
\KeywordTok{def}\NormalTok{ plot\_empirical\_correlogram(ax,}
\NormalTok{                               expectand\_vals,}
\NormalTok{                               max\_L,}
\NormalTok{                               rho\_lim}\OperatorTok{=}\NormalTok{[}\OperatorTok{{-}}\FloatTok{0.2}\NormalTok{, }\FloatTok{1.1}\NormalTok{],}
\NormalTok{                               name}\OperatorTok{=}\StringTok{""}\NormalTok{):}
  \CommentTok{"""Plot empirical correlograms for a given expectand across a Markov}
\CommentTok{     chain ensemble."""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}

\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
  
\NormalTok{  idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_L) }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
\NormalTok{  xs }\OperatorTok{=}\NormalTok{ [ idx }\OperatorTok{+}\NormalTok{ delta }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_L) }\ControlFlowTok{for}\NormalTok{ delta }\KeywordTok{in}\NormalTok{ [}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{]]}
  
\NormalTok{  colors }\OperatorTok{=}\NormalTok{ [dark, dark\_highlight, mid, light\_highlight]}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    rhos }\OperatorTok{=}\NormalTok{ compute\_rhos(expectand\_vals[c,:])}
\NormalTok{    pad\_rhos }\OperatorTok{=}\NormalTok{ [ rhos[idx] }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in}\NormalTok{ idxs ]}
\NormalTok{    ax.plot(xs, pad\_rhos, colors[c }\OperatorTok{\%} \DecValTok{4}\NormalTok{], linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
  
\NormalTok{  ax.axhline(y}\OperatorTok{=}\DecValTok{0}\NormalTok{, linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{, color}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{)}
  
\NormalTok{  ax.set\_title(name)}
\NormalTok{  ax.set\_xlabel(}\StringTok{"Lag"}\NormalTok{)}
\NormalTok{  ax.set\_xlim(}\OperatorTok{{-}}\FloatTok{0.5}\NormalTok{, max\_L }\OperatorTok{+} \FloatTok{0.5}\NormalTok{)}
\NormalTok{  ax.set\_ylabel(}\StringTok{"Empirical}\CharTok{\textbackslash{}n}\StringTok{Autocorrelation"}\NormalTok{)}
\NormalTok{  ax.set\_ylim(rho\_lim[}\DecValTok{0}\NormalTok{], rho\_lim[}\DecValTok{1}\NormalTok{])}
\NormalTok{  ax.spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{  ax.spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Chain-Separated Pairs
Plot}\label{chain-separated-pairs-plot}

We can also visualize strong autocorrelations by coloring the states of
each Markov chain in a continuous gradient. When neighboring states are
strongly correlated these colors will appear to vary smoothly across the
ambient space. More productive Markov transitions result in a more
chaotic spray of colors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Visualize the projection of a Markov chain ensemble along two}
\CommentTok{\# expectands as a pairs plot.  Point colors darken along each Markov}
\CommentTok{\# chain to visualize the autocorrelation.}
\CommentTok{\# @param expectand1\_vals A two{-}dimensional array of expectand values}
\CommentTok{\#                        with the first dimension indexing the Markov}
\CommentTok{\#                        chains and the second dimension indexing the}
\CommentTok{\#                        sequential states within each Markov chain.}
\CommentTok{\# @params display\_name1 Name of first expectand}
\CommentTok{\# @param expectand2\_vals A two{-}dimensional array of expectand values}
\CommentTok{\#                        with the first dimension indexing the Markov}
\CommentTok{\#                        chains and the second dimension indexing the}
\CommentTok{\#                        sequential states within each Markov chain}
\CommentTok{\# @params display\_name2 Name of second expectand}
\KeywordTok{def}\NormalTok{ plot\_pairs\_by\_chain(expectand1\_vals, display\_name1,}
\NormalTok{                        expectand2\_vals, display\_name2):}
  \CommentTok{"""Plot two expectand output ensembles against each other separated by}
\CommentTok{     Markov chain """}
\NormalTok{  validate\_array(expectand1\_vals, }\StringTok{\textquotesingle{}expectand1\_vals\textquotesingle{}}\NormalTok{)}
\NormalTok{  C1 }\OperatorTok{=}\NormalTok{ expectand1\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S1 }\OperatorTok{=}\NormalTok{ expectand1\_vals.shape[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  validate\_array(expectand2\_vals, }\StringTok{\textquotesingle{}expectand2\_vals\textquotesingle{}}\NormalTok{)}
\NormalTok{  C2 }\OperatorTok{=}\NormalTok{ expectand2\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S2 }\OperatorTok{=}\NormalTok{ expectand2\_vals.shape[}\DecValTok{1}\NormalTok{]}
    
  \ControlFlowTok{if}\NormalTok{ C1 }\OperatorTok{!=}\NormalTok{ C2:}
\NormalTok{    C }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(C1, C2)}
\NormalTok{    C1 }\OperatorTok{=}\NormalTok{ C}
\NormalTok{    C2 }\OperatorTok{=}\NormalTok{ C}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Plotting only }\SpecialCharTok{\{}\NormalTok{C}\SpecialCharTok{\}}\SpecialStringTok{ Markov chains.\textquotesingle{}}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ S1 }\OperatorTok{!=}\NormalTok{ S2:}
\NormalTok{    S }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(S1, S2)}
\NormalTok{    S1 }\OperatorTok{=}\NormalTok{ S}
\NormalTok{    S2 }\OperatorTok{=}\NormalTok{ S}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Plotting only }\SpecialCharTok{\{}\NormalTok{S}\SpecialCharTok{\}}\SpecialStringTok{ samples per Markov chain.\textquotesingle{}}\NormalTok{)}
  
\NormalTok{  colors }\OperatorTok{=}\NormalTok{ [}\StringTok{"\#DCBCBC"}\NormalTok{, }\StringTok{"\#C79999"}\NormalTok{, }\StringTok{"\#B97C7C"}\NormalTok{,}
            \StringTok{"\#A25050"}\NormalTok{, }\StringTok{"\#8F2727"}\NormalTok{, }\StringTok{"\#7C0000"}\NormalTok{]}
\NormalTok{  cmap }\OperatorTok{=}\NormalTok{ LinearSegmentedColormap.from\_list(}\StringTok{"reds"}\NormalTok{, colors, N}\OperatorTok{=}\NormalTok{S1)}

\NormalTok{  min\_x }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(expectand1\_vals.flatten())}
\NormalTok{  max\_x }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(expectand1\_vals.flatten())}
  
\NormalTok{  min\_y }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(expectand2\_vals.flatten())}
\NormalTok{  max\_y }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(expectand2\_vals.flatten())}
  
\NormalTok{  N\_plots }\OperatorTok{=}\NormalTok{ C1}
\NormalTok{  N\_cols }\OperatorTok{=} \DecValTok{2}
\NormalTok{  N\_rows }\OperatorTok{=}\NormalTok{ math.ceil(N\_plots }\OperatorTok{/}\NormalTok{ N\_cols)}
\NormalTok{  f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(N\_rows, N\_cols, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}
\NormalTok{  k }\OperatorTok{=} \DecValTok{0}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C1):}
\NormalTok{    idx1 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{//}\NormalTok{ N\_cols}
\NormalTok{    idx2 }\OperatorTok{=}\NormalTok{ k }\OperatorTok{\%}\NormalTok{ N\_cols}
\NormalTok{    k }\OperatorTok{+=} \DecValTok{1}
    
\NormalTok{    axarr[idx1, idx2].scatter(expectand1\_vals.flatten(),}
\NormalTok{                              expectand2\_vals.flatten(),}
\NormalTok{                              color}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{, s}\OperatorTok{=}\DecValTok{5}\NormalTok{, zorder}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].scatter(expectand1\_vals[c,:], expectand2\_vals[c,:],}
\NormalTok{                              cmap}\OperatorTok{=}\NormalTok{cmap, c}\OperatorTok{=}\BuiltInTok{range}\NormalTok{(S1), s}\OperatorTok{=}\DecValTok{5}\NormalTok{, zorder}\OperatorTok{=}\DecValTok{4}\NormalTok{)}
    
\NormalTok{    axarr[idx1, idx2].set\_title(}\SpecialStringTok{f\textquotesingle{}Chain }\SpecialCharTok{\{}\NormalTok{c }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{\textquotesingle{}}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].set\_xlabel(display\_name1)}
\NormalTok{    axarr[idx1, idx2].set\_xlim([min\_x, max\_x])}
\NormalTok{    axarr[idx1, idx2].set\_ylabel(display\_name2)}
\NormalTok{    axarr[idx1, idx2].set\_ylim([min\_y, max\_y])}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    axarr[idx1, idx2].spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
  
\NormalTok{  plot.show()}
\end{Highlighting}
\end{Shaded}

\section{Markov Chain Monte Carlo
Estimation}\label{markov-chain-monte-carlo-estimation}

If none of the diagnostics indicate an obstruction to a Markov chain
Monte Carlo central limit theorem then we can construct expectation
value estimates and their standard errors.

When interested in expectands that have not already been computed we
will need to evaluate the existing samples on these new functions,
generating pushforward samples. This is particularly straightforward for
functions with a single input variable.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Evaluate an expectand on the values of a one{-}dimensional input}
\CommentTok{\# variable.}
\CommentTok{\# @param input\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                   the first dimension indexing the Markov chains}
\CommentTok{\#                   and the second dimension indexing the sequential}
\CommentTok{\#                   states within each Markov chain.}
\CommentTok{\# @param expectand Scalar function to be applied to the Markov chain}
\CommentTok{\#                  states.}
\CommentTok{\# @return A two{-}dimensional array of expectand values with the}
\CommentTok{\#         first dimension indexing the Markov chains and the}
\CommentTok{\#         second dimension indexing the sequential states within}
\CommentTok{\#         each Markov chain.}
\KeywordTok{def}\NormalTok{ eval\_uni\_expectand\_pushforward(input\_vals, expectand):}
  \CommentTok{"""Evaluate an expectand along a Markov chain"""}
  \ControlFlowTok{return}\NormalTok{ numpy.vectorize(expectand)(input\_vals)}
\end{Highlighting}
\end{Shaded}

Pushing samples forward along more complicated functions is a bit
trickier to implement.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a numpy array of element names from the specified dimensions.}
\CommentTok{\# For example \textasciigrave{}name\_array(\textquotesingle{}x\textquotesingle{}, [2, 3]))\textasciigrave{} returns the array}
\CommentTok{\# \textgreater{}\textgreater{} array([[\textquotesingle{}x[1,1]\textquotesingle{}, \textquotesingle{}x[1,2]\textquotesingle{}, \textquotesingle{}x[1,3]\textquotesingle{}],}
\CommentTok{\# \textgreater{}\textgreater{}        [\textquotesingle{}x[2,1]\textquotesingle{}, \textquotesingle{}x[2,2]\textquotesingle{}, \textquotesingle{}x[2,3]\textquotesingle{}]], dtype=\textquotesingle{}\textless{}U6\textquotesingle{})}
\CommentTok{\# @ param base Base name.}
\CommentTok{\# @ param dims Vector of array dimensions.}
\CommentTok{\# @ return Array of element names with dimensions given by dims.}
\KeywordTok{def}\NormalTok{ name\_array(base, dims):}
  \CommentTok{\# Validate inputs}
  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(base, }\BuiltInTok{str}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Input variable }\SpecialCharTok{\{}\NormalTok{base}\SpecialCharTok{\}}\SpecialStringTok{ is not a string.\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(dims, }\BuiltInTok{list}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}Input variable }\SpecialCharTok{\{}\NormalTok{dims}\SpecialCharTok{\}}\SpecialStringTok{ is not a list.\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{all}\NormalTok{([ }\BuiltInTok{isinstance}\NormalTok{(d, }\BuiltInTok{int}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ d }\KeywordTok{in}\NormalTok{ dims ]):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}The elements of input variable }\SpecialCharTok{\{}\NormalTok{dims}\SpecialCharTok{\}}\SpecialStringTok{ \textquotesingle{}}
                      \StringTok{\textquotesingle{}are not all integers.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Create element names and format them into desired array.}
  \ControlFlowTok{return}\NormalTok{ numpy.array(name\_nested\_list(base, dims))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Evaluate a dictionary of expectands on the values of an arbitrary}
\CommentTok{\# number of input variables.  Expectands must all return a float,}
\CommentTok{\# integer, or logical output.}
\CommentTok{\#}
\CommentTok{\# By default expectand argument values are accessed by name}
\CommentTok{\# in expectand\_vals\_dict.  If a non{-}null alt\_arg\_names is provided then}
\CommentTok{\# the alternate names are used to access values in expectand\_vals\_dict.}
\CommentTok{\# The elements of alt\_arg\_names can also be numpy arrays of arbitrary}
\CommentTok{\# dimension in which case the individual element values are first}
\CommentTok{\# accessed then formatted into matching numpy arrays before being}
\CommentTok{\# passed to the expectand.}
\CommentTok{\#}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays.}
\CommentTok{\#                            The first dimension of each element indexes}
\CommentTok{\#                            the Markov chains and the second dimension}
\CommentTok{\#                            indexes the sequential states within each}
\CommentTok{\#                            Markov chain.}
\CommentTok{\# @param expectand\_dict List of functions with the same arguments.}
\CommentTok{\# @param alt\_arg\_names Optional dictionary of alternate names for the}
\CommentTok{\#                      nominal expectand argument names; when used all}
\CommentTok{\#                      expectand argument names must be included.}
\CommentTok{\# @return A list of two{-}dimensional arrays, one for each element of}
\CommentTok{\#         expectand\_list with the same keys as expectand\_dict.}
\KeywordTok{def}\NormalTok{ eval\_expectand\_pushforwards(expectand\_vals\_dict,}
\NormalTok{                                expectand\_dict,}
\NormalTok{                                alt\_arg\_names}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
  \CommentTok{"""Evaluate a collection of expectands on the values of an arbitrary}
\CommentTok{     number of input variables."""}
  \CommentTok{\# Validate inputs}
\NormalTok{  validate\_dict\_of\_arrays(expectand\_vals\_dict, }\StringTok{\textquotesingle{}expectand\_vals\_dict\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(expectand\_dict, }\BuiltInTok{dict}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}expectand\_dict\textasciigrave{} is \textquotesingle{}}
                    \StringTok{\textquotesingle{}not a dictionary.\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{all}\NormalTok{([ }\BuiltInTok{callable}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ expectand\_dict.items() ]):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\StringTok{\textquotesingle{}The elements of input variable \textasciigrave{}expectand\_dict\textasciigrave{} \textquotesingle{}}
                    \StringTok{\textquotesingle{}are not all functions.\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if}\NormalTok{ alt\_arg\_names }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
    \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(alt\_arg\_names, }\BuiltInTok{dict}\NormalTok{):}
      \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{(}\StringTok{\textquotesingle{}Input variable \textasciigrave{}alt\_arg\_names\textasciigrave{} \textquotesingle{}}
                      \StringTok{\textquotesingle{}is not a dictionary.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Check existence of all expectand arguments}
  \KeywordTok{def}\NormalTok{ compare\_args(e):}
    \ControlFlowTok{return}\NormalTok{ (   }\BuiltInTok{set}\NormalTok{(inspect.getfullargspec(e).args)}
            \OperatorTok{==} \BuiltInTok{set}\NormalTok{(nominal\_arg\_names)              )}

\NormalTok{  nominal\_arg\_names }\OperatorTok{=}\NormalTok{ []}
\NormalTok{  arg\_consistency }\OperatorTok{=} \VariableTok{True}
  \ControlFlowTok{for}\NormalTok{ e }\KeywordTok{in}\NormalTok{ expectand\_dict.values():}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ nominal\_arg\_names:}
\NormalTok{      nominal\_arg\_names }\OperatorTok{=}\NormalTok{ inspect.getfullargspec(e).args}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{      arg\_consistency }\OperatorTok{\&=}\NormalTok{ compare\_args(e)}

  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ arg\_consistency:}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{\textquotesingle{}The arguments of the functions in \textquotesingle{}}
                     \StringTok{\textquotesingle{}\textasciigrave{}expectand\_list\textasciigrave{} are not consistent \textquotesingle{}}
                     \StringTok{\textquotesingle{}with each other.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Ensure that all argument replacements are arrays}
  \ControlFlowTok{if}\NormalTok{ alt\_arg\_names }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    alt\_arg\_names\_array }\OperatorTok{=}\NormalTok{ \{ k: numpy.array(v)}
                            \ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ alt\_arg\_names.items() \}}

  \CommentTok{\# Check existence of all expectand arguments}
  \ControlFlowTok{if}\NormalTok{ alt\_arg\_names }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{    check\_arg\_names }\OperatorTok{=}\NormalTok{ nominal\_arg\_names}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    alt\_keys }\OperatorTok{=}\NormalTok{ alt\_arg\_names.keys()}
\NormalTok{    missing\_args }\OperatorTok{=} \BuiltInTok{set}\NormalTok{(nominal\_arg\_names).difference(alt\_keys)}

    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(missing\_args) }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
      \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}The nominal expectand argument \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(missing\_args)}\SpecialCharTok{\}}\SpecialStringTok{ does not have \textquotesingle{}}
                        \StringTok{\textquotesingle{}a replacement in \textasciigrave{}alt\_arg\_names\textasciigrave{}.\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{elif} \BuiltInTok{len}\NormalTok{(missing\_args) }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
      \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}The nominal expectand arguments \textquotesingle{}}
                       \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(missing\_args)}\SpecialCharTok{\}}\SpecialStringTok{ do not have \textquotesingle{}}
                        \StringTok{\textquotesingle{}replacements in \textasciigrave{}alt\_arg\_names\textasciigrave{}.\textquotesingle{}}\NormalTok{)}

\NormalTok{    arglistlist }\OperatorTok{=}\NormalTok{ [ v.flatten().tolist()}
                    \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(v, numpy.ndarray)}
                    \ControlFlowTok{else}\NormalTok{ [v]}
                    \ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ alt\_arg\_names.items() ]}
\NormalTok{    check\_arg\_names }\OperatorTok{=}\NormalTok{ [ arg }\ControlFlowTok{for}\NormalTok{ arglist }\KeywordTok{in}\NormalTok{ arglistlist}
                        \ControlFlowTok{for}\NormalTok{ arg }\KeywordTok{in}\NormalTok{ arglist ]}

\NormalTok{  missing\_args }\OperatorTok{=} \OperatorTok{\textbackslash{}}
    \BuiltInTok{set}\NormalTok{(check\_arg\_names).difference(expectand\_vals\_dict.keys())}
  \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(missing\_args) }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}The expectand argument \textquotesingle{}}
                     \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(missing\_args)}\SpecialCharTok{\}}\SpecialStringTok{ is not in \textquotesingle{}}
                      \StringTok{\textquotesingle{}\textasciigrave{}expectand\_vals\_dict\textasciigrave{}.\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{elif} \BuiltInTok{len}\NormalTok{(missing\_args) }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{( }\StringTok{\textquotesingle{}The expectand arguments \textquotesingle{}}
                     \SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\StringTok{", "}\SpecialCharTok{.}\NormalTok{join(missing\_args)}\SpecialCharTok{\}}\SpecialStringTok{ are not in \textquotesingle{}}
                      \StringTok{\textquotesingle{}\textasciigrave{}expectand\_vals\_dict\textasciigrave{}.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Apply expectand to all inputs}
\NormalTok{  C }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(expectand\_vals\_dict.values())).shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  S }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(expectand\_vals\_dict.values())).shape[}\DecValTok{1}\NormalTok{]}

\NormalTok{  pushforward\_vals }\OperatorTok{=}\NormalTok{ \{ k: numpy.zeros([C, S])}
                       \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ expectand\_dict.keys() \}}

  \ControlFlowTok{if}\NormalTok{ alt\_arg\_names }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    alt\_names }\OperatorTok{=}\NormalTok{ [ alt\_arg\_names[name]}
                  \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ nominal\_arg\_names ]}

  \KeywordTok{def}\NormalTok{ access\_val(name):}
    \ControlFlowTok{return}\NormalTok{ expectand\_vals\_dict[name][c, s]}

  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
    \ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(S):}
      \ControlFlowTok{if}\NormalTok{ alt\_arg\_names }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        arg\_vals }\OperatorTok{=}\NormalTok{ [ access\_val(name)}
                     \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ nominal\_arg\_names ]}
      \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        arg\_vals }\OperatorTok{=}\NormalTok{ [ numpy.vectorize(access\_val)(name)}
                     \ControlFlowTok{for}\NormalTok{ name }\KeywordTok{in}\NormalTok{ alt\_names ]}

      \ControlFlowTok{for}\NormalTok{ n, e }\KeywordTok{in}\NormalTok{ expectand\_dict.items():}
\NormalTok{        pushforward\_vals[n][c, s] }\OperatorTok{=}\NormalTok{ e(}\OperatorTok{*}\NormalTok{arg\_vals)}

  \ControlFlowTok{return}\NormalTok{ pushforward\_vals}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Evaluate an expectand on the values of an arbitrary number of input}
\CommentTok{\# variables.  Expectands must all return a float, integer, or logical}
\CommentTok{\# output.}
\CommentTok{\#}
\CommentTok{\# By default expectand argument values are accessed by name}
\CommentTok{\# in expectand\_vals\_dict.  If a non{-}null alt\_arg\_names is provided then}
\CommentTok{\# the alternate names are used to access values in expectand\_vals\_dict.}
\CommentTok{\# The elements of alt\_arg\_names can also be numpy arrays of arbitrary}
\CommentTok{\# dimension in which case the individual element values are first}
\CommentTok{\# accessed then formatted into matching numpy arrays before being}
\CommentTok{\# passed to the expectand.}
\CommentTok{\#}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays.}
\CommentTok{\#                            The first dimension of each element indexes}
\CommentTok{\#                            the Markov chains and the second dimension}
\CommentTok{\#                            indexes the sequential states within each}
\CommentTok{\#                            Markov chain.}
\CommentTok{\# @param expectand Functions with arbitrary number of scalar and array}
\CommentTok{\#                  input arguments.}
\CommentTok{\# @param alt\_arg\_names Optional dictionary of alternate names for the}
\CommentTok{\#                      nominal expectand argument names; when used all}
\CommentTok{\#                      expectand argument names must be included.}
\CommentTok{\# @return A two{-}dimensional array.}
\KeywordTok{def}\NormalTok{ eval\_expectand\_pushforward(expectand\_vals\_dict,}
\NormalTok{                               expectand,}
\NormalTok{                               alt\_arg\_names}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{  pushforward\_vals }\OperatorTok{=}\NormalTok{ eval\_expectand\_pushforwards(expectand\_vals\_dict,}
\NormalTok{                                                 \{ }\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{: expectand \},}
\NormalTok{                                                 alt\_arg\_names)}
  \ControlFlowTok{return}\NormalTok{ pushforward\_vals[}\StringTok{\textquotesingle{}e\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Regardless of whether the expectand samples were generated by
\texttt{Stan} or if we had to derive them ourselves the Markov chain
Monte Carlo estimation is the same. In particular we can estimate
expectation values using either a single Markov chain or an entire
ensemble of Markov chains.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate expectand expectation value from a single Markov chain.}
\CommentTok{\# @param vals A one{-}dimensional array of sequential expectand values.}
\CommentTok{\# @return The Markov chain Monte Carlo estimate, its estimated standard}
\CommentTok{\#         error, and empirical effective sample size.}
\KeywordTok{def}\NormalTok{ mcmc\_est(vals):}
  \CommentTok{"""Estimate expectand expectation value from a Markov chain"""}
\NormalTok{  S }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(vals)}
  \ControlFlowTok{if}\NormalTok{ S }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \ControlFlowTok{return}\NormalTok{ [vals[}\DecValTok{0}\NormalTok{], }\DecValTok{0}\NormalTok{, math.nan]}
  
\NormalTok{  summary }\OperatorTok{=}\NormalTok{ welford\_summary(vals)}
  
  \ControlFlowTok{if}\NormalTok{ summary[}\DecValTok{1}\NormalTok{] }\OperatorTok{==} \DecValTok{0}\NormalTok{:}
    \ControlFlowTok{return}\NormalTok{ [summary[}\DecValTok{0}\NormalTok{], }\DecValTok{0}\NormalTok{, math.nan]}
  
\NormalTok{  tau\_hat }\OperatorTok{=}\NormalTok{ compute\_tau\_hat(vals)}
\NormalTok{  ess\_hat }\OperatorTok{=}\NormalTok{ S }\OperatorTok{/}\NormalTok{ tau\_hat}
  \ControlFlowTok{return}\NormalTok{ [summary[}\DecValTok{0}\NormalTok{], math.sqrt(summary[}\DecValTok{1}\NormalTok{] }\OperatorTok{/}\NormalTok{ ess\_hat), ess\_hat]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate expectand expectation value from a Markov chain ensemble.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @return The ensemble Markov chain Monte Carlo estimate, its estimated}
\CommentTok{\#         standard error, and empirical effective sample size.}
\KeywordTok{def}\NormalTok{ ensemble\_mcmc\_est(expectand\_vals):}
  \CommentTok{"""Estimate expectand expectation value from a collection of}
\CommentTok{     Markov chains"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
    
\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
\NormalTok{  chain\_ests }\OperatorTok{=}\NormalTok{ [ mcmc\_est(expectand\_vals[c,:]) }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C) ]}
  
  \CommentTok{\# Total effective sample size}
\NormalTok{  total\_ess }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{([ est[}\DecValTok{2}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ est }\KeywordTok{in}\NormalTok{ chain\_ests ])}
  
  \ControlFlowTok{if}\NormalTok{ math.isnan(total\_ess):}
\NormalTok{    m  }\OperatorTok{=}\NormalTok{ numpy.mean([ est[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ est }\KeywordTok{in}\NormalTok{ chain\_ests ])}
\NormalTok{    se }\OperatorTok{=}\NormalTok{ numpy.mean([ est[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ est }\KeywordTok{in}\NormalTok{ chain\_ests ])}
    \ControlFlowTok{return}\NormalTok{ [m, se, math.nan]}
  
  \CommentTok{\# Ensemble average weighted by effective sample size}
\NormalTok{  mean }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{([ est[}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ est[}\DecValTok{2}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ est }\KeywordTok{in}\NormalTok{ chain\_ests ]) }\OperatorTok{/}\NormalTok{ total\_ess}

  \CommentTok{\# Ensemble variance weighed by effective sample size}
  \CommentTok{\# including correction for the fact that individual Markov chain}
  \CommentTok{\# variances are defined relative to the individual mean estimators}
  \CommentTok{\# and not the ensemble mean estimator}
  \BuiltInTok{vars} \OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ C}
  
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    est }\OperatorTok{=}\NormalTok{ chain\_ests[c]}
\NormalTok{    chain\_var }\OperatorTok{=}\NormalTok{ est[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\NormalTok{ est[}\DecValTok{1}\NormalTok{]}\OperatorTok{**}\DecValTok{2}
\NormalTok{    var\_update }\OperatorTok{=}\NormalTok{ (est[}\DecValTok{0}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ mean)}\OperatorTok{**}\DecValTok{2}
    \BuiltInTok{vars}\NormalTok{[c] }\OperatorTok{=}\NormalTok{ est[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\NormalTok{ (var\_update }\OperatorTok{+}\NormalTok{ chain\_var)}
\NormalTok{  var }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(}\BuiltInTok{vars}\NormalTok{) }\OperatorTok{/}\NormalTok{ total\_ess}

  \ControlFlowTok{return}\NormalTok{ [mean, math.sqrt(var }\OperatorTok{/}\NormalTok{ total\_ess), total\_ess]}
\end{Highlighting}
\end{Shaded}

A particularly common probabilistic calculation is estimating the
probability allocated to subsets that are defined only implicitly by an
indicator function. In practice we can estimate this probability by
pushing samples forward along the indicator function and then
constructing the Markov chain Monte Carlo expectation value estimator.
These two steps occur together so often that it's helpful to wrap them
into a dedicated function.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate the probability allocated to a subset implicitly defined by}
\CommentTok{\# an indicator function.}
\CommentTok{\# @param expectand\_vals\_dict A dictionary of two{-}dimensional arrays.}
\CommentTok{\#                            The first dimension of each element indexes}
\CommentTok{\#                            the Markov chains and the second dimension}
\CommentTok{\#                            indexes the sequential states within each}
\CommentTok{\#                            Markov chain.}
\CommentTok{\# @param indicator Function with logical or 0/1 numeric outputs.}
\CommentTok{\# @param alt\_arg\_names Optional dictionary of alternate names for the}
\CommentTok{\#                      nominal expectand argument names; when used all}
\CommentTok{\#                      expectand argument names must be included.}
\CommentTok{\# @return The probability estimate and its standard error.}
\KeywordTok{def}\NormalTok{ implicit\_subset\_prob(expectand\_vals\_dict,}
\NormalTok{                         indicator,}
\NormalTok{                         alt\_arg\_names):}
  \CommentTok{\# Evaluate indicator function}
\NormalTok{  indicator\_samples }\OperatorTok{=}\NormalTok{ eval\_expectand\_pushforward(expectand\_vals\_dict,}
\NormalTok{                                                 indicator,}
\NormalTok{                                                 alt\_arg\_names)}

  \CommentTok{\# Verify outputs}
\NormalTok{  unique\_vals }\OperatorTok{=} \BuiltInTok{set}\NormalTok{(indicator\_samples.flatten())}

  \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ (  unique\_vals }\OperatorTok{==} \BuiltInTok{set}\NormalTok{([}\DecValTok{0}\NormalTok{])}
          \OperatorTok{|}\NormalTok{ unique\_vals }\OperatorTok{==} \BuiltInTok{set}\NormalTok{([}\DecValTok{1}\NormalTok{])}
          \OperatorTok{|}\NormalTok{ unique\_vals }\OperatorTok{==} \BuiltInTok{set}\NormalTok{([}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{])):}
    \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(}\StringTok{\textquotesingle{}The function \textasciigrave{}indicator\textasciigrave{} must return only \textquotesingle{}}
                     \StringTok{\textquotesingle{}logical or 0/1 numeric outputs.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Return probability as expectation value of indicator function}
  \ControlFlowTok{return}\NormalTok{ ensemble\_mcmc\_est(indicator\_samples)[}\DecValTok{0}\NormalTok{:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

We can also use realized Markov chains to estimate quantiles of the
pushforward distribution along an expectand. Within a single Markov
chain ordering the expectand values allow us to efficiently search for
the value \(x_{q}\) whose corresponding interval probability first
exceeds the defining quantile probability \(p\), \begin{align*}
p
&<
\pi( \, \{ -\infty, x_{q} ] \, )
\\
&=
\mathbb{E}_{\pi} \left[ I_{ \{ -\infty, x_{q} ] } \right]
\\
&\approx
\frac{1}{N} \sum_{n = 1}^{N} I_{ \{ -\infty,  x_{q} ] }( \tilde{x}_{n}).
\end{align*} The empirical quantiles within each Markov chain can then
be averaged together to provide an ensemble estimator.

In theory the empirical standard deviation of the individual Markov
chain estimates consistently estimates the estimator error, but the
estimation is unreliable without many Markov chains. Consequently it is
not reported here.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Estimate expectand pushforward quantiles from a Markov chain ensemble.}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param probs An array of quantile percentages in [0, 100].}
\CommentTok{\# @return The ensemble Markov chain Monte Carlo quantile estimate.}
\KeywordTok{def}\NormalTok{ ensemble\_mcmc\_quantile\_est(expectand\_vals, probs):}
  \CommentTok{\# Validate inputs}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}

  \ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(probs, }\BuiltInTok{list}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{TypeError}\NormalTok{((}\StringTok{\textquotesingle{}Input variable \textasciigrave{}probs\textasciigrave{} is not a list.\textquotesingle{}}\NormalTok{))}

  \CommentTok{\# Estimate and return quantile}
\NormalTok{  q }\OperatorTok{=}\NormalTok{ numpy.zeros(}\BuiltInTok{len}\NormalTok{(probs))}

\NormalTok{  C }\OperatorTok{=}\NormalTok{ expectand\_vals.shape[}\DecValTok{0}\NormalTok{]}
  \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(C):}
\NormalTok{    q }\OperatorTok{+=}\NormalTok{ numpy.percentile(expectand\_vals[c,:], probs) }\OperatorTok{/}\NormalTok{ C}

  \ControlFlowTok{return}\NormalTok{ q}
\end{Highlighting}
\end{Shaded}

Finally we can also visualize the entire pushforward distribution by
estimating the target probabilities in histogram bins.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Visualize pushforward distribution of a given expectand as a}
\CommentTok{\# histogram, using Markov chain Monte Carlo estimators to estimate the}
\CommentTok{\# output bin probabilities.  Bin probability estimator error is shown}
\CommentTok{\# in gray.}
\CommentTok{\# @ax Matplotlib axis object}
\CommentTok{\# @param expectand\_vals A two{-}dimensional array of expectand values with}
\CommentTok{\#                       the first dimension indexing the Markov chains}
\CommentTok{\#                       and the second dimension indexing the sequential}
\CommentTok{\#                       states within each Markov chain.}
\CommentTok{\# @param B The number of histogram bins}
\CommentTok{\# @param display\_name Expectand name}
\CommentTok{\# @param flim Optional histogram range}
\CommentTok{\# @param ylim Optional y{-}axis range; ignored if add is TRUE}
\CommentTok{\# @param color Color for plotting weighted bin probabilities; defaults}
\CommentTok{\#              to dark.}
\CommentTok{\# @param border Color for plotting estimator error; defaults to gray}
\CommentTok{\# @param border\_opacity Opacity for plotting estimator error; defaults}
\CommentTok{\#                       to 1.}
\CommentTok{\# @param add Configure plot to overlay over existing plot; defaults to}
\CommentTok{\#            FALSE}
\CommentTok{\# @param title Optional plot title}
\CommentTok{\# @param baseline Optional baseline value for visual comparison}
\CommentTok{\# @param baseline\_color Color for plotting baseline value; defaults to}
\CommentTok{\#                       "black"}
\KeywordTok{def}\NormalTok{ plot\_expectand\_pushforward(ax, expectand\_vals, B, display\_name}\OperatorTok{=}\StringTok{"f"}\NormalTok{,}
\NormalTok{                               flim}\OperatorTok{=}\VariableTok{None}\NormalTok{, ylim}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{                               color}\OperatorTok{=}\NormalTok{dark, border}\OperatorTok{=}\StringTok{"\#DDDDDD"}\NormalTok{,}
\NormalTok{                               border\_opacity}\OperatorTok{=}\DecValTok{1}\NormalTok{,}
\NormalTok{                               add}\OperatorTok{=}\VariableTok{False}\NormalTok{, title}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{                               baseline}\OperatorTok{=}\VariableTok{None}\NormalTok{, baseline\_color}\OperatorTok{=}\StringTok{"black"}\NormalTok{):}
  \CommentTok{"""Plot pushforward histogram of a given expectand using Markov chain}
\CommentTok{     Monte Carlo estimators to estimate the output bin probabilities"""}
\NormalTok{  validate\_array(expectand\_vals, }\StringTok{\textquotesingle{}expectand\_vals\textquotesingle{}}\NormalTok{)}
    
  \ControlFlowTok{if}\NormalTok{ flim }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
    \CommentTok{\# Automatically adjust histogram binning to range of outputs}
\NormalTok{    min\_f }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(expectand\_vals.flatten())}
\NormalTok{    max\_f }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(expectand\_vals.flatten())}
\NormalTok{    delta }\OperatorTok{=}\NormalTok{ (max\_f }\OperatorTok{{-}}\NormalTok{ min\_f) }\OperatorTok{/}\NormalTok{ B}

    \CommentTok{\# Add bounding bins}
\NormalTok{    B }\OperatorTok{=}\NormalTok{ B }\OperatorTok{+} \DecValTok{2}
\NormalTok{    min\_f }\OperatorTok{=}\NormalTok{ min\_f }\OperatorTok{{-}}\NormalTok{ delta}
\NormalTok{    max\_f }\OperatorTok{=}\NormalTok{ max\_f }\OperatorTok{+}\NormalTok{ delta}
\NormalTok{    flim }\OperatorTok{=}\NormalTok{ [min\_f, max\_f]}
    
\NormalTok{    bins }\OperatorTok{=}\NormalTok{ numpy.arange(min\_f, max\_f }\OperatorTok{+}\NormalTok{ delta, delta)}
  \ControlFlowTok{else}\NormalTok{:}
\NormalTok{    min\_f }\OperatorTok{=}\NormalTok{ flim[}\DecValTok{0}\NormalTok{]}
\NormalTok{    max\_f }\OperatorTok{=}\NormalTok{ flim[}\DecValTok{1}\NormalTok{]}
\NormalTok{    delta }\OperatorTok{=}\NormalTok{ (max\_f }\OperatorTok{{-}}\NormalTok{ min\_f) }\OperatorTok{/}\NormalTok{ B}

\NormalTok{    bins }\OperatorTok{=}\NormalTok{ numpy.arange(min\_f, max\_f }\OperatorTok{+}\NormalTok{ delta, delta)}
  
  \CommentTok{\# Check sample containment}
\NormalTok{  S }\OperatorTok{=}\NormalTok{ expectand\_vals.size}

\NormalTok{  S\_low }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(expectand\_vals.flatten() }\OperatorTok{\textless{}}\NormalTok{ min\_f)}
  \ControlFlowTok{if}\NormalTok{ S\_low }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{S\_low}\SpecialCharTok{\}}\SpecialStringTok{ value (}\SpecialCharTok{\{}\NormalTok{S\_low }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{)\textquotesingle{}}
           \StringTok{\textquotesingle{} fell below the histogram binning.\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{elif}\NormalTok{ S\_low }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{S\_low}\SpecialCharTok{\}}\SpecialStringTok{ values (}\SpecialCharTok{\{}\NormalTok{S\_low }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{)\textquotesingle{}}
           \StringTok{\textquotesingle{} fell below the histogram binning.\textquotesingle{}}\NormalTok{)}

\NormalTok{  S\_high }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(max\_f }\OperatorTok{\textless{}}\NormalTok{ expectand\_vals.flatten())}
  \ControlFlowTok{if}\NormalTok{ S\_high }\OperatorTok{==} \DecValTok{1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{S\_high}\SpecialCharTok{\}}\SpecialStringTok{ value (}\SpecialCharTok{\{}\NormalTok{S\_high }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{)\textquotesingle{}}
           \StringTok{\textquotesingle{} fell above the histogram binning.\textquotesingle{}}\NormalTok{)}
  \ControlFlowTok{elif}\NormalTok{ S\_high }\OperatorTok{\textgreater{}} \DecValTok{1}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f\textquotesingle{}}\SpecialCharTok{\{}\NormalTok{S\_high}\SpecialCharTok{\}}\SpecialStringTok{ values (}\SpecialCharTok{\{}\NormalTok{S\_high }\OperatorTok{/}\NormalTok{ S}\SpecialCharTok{:.2\%\}}\SpecialStringTok{)\textquotesingle{}}
           \StringTok{\textquotesingle{} fell above the histogram binning.\textquotesingle{}}\NormalTok{)}

  \CommentTok{\# Compute bin heights}
\NormalTok{  mean\_p }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ B}
\NormalTok{  delta\_p }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{] }\OperatorTok{*}\NormalTok{ B}
  
  \ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(B):}
    \KeywordTok{def}\NormalTok{ bin\_indicator(x):}
      \ControlFlowTok{return} \FloatTok{1.0} \ControlFlowTok{if}\NormalTok{ bins[b] }\OperatorTok{\textless{}=}\NormalTok{ x }\KeywordTok{and}\NormalTok{ x }\OperatorTok{\textless{}}\NormalTok{ bins[b }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\ControlFlowTok{else} \FloatTok{0.0}
    
\NormalTok{    indicator\_vals }\OperatorTok{=}\NormalTok{ eval\_uni\_expectand\_pushforward(expectand\_vals,}
\NormalTok{                                                    bin\_indicator)}
\NormalTok{    est }\OperatorTok{=}\NormalTok{ ensemble\_mcmc\_est(indicator\_vals)}
    
    \CommentTok{\# Normalize bin probabilities by bin width to allow}
    \CommentTok{\# for direct comparison to probability density functions}
\NormalTok{    width }\OperatorTok{=}\NormalTok{ bins[b }\OperatorTok{+} \DecValTok{1}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ bins[b]}
\NormalTok{    mean\_p[b] }\OperatorTok{=}\NormalTok{ est[}\DecValTok{0}\NormalTok{] }\OperatorTok{/}\NormalTok{ width}
\NormalTok{    delta\_p[b] }\OperatorTok{=}\NormalTok{ est[}\DecValTok{1}\NormalTok{] }\OperatorTok{/}\NormalTok{ width}
  
\NormalTok{  idxs }\OperatorTok{=}\NormalTok{ [ idx }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(B) }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
\NormalTok{  xs }\OperatorTok{=}\NormalTok{ [ bins[b }\OperatorTok{+}\NormalTok{ o] }\ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(B) }\ControlFlowTok{for}\NormalTok{ o }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{2}\NormalTok{) ]}
  
\NormalTok{  lower\_inter }\OperatorTok{=}\NormalTok{ [ }\BuiltInTok{max}\NormalTok{(mean\_p[idx] }\OperatorTok{{-}} \DecValTok{2} \OperatorTok{*}\NormalTok{ delta\_p[idx], }\DecValTok{0}\NormalTok{)}
                  \ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in}\NormalTok{ idxs ]}
\NormalTok{  upper\_inter }\OperatorTok{=}\NormalTok{ [ }\BuiltInTok{min}\NormalTok{(mean\_p[idx] }\OperatorTok{+} \DecValTok{2} \OperatorTok{*}\NormalTok{ delta\_p[idx], }\DecValTok{1} \OperatorTok{/}\NormalTok{ width) }
                  \ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in}\NormalTok{ idxs ]}
  
  \ControlFlowTok{if}\NormalTok{ add:}
\NormalTok{    ax.fill\_between(xs, lower\_inter, upper\_inter,}
\NormalTok{                    color}\OperatorTok{=}\NormalTok{border, facecolor}\OperatorTok{=}\NormalTok{border,}
\NormalTok{                    alpha}\OperatorTok{=}\NormalTok{border\_opacity)}
\NormalTok{    ax.plot(xs, [ mean\_p[idx] }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in}\NormalTok{ idxs ],}
\NormalTok{            color}\OperatorTok{=}\NormalTok{color, linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
  \ControlFlowTok{else}\NormalTok{:}
    \ControlFlowTok{if}\NormalTok{ ylim }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{      ylim }\OperatorTok{=}\NormalTok{ [ }\DecValTok{0}\NormalTok{, }\FloatTok{1.05} \OperatorTok{*} \BuiltInTok{max}\NormalTok{(upper\_inter) ]}

\NormalTok{    ax.fill\_between(xs, lower\_inter, upper\_inter,}
\NormalTok{                    color}\OperatorTok{=}\NormalTok{border, facecolor}\OperatorTok{=}\NormalTok{border,}
\NormalTok{                    alpha}\OperatorTok{=}\NormalTok{border\_opacity)}
\NormalTok{    ax.plot(xs, [ mean\_p[idx] }\ControlFlowTok{for}\NormalTok{ idx }\KeywordTok{in}\NormalTok{ idxs ],}
\NormalTok{            color}\OperatorTok{=}\NormalTok{color, linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

    \ControlFlowTok{if}\NormalTok{ title }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{      ax.set\_title(title)}
\NormalTok{    ax.set\_xlim(flim)}
\NormalTok{    ax.set\_xlabel(display\_name)}
\NormalTok{    ax.set\_ylim(ylim)}
\NormalTok{    ax.set\_ylabel(}\StringTok{"Estimated Bin}\CharTok{\textbackslash{}n}\StringTok{Probabilities / Bin Width"}\NormalTok{)}
\NormalTok{    ax.get\_yaxis().set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    ax.spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    ax.spines[}\StringTok{"left"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{    ax.spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}

  \ControlFlowTok{if}\NormalTok{ baseline }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    ax.axvline(x}\OperatorTok{=}\NormalTok{baseline, linewidth}\OperatorTok{=}\DecValTok{4}\NormalTok{, color}\OperatorTok{=}\StringTok{"white"}\NormalTok{)}
\NormalTok{    ax.axvline(x}\OperatorTok{=}\NormalTok{baseline, linewidth}\OperatorTok{=}\DecValTok{2}\NormalTok{, color}\OperatorTok{=}\NormalTok{baseline\_color)}

\end{Highlighting}
\end{Shaded}

\section{Demonstration}\label{demonstration}

Now let's put all of these analysis tools to use with an \texttt{PyStan}
fit object.

First we setup our local \texttt{Python} environment.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plot}
\NormalTok{plot.show()}
\NormalTok{plot.rcParams[}\StringTok{\textquotesingle{}figure.figsize\textquotesingle{}}\NormalTok{] }\OperatorTok{=}\NormalTok{ [}\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{]}
\NormalTok{plot.rcParams[}\StringTok{\textquotesingle{}figure.dpi\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \DecValTok{100}
\NormalTok{plot.rcParams[}\StringTok{\textquotesingle{}font.family\textquotesingle{}}\NormalTok{] }\OperatorTok{=} \StringTok{"Serif"}

\NormalTok{light}\OperatorTok{=}\StringTok{"\#DCBCBC"}
\NormalTok{light\_highlight}\OperatorTok{=}\StringTok{"\#C79999"}
\NormalTok{mid}\OperatorTok{=}\StringTok{"\#B97C7C"}
\NormalTok{mid\_highlight}\OperatorTok{=}\StringTok{"\#A25050"}
\NormalTok{dark}\OperatorTok{=}\StringTok{"\#8F2727"}
\NormalTok{dark\_highlight}\OperatorTok{=}\StringTok{"\#7C0000"}

\ImportTok{import}\NormalTok{ math}
\ImportTok{import}\NormalTok{ numpy}

\CommentTok{\# Needed to run through a jupyter kernel}
\ImportTok{import}\NormalTok{ nest\_asyncio}
\NormalTok{nest\_asyncio.}\BuiltInTok{apply}\NormalTok{()}

\ImportTok{import}\NormalTok{ stan}
\end{Highlighting}
\end{Shaded}

Next we source all of these diagnostics into a local namespace to avoid
any conflicts with other functions.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ mcmc\_analysis\_tools\_pystan3 }\ImportTok{as}\NormalTok{ util}
\end{Highlighting}
\end{Shaded}

Then we can simulate some binary data from a logistic regression model.

\begin{codelisting}

\caption{\texttt{simu\textbackslash\_logistic\textbackslash\_reg.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{transformed data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} M = }\DecValTok{3}\NormalTok{;         }\CommentTok{// Number of covariates}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N = }\DecValTok{1000}\NormalTok{;      }\CommentTok{// Number of observations}
  
  \DataTypeTok{vector}\NormalTok{[M] x0 = [{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{]\textquotesingle{}; }\CommentTok{// Covariate baseline}
  \DataTypeTok{vector}\NormalTok{[M] z0 = [{-}}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]\textquotesingle{}; }\CommentTok{// Latent functional behavior baseline}
  \DataTypeTok{real}\NormalTok{ gamma0 = {-}}\FloatTok{2.6}\NormalTok{;                      }\CommentTok{// True intercept}
  \DataTypeTok{vector}\NormalTok{[M] gamma1 = [}\FloatTok{0.2}\NormalTok{, {-}}\FloatTok{2.0}\NormalTok{, }\FloatTok{0.33}\NormalTok{]\textquotesingle{};   }\CommentTok{// True slopes}
  \DataTypeTok{matrix}\NormalTok{[M, M] gamma2 = [ [+}\FloatTok{0.40}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{, {-}}\FloatTok{0.20}\NormalTok{],}
\NormalTok{                          [{-}}\FloatTok{0.05}\NormalTok{, {-}}\FloatTok{1.00}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{],}
\NormalTok{                          [{-}}\FloatTok{0.20}\NormalTok{, {-}}\FloatTok{0.05}\NormalTok{, +}\FloatTok{0.50}\NormalTok{] ];}
\NormalTok{\}}

\KeywordTok{generated quantities}\NormalTok{ \{}
  \DataTypeTok{matrix}\NormalTok{[N, M] X; }\CommentTok{// Covariate design matrix}
  \DataTypeTok{array}\NormalTok{[N] }\DataTypeTok{real}\NormalTok{ y;      }\CommentTok{// Variates}

  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N) \{}
    \DataTypeTok{real}\NormalTok{ x2 = {-}}\DecValTok{5}\NormalTok{;}
    \ControlFlowTok{while}\NormalTok{ (x2 \textless{} x0[}\DecValTok{2}\NormalTok{] {-} }\DecValTok{4}\NormalTok{ || x2 \textgreater{} x0[}\DecValTok{2}\NormalTok{] + }\DecValTok{4}\NormalTok{)}
\NormalTok{      x2 = normal\_rng(x0[}\DecValTok{2}\NormalTok{], }\DecValTok{2}\NormalTok{);}
    
\NormalTok{    X[n, }\DecValTok{2}\NormalTok{] = x2;}
\NormalTok{    X[n, }\DecValTok{1}\NormalTok{] = normal\_rng(x0[}\DecValTok{1}\NormalTok{] + }\FloatTok{1.0}\NormalTok{ * cos(}\FloatTok{1.5}\NormalTok{ * (X[n, }\DecValTok{2}\NormalTok{] {-} x0[}\DecValTok{2}\NormalTok{])), }\FloatTok{0.3}\NormalTok{);}
\NormalTok{    X[n, }\DecValTok{3}\NormalTok{] = normal\_rng(x0[}\DecValTok{3}\NormalTok{] + }\FloatTok{0.76}\NormalTok{ * (X[n, }\DecValTok{1}\NormalTok{] {-} x0[}\DecValTok{1}\NormalTok{]), }\FloatTok{0.5}\NormalTok{);}

\NormalTok{    y[n] = bernoulli\_logit\_rng(  gamma0 }
\NormalTok{                               + (X[n] {-} z0\textquotesingle{}) * gamma1}
\NormalTok{                               + (X[n] {-} z0\textquotesingle{}) * gamma2 * (X[n] {-} z0\textquotesingle{})\textquotesingle{});}
\NormalTok{  \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{\textquotesingle{}stan\_programs/simu\_logistic\_reg.stan\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{  stan\_program }\OperatorTok{=} \BuiltInTok{file}\NormalTok{.read()}
\NormalTok{model }\OperatorTok{=}\NormalTok{ stan.build(stan\_program, random\_seed}\OperatorTok{=}\DecValTok{4838282}\NormalTok{)}
\NormalTok{simu }\OperatorTok{=}\NormalTok{ model.fixed\_param(num\_chains}\OperatorTok{=}\DecValTok{1}\NormalTok{, num\_samples}\OperatorTok{=}\DecValTok{1}\NormalTok{)}

\NormalTok{samples }\OperatorTok{=}\NormalTok{ util.extract\_expectand\_vals(simu)}

\NormalTok{y }\OperatorTok{=}\NormalTok{ [ v[}\DecValTok{0}\NormalTok{][}\DecValTok{0}\NormalTok{].astype(numpy.int64) }\ControlFlowTok{for}\NormalTok{ k, v }\KeywordTok{in}\NormalTok{ samples.items() }\ControlFlowTok{if} \StringTok{\textquotesingle{}y\textquotesingle{}} \KeywordTok{in}\NormalTok{ k ]}

\NormalTok{N }\OperatorTok{=} \DecValTok{1000}
\NormalTok{M }\OperatorTok{=} \DecValTok{3}
\NormalTok{X }\OperatorTok{=}\NormalTok{ numpy.zeros((N, M))}
\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(N):}
  \ControlFlowTok{for}\NormalTok{ m }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(M):}
\NormalTok{    X[n, m] }\OperatorTok{=}\NormalTok{ samples[}\SpecialStringTok{f\textquotesingle{}X[}\SpecialCharTok{\{}\NormalTok{n }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{,}\SpecialCharTok{\{}\NormalTok{m }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{]\textquotesingle{}}\NormalTok{][}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]}

\NormalTok{data }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}M\textquotesingle{}}\NormalTok{: M, }\StringTok{\textquotesingle{}N\textquotesingle{}}\NormalTok{: N, }\StringTok{\textquotesingle{}x0\textquotesingle{}}\NormalTok{: [}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{], }\StringTok{\textquotesingle{}X\textquotesingle{}}\NormalTok{: X, }\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{: y\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Building...
\end{verbatim}

We'll try to fit this model not with a constraint-respecting logistic
regression model but rather a constraint blaspheming linear probability
model. Importantly the resulting posterior density function is
discontinuous with configurations
\texttt{alpha\ +\ deltaX\ *\ beta\ \textgreater{}\ 0} resulting in
finite \texttt{bernoulli\_lpmf} outputs and those with
\texttt{alpha\ +\ deltaX\ *\ beta\ \textless{}=\ 0} resulting in minus
infinite outputs.

\begin{codelisting}

\caption{\texttt{bernoulli\textbackslash\_linear.stan}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{ \{}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} M; }\CommentTok{// Number of covariates}
  \DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{\textgreater{} N; }\CommentTok{// Number of observations}
  
  \DataTypeTok{vector}\NormalTok{[M] x0;   }\CommentTok{// Covariate baselines}
  \DataTypeTok{matrix}\NormalTok{[N, M] X; }\CommentTok{// Covariate design matrix}
  
  \DataTypeTok{array}\NormalTok{[N] }\DataTypeTok{int}\NormalTok{\textless{}}\KeywordTok{lower}\NormalTok{=}\DecValTok{0}\NormalTok{, }\KeywordTok{upper}\NormalTok{=}\DecValTok{1}\NormalTok{\textgreater{} y; }\CommentTok{// Variates}
\NormalTok{\}}

\KeywordTok{transformed data}\NormalTok{ \{}
  \DataTypeTok{matrix}\NormalTok{[N, M] deltaX;}
  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\NormalTok{:N) \{}
\NormalTok{    deltaX[n,] = X[n] {-} x0\textquotesingle{};}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{parameters}\NormalTok{ \{}
  \DataTypeTok{real}\NormalTok{ alpha;      }\CommentTok{// Intercept}
  \DataTypeTok{vector}\NormalTok{[M] beta;  }\CommentTok{// Linear slopes}
\NormalTok{\}}

\KeywordTok{model}\NormalTok{ \{}
  \CommentTok{// Prior model}
\NormalTok{  alpha \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}
\NormalTok{  beta \textasciitilde{} normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{);}

  \CommentTok{// Vectorized observation model}
\NormalTok{  y \textasciitilde{} bernoulli(alpha + deltaX * beta);}
\NormalTok{\}}

\CommentTok{// Simulate a full observation from the current value of the parameters}
\KeywordTok{generated quantities}\NormalTok{ \{}
  \DataTypeTok{vector}\NormalTok{[N] p = alpha + deltaX * beta;}
  \DataTypeTok{array}\NormalTok{[N] }\DataTypeTok{int}\NormalTok{ y\_pred = bernoulli\_rng(p);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\end{codelisting}

Because of this awkward constraint we have to carefully initialize our
Markov chains to satisfy the
\texttt{alpha\ +\ deltaX\ *\ beta\ \textgreater{}\ 0} constraint.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ scipy.stats }\ImportTok{as}\NormalTok{ stats}
\NormalTok{numpy.random.seed(seed}\OperatorTok{=}\DecValTok{48383499}\NormalTok{)}

\NormalTok{interval\_inits }\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*} \DecValTok{4}

\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{4}\NormalTok{):}
\NormalTok{  beta }\OperatorTok{=}\NormalTok{ [}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]}
\NormalTok{  alpha }\OperatorTok{=}\NormalTok{ stats.norm.rvs(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.1}\NormalTok{, size}\OperatorTok{=}\DecValTok{1}\NormalTok{)[}\DecValTok{0}\NormalTok{]}
\NormalTok{  interval\_inits[c] }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(alpha }\OperatorTok{=}\NormalTok{ alpha, beta }\OperatorTok{=}\NormalTok{ beta)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{\textquotesingle{}stan\_programs/bernoulli\_linear.stan\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{) }\ImportTok{as} \BuiltInTok{file}\NormalTok{:}
\NormalTok{  stan\_program }\OperatorTok{=} \BuiltInTok{file}\NormalTok{.read()}
\NormalTok{model }\OperatorTok{=}\NormalTok{ stan.build(stan\_program, random\_seed}\OperatorTok{=}\DecValTok{8438338}\NormalTok{, data}\OperatorTok{=}\NormalTok{data)}
\NormalTok{fit }\OperatorTok{=}\NormalTok{ model.sample(num\_samples}\OperatorTok{=}\DecValTok{1024}\NormalTok{, init}\OperatorTok{=}\NormalTok{interval\_inits)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Building...
\end{verbatim}

Stan is able to run to completion, but just how useful are the Markov
chains that it generates?

Let's start with the Hamiltonian Monte Carlo diagnostics.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics }\OperatorTok{=}\NormalTok{ util.extract\_hmc\_diagnostics(fit)}
\NormalTok{util.check\_all\_hmc\_diagnostics(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Chain 1: 1016 of 1024 transitions (99.22%) diverged.
  Chain 1: Average proxy acceptance statistic (0.566) is smaller than
90% of the target (0.801).
 
  Chain 2: 1015 of 1024 transitions (99.12%) diverged.
 
  Chain 3: 1022 of 1024 transitions (99.80%) diverged.
 
  Chain 4: 1016 of 1024 transitions (99.22%) diverged.
 
Divergent Hamiltonian transitions result from unstable numerical
trajectories.  These instabilities are often due to degenerate target
geometry, especially "pinches".  If there are only a small number of
divergences then running with adept_delta larger than 0.801 may reduce
the instabilities at the cost of more expensive Hamiltonian transitions.
 
A small average proxy acceptance statistic indicates that the adaptation
of the numerical integrator step size failed to converge.  This is often
due to discontinuous or imprecise gradients.
 
\end{verbatim}

Almost every transition across the four Markov chains resulted in a
divergence. This is due to the discontinuity in the linear probability
model as the sudden jump from a finite to a negative infinite target
density results in unstable numerical trajectories.

We also see the one of the Markov chains wasn't quite able to hit the
step size adaptation target. To see why let's dig into the adapted
configuration of the Hamiltonian Markov transition.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_inv\_metric(fit, }\DecValTok{75}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-8-output-1.pdf}

The problematic third Markov chain also exhibits the least variation in
its inverse metric elements, which in this case is probably an artifact
of its warmup phase spending too much time close to a constraint
boundary. Inverse metric elements that cannot adapt to each parameter
can frustrate numerical integration which can then frustrate the
integrator step size adaptation.

The step size in the third Markov chain is slightly larger than the
others which explains the lower average proxy acceptance statistic. We
can also see that the first Markov chain has a much smaller step size
than the other which results in an overly conservative average proxy
acceptance statistic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.display\_stepsizes(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Chain 1: Integrator Step Size = 7.59e-02
Chain 2: Integrator Step Size = 1.13e-02
Chain 3: Integrator Step Size = 4.31e-02
Chain 4: Integrator Step Size = 5.33e-03
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.display\_ave\_accept\_proxy(diagnostics)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Chain 1: Average proxy acceptance statistic = 0.566
Chain 2: Average proxy acceptance statistic = 0.856
Chain 3: Average proxy acceptance statistic = 0.738
Chain 4: Average proxy acceptance statistic = 0.957
\end{verbatim}

The different inverse metric results in different Hamiltonian dynamics.
In this case the dynamics driving the third Markov chain are not able to
explore as far as those in the other chains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_num\_leapfrogs\_by\_chain(diagnostics)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-11-output-1.pdf}

Finally because nearly every transition is divergent we can't extract
much information from the divergent-labeled pairs plots.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samples }\OperatorTok{=}\NormalTok{ util.extract\_expectand\_vals(fit)}

\NormalTok{names }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{]}
\NormalTok{names }\OperatorTok{+=}\NormalTok{ [ }\SpecialStringTok{f\textquotesingle{}beta[}\SpecialCharTok{\{}\NormalTok{m }\OperatorTok{+} \DecValTok{1}\SpecialCharTok{\}}\SpecialStringTok{]\textquotesingle{}} \ControlFlowTok{for}\NormalTok{ m }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(data[}\StringTok{\textquotesingle{}M\textquotesingle{}}\NormalTok{]) ]}
\NormalTok{util.plot\_div\_pairs(names, names, samples, diagnostics)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-12-output-1.pdf}

We can also color the divergent transitions by their numerical
trajectory lengths. On average transitions from shorter numerical
trajectories should be closer to the problematic behavior than
transitions from longer numerical trajectories. Because there are so
many divergent transitions here the point colors overlap and it's hard
to make too much out, but there \emph{may} be signs of a problematic
boundary.\\
For example plot of \texttt{beta{[}2{]}} against \texttt{beta{[}1{]}} is
not inconsistent with a boundary defined by \[
\beta_{1} + \beta_{2} = \mathrm{constant}.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_div\_pairs(names, names, samples, diagnostics, plot\_mode}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-13-output-1.pdf}

Having examined the Hamiltonian Monte Carlo diagnostics let's now look
through the expectand specific diagnostics. By default we'll look at the
parameter projection functions as well as all of the expectands defined
in the \texttt{generated\ quantities} block.

Because of the Hamiltonian Monte Carlo diagnostic failures let's start
by looking at the expectand diagnostics summary instead of the full
details.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.summarize\_expectand\_diagnostics(samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
The expectands alpha, beta[1], beta[2], beta[3], p[1000], p[100],
p[101], p[102], p[103], p[104], p[105], p[106], p[107], p[108], p[109],
p[10], p[110], p[111], p[112], p[113], p[114], p[115], p[116], p[117],
p[118], p[119], p[11], p[120], p[121], p[122], p[123], p[124], p[125],
p[126], p[127], p[128], p[129], p[12], p[130], p[131], p[132], p[133],
p[134], p[135], p[136], p[137], p[138], p[139], p[13], p[140], p[141],
p[142], p[143], p[144], p[145], p[146], p[147], p[148], p[149], p[14],
p[150], p[151], p[152], p[153], p[154], p[155], p[156], p[157], p[158],
p[159], p[15], p[160], p[161], p[162], p[163], p[164], p[165], p[166],
p[167], p[168], p[169], p[16], p[170], p[171], p[172], p[173], p[174],
p[175], p[176], p[177], p[178], p[179], p[17], p[180], p[181], p[182],
p[183], p[184], p[185], p[186], p[187], p[188], p[189], p[18], p[190],
p[191], p[192], p[193], p[194], p[195], p[196], p[197], p[198], p[199],
p[19], p[1], p[200], p[201], p[202], p[203], p[204], p[205], p[206],
p[207], p[208], p[209], p[20], p[210], p[211], p[212], p[213], p[214],
p[215], p[216], p[217], p[218], p[219], p[21], p[220], p[221], p[222],
p[223], p[224], p[225], p[226], p[227], p[228], p[229], p[22], p[230],
p[231], p[232], p[233], p[234], p[235], p[236], p[237], p[238], p[239],
p[23], p[240], p[241], p[242], p[243], p[244], p[245], p[246], p[247],
p[248], p[249], p[24], p[250], p[251], p[252], p[253], p[254], p[255],
p[256], p[257], p[258], p[259], p[25], p[260], p[261], p[262], p[263],
p[264], p[265], p[266], p[267], p[268], p[269], p[26], p[270], p[271],
p[272], p[273], p[274], p[275], p[276], p[277], p[278], p[279], p[27],
p[280], p[281], p[282], p[283], p[284], p[285], p[286], p[287], p[288],
p[289], p[28], p[290], p[291], p[292], p[293], p[294], p[295], p[296],
p[297], p[298], p[299], p[29], p[2], p[300], p[301], p[302], p[303],
p[304], p[305], p[306], p[307], p[308], p[309], p[30], p[310], p[311],
p[312], p[313], p[314], p[315], p[316], p[317], p[318], p[319], p[31],
p[320], p[321], p[322], p[323], p[324], p[325], p[326], p[327], p[328],
p[329], p[32], p[330], p[331], p[332], p[333], p[334], p[335], p[336],
p[337], p[338], p[339], p[33], p[340], p[341], p[342], p[343], p[344],
p[345], p[346], p[347], p[348], p[349], p[34], p[350], p[351], p[352],
p[353], p[354], p[355], p[356], p[357], p[358], p[359], p[35], p[360],
p[361], p[362], p[363], p[364], p[365], p[366], p[367], p[368], p[369],
p[36], p[370], p[371], p[372], p[373], p[374], p[375], p[376], p[377],
p[378], p[379], p[37], p[380], p[381], p[382], p[383], p[384], p[385],
p[386], p[387], p[388], p[389], p[38], p[390], p[391], p[392], p[393],
p[394], p[395], p[396], p[397], p[398], p[399], p[39], p[3], p[400],
p[401], p[402], p[403], p[404], p[405], p[406], p[407], p[408], p[409],
p[40], p[410], p[411], p[412], p[413], p[414], p[415], p[416], p[417],
p[418], p[419], p[41], p[420], p[421], p[422], p[423], p[424], p[425],
p[426], p[427], p[428], p[429], p[42], p[430], p[431], p[432], p[433],
p[434], p[435], p[436], p[437], p[438], p[439], p[43], p[440], p[441],
p[442], p[443], p[444], p[445], p[446], p[447], p[448], p[449], p[44],
p[450], p[451], p[452], p[453], p[454], p[455], p[456], p[457], p[458],
p[459], p[45], p[460], p[461], p[462], p[463], p[464], p[465], p[466],
p[467], p[468], p[469], p[46], p[470], p[471], p[472], p[473], p[474],
p[475], p[476], p[477], p[478], p[479], p[47], p[480], p[481], p[482],
p[483], p[484], p[485], p[486], p[487], p[488], p[489], p[48], p[490],
p[491], p[492], p[493], p[494], p[495], p[496], p[497], p[498], p[499],
p[49], p[4], p[500], p[501], p[502], p[503], p[504], p[505], p[506],
p[507], p[508], p[509], p[50], p[510], p[511], p[512], p[513], p[514],
p[515], p[516], p[517], p[518], p[519], p[51], p[520], p[521], p[522],
p[523], p[524], p[525], p[526], p[527], p[528], p[529], p[52], p[530],
p[531], p[532], p[533], p[534], p[535], p[536], p[537], p[538], p[539],
p[53], p[540], p[541], p[542], p[543], p[544], p[545], p[546], p[547],
p[548], p[549], p[54], p[550], p[551], p[552], p[553], p[554], p[555],
p[556], p[557], p[558], p[559], p[55], p[560], p[561], p[562], p[563],
p[564], p[565], p[566], p[567], p[568], p[569], p[56], p[570], p[571],
p[572], p[573], p[574], p[575], p[576], p[577], p[578], p[579], p[57],
p[580], p[581], p[582], p[583], p[584], p[585], p[586], p[587], p[588],
p[589], p[58], p[590], p[591], p[592], p[593], p[594], p[595], p[596],
p[597], p[598], p[599], p[59], p[5], p[600], p[601], p[602], p[603],
p[604], p[605], p[606], p[607], p[608], p[609], p[60], p[610], p[611],
p[612], p[613], p[614], p[615], p[616], p[617], p[618], p[619], p[61],
p[620], p[621], p[622], p[623], p[624], p[625], p[626], p[627], p[628],
p[629], p[62], p[630], p[631], p[632], p[633], p[634], p[635], p[636],
p[637], p[638], p[639], p[63], p[640], p[641], p[642], p[643], p[644],
p[645], p[646], p[647], p[648], p[649], p[64], p[650], p[651], p[652],
p[653], p[654], p[655], p[656], p[657], p[658], p[659], p[65], p[660],
p[661], p[662], p[663], p[664], p[665], p[666], p[667], p[668], p[669],
p[66], p[670], p[671], p[672], p[673], p[674], p[675], p[676], p[677],
p[678], p[679], p[67], p[680], p[681], p[682], p[683], p[684], p[685],
p[686], p[687], p[688], p[689], p[68], p[690], p[691], p[692], p[693],
p[694], p[695], p[696], p[697], p[698], p[699], p[69], p[6], p[700],
p[701], p[702], p[703], p[704], p[705], p[706], p[707], p[708], p[709],
p[70], p[710], p[711], p[712], p[713], p[714], p[715], p[716], p[717],
p[718], p[719], p[71], p[720], p[721], p[722], p[723], p[724], p[725],
p[726], p[727], p[728], p[729], p[72], p[730], p[731], p[732], p[733],
p[734], p[735], p[736], p[737], p[738], p[739], p[73], p[740], p[741],
p[742], p[743], p[744], p[745], p[746], p[747], p[748], p[749], p[74],
p[750], p[751], p[752], p[753], p[754], p[755], p[756], p[757], p[758],
p[759], p[75], p[760], p[761], p[762], p[763], p[764], p[765], p[766],
p[767], p[768], p[769], p[76], p[770], p[771], p[772], p[773], p[774],
p[775], p[776], p[777], p[778], p[779], p[77], p[780], p[781], p[782],
p[783], p[784], p[785], p[786], p[787], p[788], p[789], p[78], p[790],
p[791], p[792], p[793], p[794], p[795], p[796], p[797], p[798], p[799],
p[79], p[7], p[800], p[801], p[802], p[803], p[804], p[805], p[806],
p[807], p[808], p[809], p[80], p[810], p[811], p[812], p[813], p[814],
p[815], p[816], p[817], p[818], p[819], p[81], p[820], p[821], p[822],
p[823], p[824], p[825], p[826], p[827], p[828], p[829], p[82], p[830],
p[831], p[832], p[833], p[834], p[835], p[836], p[837], p[838], p[839],
p[83], p[840], p[841], p[842], p[843], p[844], p[845], p[846], p[847],
p[848], p[849], p[84], p[850], p[851], p[852], p[853], p[854], p[855],
p[856], p[857], p[858], p[859], p[85], p[860], p[861], p[862], p[863],
p[864], p[865], p[866], p[867], p[868], p[869], p[86], p[870], p[871],
p[872], p[873], p[874], p[875], p[876], p[877], p[878], p[879], p[87],
p[880], p[881], p[882], p[883], p[884], p[885], p[886], p[887], p[888],
p[889], p[88], p[890], p[891], p[892], p[893], p[894], p[895], p[896],
p[897], p[898], p[899], p[89], p[8], p[900], p[901], p[902], p[903],
p[904], p[905], p[906], p[907], p[908], p[909], p[90], p[910], p[911],
p[912], p[913], p[914], p[915], p[916], p[917], p[918], p[919], p[91],
p[920], p[921], p[922], p[923], p[924], p[925], p[926], p[927], p[928],
p[929], p[92], p[930], p[931], p[932], p[933], p[934], p[935], p[936],
p[937], p[938], p[939], p[93], p[940], p[941], p[942], p[943], p[944],
p[945], p[946], p[947], p[948], p[949], p[94], p[950], p[951], p[952],
p[953], p[954], p[955], p[956], p[957], p[958], p[959], p[95], p[960],
p[961], p[962], p[963], p[964], p[965], p[966], p[967], p[968], p[969],
p[96], p[970], p[971], p[972], p[973], p[974], p[975], p[976], p[977],
p[978], p[979], p[97], p[980], p[981], p[982], p[983], p[984], p[985],
p[986], p[987], p[988], p[989], p[98], p[990], p[991], p[992], p[993],
p[994], p[995], p[996], p[997], p[998], p[999], p[99], p[9],
y_pred[100], y_pred[101], y_pred[106], y_pred[108], y_pred[10],
y_pred[114], y_pred[116], y_pred[121], y_pred[122], y_pred[123],
y_pred[124], y_pred[126], y_pred[127], y_pred[130], y_pred[131],
y_pred[132], y_pred[133], y_pred[134], y_pred[137], y_pred[138],
y_pred[13], y_pred[144], y_pred[149], y_pred[151], y_pred[153],
y_pred[154], y_pred[155], y_pred[156], y_pred[157], y_pred[15],
y_pred[160], y_pred[161], y_pred[163], y_pred[164], y_pred[165],
y_pred[166], y_pred[167], y_pred[16], y_pred[171], y_pred[173],
y_pred[176], y_pred[177], y_pred[179], y_pred[17], y_pred[181],
y_pred[182], y_pred[183], y_pred[184], y_pred[186], y_pred[187],
y_pred[189], y_pred[18], y_pred[191], y_pred[194], y_pred[195],
y_pred[197], y_pred[1], y_pred[200], y_pred[201], y_pred[202],
y_pred[204], y_pred[205], y_pred[206], y_pred[207], y_pred[210],
y_pred[211], y_pred[214], y_pred[216], y_pred[217], y_pred[219],
y_pred[225], y_pred[226], y_pred[227], y_pred[228], y_pred[233],
y_pred[236], y_pred[239], y_pred[240], y_pred[241], y_pred[243],
y_pred[244], y_pred[246], y_pred[249], y_pred[24], y_pred[250],
y_pred[251], y_pred[252], y_pred[253], y_pred[255], y_pred[256],
y_pred[257], y_pred[258], y_pred[260], y_pred[261], y_pred[265],
y_pred[266], y_pred[267], y_pred[268], y_pred[26], y_pred[270],
y_pred[272], y_pred[27], y_pred[281], y_pred[282], y_pred[283],
y_pred[284], y_pred[286], y_pred[287], y_pred[289], y_pred[290],
y_pred[291], y_pred[294], y_pred[296], y_pred[297], y_pred[298],
y_pred[29], y_pred[2], y_pred[300], y_pred[301], y_pred[303],
y_pred[304], y_pred[308], y_pred[309], y_pred[30], y_pred[310],
y_pred[315], y_pred[316], y_pred[318], y_pred[319], y_pred[31],
y_pred[324], y_pred[325], y_pred[326], y_pred[328], y_pred[32],
y_pred[330], y_pred[332], y_pred[333], y_pred[335], y_pred[336],
y_pred[338], y_pred[339], y_pred[33], y_pred[341], y_pred[342],
y_pred[344], y_pred[345], y_pred[347], y_pred[348], y_pred[349],
y_pred[352], y_pred[353], y_pred[356], y_pred[359], y_pred[35],
y_pred[364], y_pred[365], y_pred[366], y_pred[367], y_pred[371],
y_pred[372], y_pred[373], y_pred[376], y_pred[379], y_pred[381],
y_pred[382], y_pred[384], y_pred[386], y_pred[387], y_pred[388],
y_pred[391], y_pred[392], y_pred[393], y_pred[395], y_pred[397],
y_pred[398], y_pred[399], y_pred[3], y_pred[400], y_pred[401],
y_pred[403], y_pred[404], y_pred[405], y_pred[40], y_pred[410],
y_pred[413], y_pred[414], y_pred[415], y_pred[417], y_pred[418],
y_pred[41], y_pred[422], y_pred[423], y_pred[427], y_pred[430],
y_pred[435], y_pred[436], y_pred[437], y_pred[439], y_pred[43],
y_pred[440], y_pred[441], y_pred[445], y_pred[447], y_pred[449],
y_pred[451], y_pred[452], y_pred[454], y_pred[456], y_pred[457],
y_pred[459], y_pred[45], y_pred[460], y_pred[462], y_pred[463],
y_pred[464], y_pred[465], y_pred[468], y_pred[469], y_pred[473],
y_pred[474], y_pred[475], y_pred[476], y_pred[477], y_pred[479],
y_pred[47], y_pred[480], y_pred[481], y_pred[482], y_pred[484],
y_pred[485], y_pred[487], y_pred[488], y_pred[489], y_pred[490],
y_pred[491], y_pred[492], y_pred[494], y_pred[495], y_pred[496],
y_pred[498], y_pred[500], y_pred[503], y_pred[504], y_pred[506],
y_pred[508], y_pred[509], y_pred[50], y_pred[510], y_pred[511],
y_pred[513], y_pred[517], y_pred[518], y_pred[51], y_pred[521],
y_pred[522], y_pred[523], y_pred[524], y_pred[52], y_pred[530],
y_pred[531], y_pred[536], y_pred[537], y_pred[539], y_pred[53],
y_pred[540], y_pred[543], y_pred[544], y_pred[545], y_pred[547],
y_pred[549], y_pred[551], y_pred[553], y_pred[554], y_pred[555],
y_pred[559], y_pred[55], y_pred[562], y_pred[564], y_pred[565],
y_pred[56], y_pred[570], y_pred[571], y_pred[573], y_pred[575],
y_pred[576], y_pred[577], y_pred[578], y_pred[579], y_pred[57],
y_pred[584], y_pred[586], y_pred[590], y_pred[592], y_pred[593],
y_pred[595], y_pred[597], y_pred[598], y_pred[599], y_pred[59],
y_pred[601], y_pred[604], y_pred[606], y_pred[608], y_pred[609],
y_pred[60], y_pred[611], y_pred[612], y_pred[613], y_pred[614],
y_pred[617], y_pred[622], y_pred[624], y_pred[629], y_pred[62],
y_pred[630], y_pred[632], y_pred[634], y_pred[635], y_pred[636],
y_pred[637], y_pred[640], y_pred[646], y_pred[647], y_pred[648],
y_pred[64], y_pred[651], y_pred[657], y_pred[65], y_pred[661],
y_pred[668], y_pred[66], y_pred[670], y_pred[671], y_pred[672],
y_pred[675], y_pred[678], y_pred[679], y_pred[67], y_pred[680],
y_pred[684], y_pred[686], y_pred[689], y_pred[68], y_pred[690],
y_pred[691], y_pred[692], y_pred[694], y_pred[696], y_pred[698],
y_pred[699], y_pred[69], y_pred[700], y_pred[701], y_pred[703],
y_pred[704], y_pred[710], y_pred[713], y_pred[714], y_pred[715],
y_pred[716], y_pred[71], y_pred[722], y_pred[726], y_pred[728],
y_pred[729], y_pred[730], y_pred[733], y_pred[735], y_pred[736],
y_pred[737], y_pred[73], y_pred[742], y_pred[743], y_pred[744],
y_pred[745], y_pred[747], y_pred[74], y_pred[754], y_pred[755],
y_pred[757], y_pred[758], y_pred[760], y_pred[763], y_pred[764],
y_pred[767], y_pred[770], y_pred[771], y_pred[772], y_pred[775],
y_pred[776], y_pred[778], y_pred[779], y_pred[780], y_pred[781],
y_pred[784], y_pred[785], y_pred[792], y_pred[794], y_pred[798],
y_pred[799], y_pred[79], y_pred[7], y_pred[801], y_pred[805],
y_pred[806], y_pred[808], y_pred[80], y_pred[812], y_pred[814],
y_pred[815], y_pred[816], y_pred[817], y_pred[818], y_pred[81],
y_pred[821], y_pred[822], y_pred[823], y_pred[824], y_pred[825],
y_pred[826], y_pred[827], y_pred[828], y_pred[82], y_pred[830],
y_pred[832], y_pred[834], y_pred[836], y_pred[838], y_pred[840],
y_pred[843], y_pred[844], y_pred[84], y_pred[853], y_pred[855],
y_pred[857], y_pred[859], y_pred[85], y_pred[860], y_pred[862],
y_pred[863], y_pred[864], y_pred[867], y_pred[868], y_pred[869],
y_pred[870], y_pred[872], y_pred[874], y_pred[876], y_pred[882],
y_pred[886], y_pred[887], y_pred[889], y_pred[891], y_pred[892],
y_pred[894], y_pred[898], y_pred[899], y_pred[89], y_pred[8],
y_pred[900], y_pred[905], y_pred[90], y_pred[911], y_pred[912],
y_pred[915], y_pred[916], y_pred[917], y_pred[918], y_pred[919],
y_pred[921], y_pred[927], y_pred[928], y_pred[930], y_pred[933],
y_pred[934], y_pred[936], y_pred[937], y_pred[938], y_pred[941],
y_pred[942], y_pred[944], y_pred[947], y_pred[949], y_pred[94],
y_pred[952], y_pred[953], y_pred[954], y_pred[957], y_pred[958],
y_pred[960], y_pred[962], y_pred[963], y_pred[967], y_pred[969],
y_pred[970], y_pred[971], y_pred[972], y_pred[974], y_pred[975],
y_pred[976], y_pred[977], y_pred[979], y_pred[97], y_pred[981],
y_pred[982], y_pred[986], y_pred[987], y_pred[991], y_pred[992],
y_pred[994], y_pred[995], y_pred[996], y_pred[997], y_pred[99],
y_pred[9] triggered diagnostic warnings.
 
The expectands y_pred[100], y_pred[101], y_pred[106], y_pred[108],
y_pred[10], y_pred[114], y_pred[116], y_pred[121], y_pred[122],
y_pred[123], y_pred[124], y_pred[126], y_pred[127], y_pred[130],
y_pred[131], y_pred[132], y_pred[133], y_pred[134], y_pred[137],
y_pred[138], y_pred[13], y_pred[144], y_pred[149], y_pred[151],
y_pred[153], y_pred[154], y_pred[155], y_pred[156], y_pred[157],
y_pred[15], y_pred[160], y_pred[161], y_pred[163], y_pred[164],
y_pred[165], y_pred[166], y_pred[167], y_pred[16], y_pred[171],
y_pred[173], y_pred[176], y_pred[177], y_pred[179], y_pred[17],
y_pred[181], y_pred[182], y_pred[183], y_pred[184], y_pred[186],
y_pred[187], y_pred[189], y_pred[18], y_pred[191], y_pred[194],
y_pred[195], y_pred[197], y_pred[1], y_pred[200], y_pred[201],
y_pred[202], y_pred[204], y_pred[205], y_pred[206], y_pred[207],
y_pred[210], y_pred[211], y_pred[214], y_pred[216], y_pred[217],
y_pred[219], y_pred[225], y_pred[226], y_pred[227], y_pred[228],
y_pred[233], y_pred[236], y_pred[239], y_pred[240], y_pred[241],
y_pred[243], y_pred[244], y_pred[246], y_pred[249], y_pred[24],
y_pred[250], y_pred[251], y_pred[252], y_pred[253], y_pred[255],
y_pred[256], y_pred[257], y_pred[258], y_pred[260], y_pred[261],
y_pred[265], y_pred[266], y_pred[267], y_pred[268], y_pred[26],
y_pred[270], y_pred[272], y_pred[27], y_pred[281], y_pred[282],
y_pred[283], y_pred[284], y_pred[286], y_pred[287], y_pred[289],
y_pred[290], y_pred[291], y_pred[294], y_pred[296], y_pred[297],
y_pred[298], y_pred[29], y_pred[2], y_pred[300], y_pred[301],
y_pred[303], y_pred[304], y_pred[308], y_pred[309], y_pred[30],
y_pred[310], y_pred[315], y_pred[316], y_pred[318], y_pred[319],
y_pred[31], y_pred[324], y_pred[325], y_pred[326], y_pred[328],
y_pred[32], y_pred[330], y_pred[332], y_pred[333], y_pred[335],
y_pred[336], y_pred[338], y_pred[339], y_pred[33], y_pred[341],
y_pred[342], y_pred[344], y_pred[345], y_pred[347], y_pred[348],
y_pred[349], y_pred[352], y_pred[353], y_pred[356], y_pred[359],
y_pred[35], y_pred[364], y_pred[365], y_pred[366], y_pred[367],
y_pred[371], y_pred[372], y_pred[373], y_pred[376], y_pred[379],
y_pred[381], y_pred[382], y_pred[384], y_pred[386], y_pred[387],
y_pred[388], y_pred[391], y_pred[392], y_pred[393], y_pred[395],
y_pred[397], y_pred[398], y_pred[399], y_pred[3], y_pred[400],
y_pred[401], y_pred[403], y_pred[404], y_pred[405], y_pred[40],
y_pred[410], y_pred[413], y_pred[414], y_pred[415], y_pred[417],
y_pred[418], y_pred[41], y_pred[422], y_pred[423], y_pred[427],
y_pred[430], y_pred[435], y_pred[436], y_pred[437], y_pred[439],
y_pred[43], y_pred[440], y_pred[441], y_pred[445], y_pred[447],
y_pred[449], y_pred[451], y_pred[452], y_pred[454], y_pred[456],
y_pred[457], y_pred[459], y_pred[45], y_pred[460], y_pred[462],
y_pred[463], y_pred[464], y_pred[465], y_pred[468], y_pred[469],
y_pred[473], y_pred[474], y_pred[475], y_pred[476], y_pred[477],
y_pred[479], y_pred[47], y_pred[480], y_pred[481], y_pred[482],
y_pred[484], y_pred[485], y_pred[487], y_pred[488], y_pred[489],
y_pred[490], y_pred[491], y_pred[492], y_pred[494], y_pred[495],
y_pred[496], y_pred[498], y_pred[500], y_pred[503], y_pred[504],
y_pred[506], y_pred[508], y_pred[509], y_pred[50], y_pred[510],
y_pred[511], y_pred[513], y_pred[517], y_pred[518], y_pred[51],
y_pred[521], y_pred[522], y_pred[523], y_pred[524], y_pred[52],
y_pred[530], y_pred[531], y_pred[536], y_pred[537], y_pred[539],
y_pred[53], y_pred[540], y_pred[543], y_pred[544], y_pred[545],
y_pred[547], y_pred[549], y_pred[551], y_pred[553], y_pred[554],
y_pred[555], y_pred[559], y_pred[55], y_pred[562], y_pred[564],
y_pred[565], y_pred[56], y_pred[570], y_pred[571], y_pred[573],
y_pred[575], y_pred[576], y_pred[577], y_pred[578], y_pred[579],
y_pred[57], y_pred[584], y_pred[586], y_pred[590], y_pred[592],
y_pred[593], y_pred[595], y_pred[597], y_pred[598], y_pred[599],
y_pred[59], y_pred[601], y_pred[604], y_pred[606], y_pred[608],
y_pred[609], y_pred[60], y_pred[611], y_pred[612], y_pred[613],
y_pred[614], y_pred[617], y_pred[622], y_pred[624], y_pred[629],
y_pred[62], y_pred[630], y_pred[632], y_pred[634], y_pred[635],
y_pred[636], y_pred[637], y_pred[640], y_pred[646], y_pred[647],
y_pred[648], y_pred[64], y_pred[651], y_pred[657], y_pred[65],
y_pred[661], y_pred[668], y_pred[66], y_pred[670], y_pred[671],
y_pred[672], y_pred[675], y_pred[678], y_pred[679], y_pred[67],
y_pred[680], y_pred[684], y_pred[686], y_pred[689], y_pred[68],
y_pred[690], y_pred[691], y_pred[692], y_pred[694], y_pred[696],
y_pred[698], y_pred[699], y_pred[69], y_pred[700], y_pred[701],
y_pred[703], y_pred[704], y_pred[710], y_pred[713], y_pred[714],
y_pred[715], y_pred[716], y_pred[71], y_pred[722], y_pred[726],
y_pred[728], y_pred[729], y_pred[730], y_pred[733], y_pred[735],
y_pred[736], y_pred[737], y_pred[73], y_pred[742], y_pred[743],
y_pred[744], y_pred[745], y_pred[747], y_pred[74], y_pred[754],
y_pred[755], y_pred[757], y_pred[758], y_pred[760], y_pred[763],
y_pred[764], y_pred[767], y_pred[770], y_pred[771], y_pred[772],
y_pred[775], y_pred[776], y_pred[778], y_pred[779], y_pred[780],
y_pred[781], y_pred[784], y_pred[785], y_pred[792], y_pred[794],
y_pred[798], y_pred[799], y_pred[79], y_pred[7], y_pred[801],
y_pred[805], y_pred[806], y_pred[808], y_pred[80], y_pred[812],
y_pred[814], y_pred[815], y_pred[816], y_pred[817], y_pred[818],
y_pred[81], y_pred[821], y_pred[822], y_pred[823], y_pred[824],
y_pred[825], y_pred[826], y_pred[827], y_pred[828], y_pred[82],
y_pred[830], y_pred[832], y_pred[834], y_pred[836], y_pred[838],
y_pred[840], y_pred[843], y_pred[844], y_pred[84], y_pred[853],
y_pred[855], y_pred[857], y_pred[859], y_pred[85], y_pred[860],
y_pred[862], y_pred[863], y_pred[864], y_pred[867], y_pred[868],
y_pred[869], y_pred[870], y_pred[872], y_pred[874], y_pred[876],
y_pred[882], y_pred[886], y_pred[887], y_pred[889], y_pred[891],
y_pred[892], y_pred[894], y_pred[898], y_pred[899], y_pred[89],
y_pred[8], y_pred[900], y_pred[905], y_pred[90], y_pred[911],
y_pred[912], y_pred[915], y_pred[916], y_pred[917], y_pred[918],
y_pred[919], y_pred[921], y_pred[927], y_pred[928], y_pred[930],
y_pred[933], y_pred[934], y_pred[936], y_pred[937], y_pred[938],
y_pred[941], y_pred[942], y_pred[944], y_pred[947], y_pred[949],
y_pred[94], y_pred[952], y_pred[953], y_pred[954], y_pred[957],
y_pred[958], y_pred[960], y_pred[962], y_pred[963], y_pred[967],
y_pred[969], y_pred[970], y_pred[971], y_pred[972], y_pred[974],
y_pred[975], y_pred[976], y_pred[977], y_pred[979], y_pred[97],
y_pred[981], y_pred[982], y_pred[986], y_pred[987], y_pred[991],
y_pred[992], y_pred[994], y_pred[995], y_pred[996], y_pred[997],
y_pred[99], y_pred[9] triggered tail hat{xi} warnings.
  Large tail hat{xi}s suggest that the expectand might not be
sufficiently integrable.
 
The expectands alpha, beta[1], beta[2], beta[3], p[1000], p[100],
p[101], p[102], p[103], p[105], p[106], p[107], p[108], p[109], p[10],
p[110], p[111], p[112], p[113], p[114], p[116], p[118], p[119], p[11],
p[120], p[121], p[122], p[123], p[124], p[125], p[126], p[127], p[128],
p[129], p[130], p[132], p[133], p[134], p[135], p[136], p[137], p[139],
p[13], p[140], p[141], p[142], p[143], p[144], p[145], p[146], p[147],
p[148], p[14], p[150], p[151], p[152], p[153], p[154], p[155], p[156],
p[157], p[158], p[159], p[160], p[161], p[162], p[163], p[164], p[165],
p[166], p[167], p[168], p[169], p[16], p[170], p[171], p[172], p[174],
p[175], p[176], p[177], p[179], p[17], p[180], p[181], p[182], p[184],
p[185], p[186], p[187], p[188], p[189], p[18], p[190], p[191], p[192],
p[193], p[195], p[196], p[197], p[198], p[199], p[19], p[1], p[200],
p[201], p[202], p[203], p[204], p[205], p[206], p[207], p[208], p[209],
p[20], p[210], p[211], p[212], p[213], p[214], p[215], p[216], p[217],
p[218], p[219], p[21], p[222], p[223], p[225], p[226], p[227], p[228],
p[229], p[22], p[230], p[231], p[232], p[234], p[235], p[236], p[237],
p[238], p[239], p[240], p[241], p[242], p[243], p[244], p[245], p[246],
p[248], p[249], p[24], p[250], p[251], p[252], p[254], p[255], p[256],
p[257], p[258], p[259], p[25], p[260], p[262], p[263], p[264], p[265],
p[266], p[267], p[268], p[269], p[26], p[270], p[271], p[272], p[273],
p[274], p[275], p[276], p[277], p[278], p[279], p[280], p[281], p[282],
p[283], p[285], p[286], p[287], p[288], p[28], p[290], p[294], p[295],
p[297], p[298], p[299], p[29], p[2], p[300], p[301], p[302], p[303],
p[304], p[305], p[306], p[307], p[309], p[30], p[310], p[311], p[312],
p[313], p[314], p[315], p[316], p[317], p[318], p[319], p[320], p[322],
p[323], p[324], p[325], p[326], p[327], p[328], p[329], p[32], p[331],
p[332], p[333], p[334], p[335], p[336], p[337], p[33], p[340], p[341],
p[342], p[343], p[344], p[345], p[346], p[347], p[348], p[349], p[34],
p[350], p[351], p[352], p[353], p[354], p[356], p[357], p[358], p[359],
p[35], p[360], p[361], p[363], p[366], p[367], p[368], p[369], p[370],
p[371], p[372], p[373], p[374], p[375], p[376], p[377], p[378], p[379],
p[37], p[380], p[381], p[382], p[383], p[384], p[385], p[386], p[387],
p[388], p[389], p[38], p[390], p[391], p[392], p[394], p[396], p[397],
p[398], p[399], p[39], p[3], p[400], p[401], p[402], p[403], p[404],
p[405], p[407], p[408], p[409], p[40], p[410], p[411], p[412], p[413],
p[414], p[415], p[416], p[417], p[418], p[419], p[41], p[420], p[421],
p[422], p[423], p[424], p[425], p[426], p[428], p[429], p[42], p[430],
p[431], p[432], p[433], p[434], p[435], p[436], p[437], p[438], p[439],
p[43], p[440], p[441], p[443], p[444], p[445], p[446], p[447], p[448],
p[449], p[44], p[450], p[451], p[452], p[453], p[454], p[455], p[456],
p[457], p[458], p[459], p[460], p[461], p[462], p[463], p[464], p[465],
p[466], p[467], p[468], p[469], p[46], p[470], p[471], p[472], p[473],
p[474], p[475], p[476], p[477], p[478], p[47], p[480], p[481], p[482],
p[483], p[484], p[485], p[487], p[48], p[490], p[491], p[492], p[493],
p[494], p[495], p[496], p[497], p[498], p[499], p[49], p[4], p[501],
p[502], p[503], p[504], p[505], p[506], p[507], p[508], p[509], p[50],
p[510], p[511], p[512], p[514], p[515], p[516], p[517], p[518], p[519],
p[51], p[520], p[522], p[524], p[525], p[526], p[527], p[528], p[529],
p[52], p[530], p[531], p[532], p[533], p[534], p[535], p[536], p[537],
p[538], p[539], p[53], p[540], p[541], p[542], p[543], p[544], p[545],
p[546], p[547], p[548], p[549], p[54], p[550], p[551], p[552], p[553],
p[554], p[555], p[556], p[557], p[558], p[559], p[55], p[560], p[561],
p[562], p[563], p[564], p[566], p[567], p[568], p[569], p[56], p[570],
p[571], p[572], p[573], p[574], p[575], p[576], p[578], p[57], p[580],
p[581], p[582], p[583], p[584], p[585], p[586], p[587], p[588], p[589],
p[58], p[590], p[591], p[592], p[593], p[594], p[596], p[597], p[599],
p[59], p[5], p[600], p[601], p[602], p[604], p[605], p[606], p[607],
p[608], p[609], p[60], p[610], p[612], p[613], p[615], p[616], p[617],
p[618], p[619], p[61], p[620], p[621], p[622], p[623], p[624], p[625],
p[626], p[627], p[628], p[629], p[630], p[631], p[632], p[633], p[634],
p[635], p[636], p[637], p[638], p[639], p[63], p[640], p[641], p[642],
p[643], p[644], p[645], p[648], p[649], p[650], p[651], p[652], p[653],
p[654], p[655], p[656], p[657], p[658], p[659], p[65], p[662], p[663],
p[664], p[665], p[666], p[667], p[668], p[669], p[66], p[670], p[671],
p[672], p[673], p[674], p[675], p[676], p[677], p[678], p[679], p[67],
p[680], p[681], p[682], p[683], p[684], p[685], p[687], p[688], p[689],
p[690], p[691], p[692], p[693], p[694], p[695], p[697], p[698], p[69],
p[6], p[700], p[701], p[702], p[703], p[704], p[705], p[706], p[707],
p[708], p[709], p[70], p[710], p[712], p[714], p[715], p[717], p[719],
p[71], p[720], p[721], p[723], p[724], p[725], p[726], p[727], p[728],
p[729], p[72], p[730], p[731], p[732], p[733], p[734], p[735], p[736],
p[737], p[738], p[739], p[73], p[740], p[741], p[742], p[743], p[744],
p[745], p[746], p[747], p[748], p[749], p[74], p[750], p[751], p[752],
p[753], p[754], p[755], p[756], p[757], p[758], p[759], p[75], p[760],
p[761], p[762], p[764], p[765], p[766], p[767], p[768], p[769], p[76],
p[770], p[771], p[772], p[773], p[774], p[775], p[776], p[777], p[778],
p[779], p[77], p[780], p[781], p[782], p[783], p[784], p[785], p[786],
p[787], p[788], p[789], p[78], p[790], p[791], p[792], p[793], p[794],
p[795], p[797], p[798], p[799], p[79], p[7], p[801], p[802], p[803],
p[804], p[805], p[806], p[807], p[808], p[809], p[80], p[810], p[811],
p[812], p[813], p[817], p[818], p[819], p[81], p[820], p[821], p[822],
p[823], p[824], p[825], p[827], p[828], p[829], p[831], p[832], p[833],
p[834], p[835], p[836], p[837], p[838], p[839], p[83], p[841], p[842],
p[843], p[844], p[845], p[846], p[847], p[848], p[849], p[850], p[851],
p[852], p[854], p[855], p[856], p[857], p[858], p[859], p[85], p[860],
p[861], p[862], p[864], p[865], p[866], p[867], p[868], p[86], p[870],
p[871], p[872], p[873], p[874], p[875], p[876], p[877], p[878], p[879],
p[87], p[880], p[881], p[882], p[883], p[884], p[885], p[886], p[887],
p[888], p[889], p[88], p[890], p[891], p[892], p[893], p[895], p[896],
p[897], p[899], p[89], p[8], p[900], p[901], p[902], p[904], p[905],
p[906], p[907], p[908], p[909], p[90], p[910], p[911], p[913], p[914],
p[915], p[916], p[917], p[918], p[919], p[91], p[920], p[921], p[922],
p[923], p[924], p[925], p[926], p[927], p[928], p[929], p[92], p[930],
p[931], p[932], p[933], p[934], p[935], p[937], p[938], p[939], p[93],
p[940], p[941], p[942], p[943], p[944], p[945], p[946], p[947], p[948],
p[94], p[950], p[951], p[952], p[953], p[954], p[955], p[956], p[957],
p[958], p[959], p[95], p[960], p[961], p[962], p[963], p[964], p[965],
p[966], p[968], p[969], p[96], p[970], p[971], p[972], p[973], p[974],
p[975], p[976], p[977], p[978], p[979], p[97], p[980], p[981], p[982],
p[983], p[984], p[985], p[986], p[987], p[989], p[98], p[991], p[992],
p[993], p[994], p[995], p[996], p[997], p[998], p[999], p[99], p[9]
triggered hat{R} warnings.
  Split Rhat larger than 1.1 suggests that at least one of the Markov
chains has not reached an equilibrium.
 
The expectands alpha, beta[1], beta[2], beta[3], p[1000], p[100],
p[101], p[102], p[103], p[104], p[105], p[106], p[107], p[108], p[109],
p[10], p[110], p[111], p[112], p[113], p[114], p[115], p[116], p[117],
p[118], p[119], p[11], p[120], p[121], p[122], p[123], p[124], p[125],
p[126], p[127], p[128], p[129], p[12], p[130], p[131], p[132], p[133],
p[134], p[135], p[136], p[137], p[138], p[139], p[13], p[140], p[141],
p[142], p[143], p[144], p[145], p[146], p[147], p[148], p[149], p[14],
p[150], p[151], p[152], p[153], p[154], p[155], p[156], p[157], p[158],
p[159], p[15], p[160], p[161], p[162], p[163], p[164], p[165], p[166],
p[167], p[168], p[169], p[16], p[170], p[171], p[172], p[173], p[174],
p[175], p[176], p[177], p[178], p[179], p[17], p[180], p[181], p[182],
p[183], p[184], p[185], p[186], p[187], p[188], p[189], p[18], p[190],
p[191], p[192], p[193], p[194], p[195], p[196], p[197], p[198], p[199],
p[19], p[1], p[200], p[201], p[202], p[203], p[204], p[205], p[206],
p[207], p[208], p[209], p[20], p[210], p[211], p[212], p[213], p[214],
p[215], p[216], p[217], p[218], p[219], p[21], p[220], p[221], p[222],
p[223], p[224], p[225], p[226], p[227], p[228], p[229], p[22], p[230],
p[231], p[232], p[233], p[234], p[235], p[236], p[237], p[238], p[239],
p[23], p[240], p[241], p[242], p[243], p[244], p[245], p[246], p[247],
p[248], p[249], p[24], p[250], p[251], p[252], p[253], p[254], p[255],
p[256], p[257], p[258], p[259], p[25], p[260], p[261], p[262], p[263],
p[264], p[265], p[266], p[267], p[268], p[269], p[26], p[270], p[271],
p[272], p[273], p[274], p[275], p[276], p[277], p[278], p[279], p[27],
p[280], p[281], p[282], p[283], p[284], p[285], p[286], p[287], p[288],
p[289], p[28], p[290], p[291], p[292], p[293], p[294], p[295], p[296],
p[297], p[298], p[299], p[29], p[2], p[300], p[301], p[302], p[303],
p[304], p[305], p[306], p[307], p[308], p[309], p[30], p[310], p[311],
p[312], p[313], p[314], p[315], p[316], p[317], p[318], p[319], p[31],
p[320], p[321], p[322], p[323], p[324], p[325], p[326], p[327], p[328],
p[329], p[32], p[330], p[331], p[332], p[333], p[334], p[335], p[336],
p[337], p[338], p[339], p[33], p[340], p[341], p[342], p[343], p[344],
p[345], p[346], p[347], p[348], p[349], p[34], p[350], p[351], p[352],
p[353], p[354], p[355], p[356], p[357], p[358], p[359], p[35], p[360],
p[361], p[362], p[363], p[364], p[365], p[366], p[367], p[368], p[369],
p[36], p[370], p[371], p[372], p[373], p[374], p[375], p[376], p[377],
p[378], p[379], p[37], p[380], p[381], p[382], p[383], p[384], p[385],
p[386], p[387], p[388], p[389], p[38], p[390], p[391], p[392], p[393],
p[394], p[395], p[396], p[397], p[398], p[399], p[39], p[3], p[400],
p[401], p[402], p[403], p[404], p[405], p[406], p[407], p[408], p[409],
p[40], p[410], p[411], p[412], p[413], p[414], p[415], p[416], p[417],
p[418], p[419], p[41], p[420], p[421], p[422], p[423], p[424], p[425],
p[426], p[427], p[428], p[429], p[42], p[430], p[431], p[432], p[433],
p[434], p[435], p[436], p[437], p[438], p[439], p[43], p[440], p[441],
p[442], p[443], p[444], p[445], p[446], p[447], p[448], p[449], p[44],
p[450], p[451], p[452], p[453], p[454], p[455], p[456], p[457], p[458],
p[459], p[45], p[460], p[461], p[462], p[463], p[464], p[465], p[466],
p[467], p[468], p[469], p[46], p[470], p[471], p[472], p[473], p[474],
p[475], p[476], p[477], p[478], p[479], p[47], p[480], p[481], p[482],
p[483], p[484], p[485], p[486], p[487], p[488], p[489], p[48], p[490],
p[491], p[492], p[493], p[494], p[495], p[496], p[497], p[498], p[499],
p[49], p[4], p[500], p[501], p[502], p[503], p[504], p[505], p[506],
p[507], p[508], p[509], p[50], p[510], p[511], p[512], p[513], p[514],
p[515], p[516], p[517], p[518], p[519], p[51], p[520], p[521], p[522],
p[523], p[524], p[525], p[526], p[527], p[528], p[529], p[52], p[530],
p[531], p[532], p[533], p[534], p[535], p[536], p[537], p[538], p[539],
p[53], p[540], p[541], p[542], p[543], p[544], p[545], p[546], p[547],
p[548], p[549], p[54], p[550], p[551], p[552], p[553], p[554], p[555],
p[556], p[557], p[558], p[559], p[55], p[560], p[561], p[562], p[563],
p[564], p[565], p[566], p[567], p[568], p[569], p[56], p[570], p[571],
p[572], p[573], p[574], p[575], p[576], p[577], p[578], p[579], p[57],
p[580], p[581], p[582], p[583], p[584], p[585], p[586], p[587], p[588],
p[589], p[58], p[590], p[591], p[592], p[593], p[594], p[595], p[596],
p[597], p[598], p[599], p[59], p[5], p[600], p[601], p[602], p[603],
p[604], p[605], p[606], p[607], p[608], p[609], p[60], p[610], p[611],
p[612], p[613], p[614], p[615], p[616], p[617], p[618], p[619], p[61],
p[620], p[621], p[622], p[623], p[624], p[625], p[626], p[627], p[628],
p[629], p[62], p[630], p[631], p[632], p[633], p[634], p[635], p[636],
p[637], p[638], p[639], p[63], p[640], p[641], p[642], p[643], p[644],
p[645], p[646], p[647], p[648], p[649], p[64], p[650], p[651], p[652],
p[653], p[654], p[655], p[656], p[657], p[658], p[659], p[65], p[660],
p[661], p[662], p[663], p[664], p[665], p[666], p[667], p[668], p[669],
p[66], p[670], p[671], p[672], p[673], p[674], p[675], p[676], p[677],
p[678], p[679], p[67], p[680], p[681], p[682], p[683], p[684], p[685],
p[686], p[687], p[688], p[689], p[68], p[690], p[691], p[692], p[693],
p[694], p[695], p[696], p[697], p[698], p[699], p[69], p[6], p[700],
p[701], p[702], p[703], p[704], p[705], p[706], p[707], p[708], p[709],
p[70], p[710], p[711], p[712], p[713], p[714], p[715], p[716], p[717],
p[718], p[719], p[71], p[720], p[721], p[722], p[723], p[724], p[725],
p[726], p[727], p[728], p[729], p[72], p[730], p[731], p[732], p[733],
p[734], p[735], p[736], p[737], p[738], p[739], p[73], p[740], p[741],
p[742], p[743], p[744], p[745], p[746], p[747], p[748], p[749], p[74],
p[750], p[751], p[752], p[753], p[754], p[755], p[756], p[757], p[758],
p[759], p[75], p[760], p[761], p[762], p[763], p[764], p[765], p[766],
p[767], p[768], p[769], p[76], p[770], p[771], p[772], p[773], p[774],
p[775], p[776], p[777], p[778], p[779], p[77], p[780], p[781], p[782],
p[783], p[784], p[785], p[786], p[787], p[788], p[789], p[78], p[790],
p[791], p[792], p[793], p[794], p[795], p[796], p[797], p[798], p[799],
p[79], p[7], p[800], p[801], p[802], p[803], p[804], p[805], p[806],
p[807], p[808], p[809], p[80], p[810], p[811], p[812], p[813], p[814],
p[815], p[816], p[817], p[818], p[819], p[81], p[820], p[821], p[822],
p[823], p[824], p[825], p[826], p[827], p[828], p[829], p[82], p[830],
p[831], p[832], p[833], p[834], p[835], p[836], p[837], p[838], p[839],
p[83], p[840], p[841], p[842], p[843], p[844], p[845], p[846], p[847],
p[848], p[849], p[84], p[850], p[851], p[852], p[853], p[854], p[855],
p[856], p[857], p[858], p[859], p[85], p[860], p[861], p[862], p[863],
p[864], p[865], p[866], p[867], p[868], p[869], p[86], p[870], p[871],
p[872], p[873], p[874], p[875], p[876], p[877], p[878], p[879], p[87],
p[880], p[881], p[882], p[883], p[884], p[885], p[886], p[887], p[888],
p[889], p[88], p[890], p[891], p[892], p[893], p[894], p[895], p[896],
p[897], p[898], p[899], p[89], p[8], p[900], p[901], p[902], p[903],
p[904], p[905], p[906], p[907], p[908], p[909], p[90], p[910], p[911],
p[912], p[913], p[914], p[915], p[916], p[917], p[918], p[919], p[91],
p[920], p[921], p[922], p[923], p[924], p[925], p[926], p[927], p[928],
p[929], p[92], p[930], p[931], p[932], p[933], p[934], p[935], p[936],
p[937], p[938], p[939], p[93], p[940], p[941], p[942], p[943], p[944],
p[945], p[946], p[947], p[948], p[949], p[94], p[950], p[951], p[952],
p[953], p[954], p[955], p[956], p[957], p[958], p[959], p[95], p[960],
p[961], p[962], p[963], p[964], p[965], p[966], p[967], p[968], p[969],
p[96], p[970], p[971], p[972], p[973], p[974], p[975], p[976], p[977],
p[978], p[979], p[97], p[980], p[981], p[982], p[983], p[984], p[985],
p[986], p[987], p[988], p[989], p[98], p[990], p[991], p[992], p[993],
p[994], p[995], p[996], p[997], p[998], p[999], p[99], p[9] triggered
hat{ESS} warnings.
Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
 
\end{verbatim}

That is a lot of diagnostic failures. To avoid overwhelming ourselves
with too many detailed diagnostic messages let's focus on the four
parameter expectands.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{base\_samples }\OperatorTok{=}\NormalTok{ util.filter\_expectands(samples, [}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{], }\VariableTok{True}\NormalTok{)}
\NormalTok{util.check\_all\_expectand\_diagnostics(base\_samples)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
alpha:
  Split hat{R} (1.201) exceeds 1.1.
  Chain 1: hat{ESS} (25.7) is smaller than desired (100).
  Chain 2: hat{ESS} (10.8) is smaller than desired (100).
  Chain 3: hat{ESS} (16.5) is smaller than desired (100).
  Chain 4: hat{ESS} (14.7) is smaller than desired (100).

beta[1]:
  Split hat{R} (1.512) exceeds 1.1.
  Chain 1: hat{ESS} (10.9) is smaller than desired (100).
  Chain 2: hat{ESS} (14.1) is smaller than desired (100).
  Chain 3: hat{ESS} (7.7) is smaller than desired (100).
  Chain 4: hat{ESS} (5.5) is smaller than desired (100).

beta[2]:
  Split hat{R} (1.260) exceeds 1.1.
  Chain 1: hat{ESS} (9.5) is smaller than desired (100).
  Chain 2: hat{ESS} (15.1) is smaller than desired (100).
  Chain 3: hat{ESS} (7.6) is smaller than desired (100).
  Chain 4: hat{ESS} (6.4) is smaller than desired (100).

beta[3]:
  Split hat{R} (2.019) exceeds 1.1.
  Chain 1: hat{ESS} (5.3) is smaller than desired (100).
  Chain 2: hat{ESS} (11.4) is smaller than desired (100).
  Chain 3: hat{ESS} (8.0) is smaller than desired (100).
  Chain 4: hat{ESS} (9.9) is smaller than desired (100).


Split Rhat larger than 1.1 suggests that at least one of the Markov
chains has not reached an equilibrium.
 
Small empirical effective sample sizes result in imprecise Markov chain
Monte Carlo estimators.
 
\end{verbatim}

All four parameter expectands exhibit split \(\hat{R}\) warnings and low
empirical effective sample size warnings. The question is whether or not
the split \(\hat{R}\) warnings indicate quasistationarity or just
insufficient exploration.

Motivated by the small effective sample size estimates let's look at the
empirical correlograms for each parameter expectand.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}

\NormalTok{util.plot\_empirical\_correlogram(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{], }
                                \DecValTok{300}\NormalTok{, [}\OperatorTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{],  }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_empirical\_correlogram(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{300}\NormalTok{, [}\OperatorTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{],  }\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_empirical\_correlogram(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{300}\NormalTok{, [}\OperatorTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{],  }\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_empirical\_correlogram(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{300}\NormalTok{, [}\OperatorTok{{-}}\FloatTok{0.05}\NormalTok{, }\FloatTok{1.05}\NormalTok{],  }\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{)}

\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-16-output-1.pdf}

Regardless of whether or not these Markov chains are stationary they are
extremely autocorrelated. Even assuming stationarity we wouldn't start
to forget the beginning of each Markov chain until we've worked through
a quarter of the total length, leaving only about four independent
samples across each chain.

This is consistent with the constraint violations breaking the coherent,
gradient-driven exploration of Hamiltonian Monte Carlo so that the
Markov chains devolve into diffuse random walks. Indeed looking at the
chain-separated pairs plots we see the spatial color continuity
characteristic of a random walk.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_pairs\_by\_chain(samples[}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{], }\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }
\NormalTok{                         samples[}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{], }\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-17-output-1.pdf}

To more quantitatively blame the large split \(\hat{R}\)s on these
strong autocorrelations we can plot the split \(\hat{R}\) from each
expectand against the corresponding empirical effective sample size.
Specifically for each expectand we plot split \(\hat{R}\) against we use
the smallest empirical effective sample size of the four Markov chains.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rhats }\OperatorTok{=}\NormalTok{ util.compute\_split\_rhats(samples)}
\NormalTok{min\_ess\_hats }\OperatorTok{=}\NormalTok{ util.compute\_min\_ess\_hats(samples)}

\NormalTok{plot.scatter(rhats, min\_ess\_hats, color}\OperatorTok{=}\NormalTok{dark, s}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{plot.gca().set\_xlim([}\FloatTok{0.95}\NormalTok{, }\DecValTok{2}\NormalTok{])}
\NormalTok{plot.gca().set\_xlabel(}\StringTok{"Split Rhat"}\NormalTok{)}
\NormalTok{plot.gca().set\_ylim([}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{])}
\NormalTok{plot.gca().set\_ylabel(}\StringTok{"Empirical Effective}\CharTok{\textbackslash{}n}\StringTok{Sample Size"}\NormalTok{)}
\NormalTok{plot.gca().spines[}\StringTok{"top"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}
\NormalTok{plot.gca().spines[}\StringTok{"right"}\NormalTok{].set\_visible(}\VariableTok{False}\NormalTok{)}

\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-18-output-1.pdf}

Every expectand with a large split \(\hat{R}\)s also exhibits a
particularly small minimum empirical effective sample size, confirming
that the latter are due to our Markov chains not containing enough
information.

If we are sloppy, ignore these diagnostics, and assume that all of our
Markov chain Monte Carlo estimators are accurate then we are quickly
mislead about the actual behavior of the posterior distribution. One way
to guard against this sloppiness is to always accompany a Markov chain
Monte Carlo estimator with an estimated error. Even if that error is
inaccurate it can sometimes communicate underlying problems.

For example let's look at a pushforward histogram for each parameter
with light gray bands visualizing twice the standard error around the
bin probability estimates in dark red.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}

\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{], }
                                \DecValTok{25}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{25}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{25}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{25}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{)}

\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-19-output-1.pdf}

If we look at the central estimates alone we might convince ourselves of
all kinds of interesting structure. For example potential multi-modality
in \texttt{alpha} and \texttt{beta{[}2{]}} and platykurticity in
\texttt{beta{[}1{]}} and \texttt{beta{[}3{]}}. These structures,
however, are all within the scope of the relatively large standard error
bands which suggests that they are all consistent with estimator noise.

Reducing the number of bins decreases the relative standard errors but
at the same time many of the visual artifacts recede.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f, axarr }\OperatorTok{=}\NormalTok{ plot.subplots(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, layout}\OperatorTok{=}\StringTok{"constrained"}\NormalTok{)}

\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{], }
                                \DecValTok{10}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{10}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{10}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{)}
\NormalTok{util.plot\_expectand\_pushforward(axarr[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{], samples[}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{], }
                                \DecValTok{10}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{)}

\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-20-output-1.pdf}

When the bin indicator functions enjoy Markov chain Monte Carlo central
limit theorems these standard error bands allow us to discriminate
between meaningful structure and accidental artifacts regardless of the
histogram binning. Even if central limit theorems don't hold the error
bands provide one more way that we can potentially diagnose
untrustworthy computation.

The \texttt{plot\_expectand\_pushforward} can also overlay a baseline
value for comparison, for example when comparing posterior inferences to
the ground truth in simulation studies.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_expectand\_pushforward(plot.gca(), samples[}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{],}
                                \DecValTok{10}\NormalTok{, display\_name}\OperatorTok{=}\StringTok{"alpha"}\NormalTok{,}
\NormalTok{                                baseline}\OperatorTok{=}\FloatTok{0.5}\NormalTok{,}
\NormalTok{                                baseline\_color}\OperatorTok{=}\NormalTok{util.mid\_teal)}
\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-21-output-1.pdf}

Moreover the expectand pushforward histograms can be plotted on top of
each other for a more direct comparison.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{util.plot\_expectand\_pushforward(plot.gca(), samples[}\StringTok{\textquotesingle{}beta[1]\textquotesingle{}}\NormalTok{],}
                                \DecValTok{50}\NormalTok{, flim}\OperatorTok{=}\NormalTok{[}\OperatorTok{{-}}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.4}\NormalTok{],}
\NormalTok{                                ylim}\OperatorTok{=}\NormalTok{[}\DecValTok{0}\NormalTok{, }\DecValTok{60}\NormalTok{],}
\NormalTok{                                display\_name}\OperatorTok{=}\StringTok{"Slopes"}\NormalTok{,}
\NormalTok{                                color}\OperatorTok{=}\NormalTok{util.light)}
\NormalTok{plot.gca().text(}\FloatTok{0.3}\NormalTok{, }\DecValTok{55}\NormalTok{, }\StringTok{"beta[1]"}\NormalTok{, color}\OperatorTok{=}\NormalTok{util.light)}

\NormalTok{util.plot\_expectand\_pushforward(plot.gca(), samples[}\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{],}
                                \DecValTok{50}\NormalTok{, flim}\OperatorTok{=}\NormalTok{[}\OperatorTok{{-}}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.4}\NormalTok{],}
\NormalTok{                                color}\OperatorTok{=}\NormalTok{util.mid,}
\NormalTok{                                border}\OperatorTok{=}\StringTok{"\#BBBBBB"}\NormalTok{,}
\NormalTok{                                border\_opacity}\OperatorTok{=}\FloatTok{0.5}\NormalTok{,}
\NormalTok{                                add}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{plot.gca().text(}\OperatorTok{{-}}\FloatTok{0.03}\NormalTok{, }\DecValTok{60}\NormalTok{, }\StringTok{"beta[2]"}\NormalTok{, color}\OperatorTok{=}\NormalTok{util.mid)}

\NormalTok{util.plot\_expectand\_pushforward(plot.gca(), samples[}\StringTok{\textquotesingle{}beta[3]\textquotesingle{}}\NormalTok{],}
                                \DecValTok{50}\NormalTok{, flim}\OperatorTok{=}\NormalTok{[}\OperatorTok{{-}}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.4}\NormalTok{],}
\NormalTok{                                color}\OperatorTok{=}\NormalTok{util.dark,}
\NormalTok{                                border}\OperatorTok{=}\StringTok{"\#BBBBBB"}\NormalTok{,}
\NormalTok{                                border\_opacity}\OperatorTok{=}\FloatTok{0.5}\NormalTok{,}
\NormalTok{                                add}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{plot.gca().text(}\OperatorTok{{-}}\FloatTok{0.1}\NormalTok{, }\DecValTok{35}\NormalTok{, }\StringTok{"beta[3]"}\NormalTok{, color}\OperatorTok{=}\NormalTok{util.dark)}

\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-22-output-1.pdf}

Finally if we want to explore the pushforward posterior distribution of
other expectands that have not already been evaluated in the
\texttt{Stan} program then we need to evaluate them ourselves.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ euclidean\_length(x):}
  \ControlFlowTok{return}\NormalTok{ math.sqrt(numpy.dot(x, x))}

\NormalTok{beta\_names }\OperatorTok{=}\NormalTok{ util.name\_array(}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, [data[}\StringTok{\textquotesingle{}M\textquotesingle{}}\NormalTok{]])}

\NormalTok{pushforward\_samples }\OperatorTok{=} \OperatorTok{\textbackslash{}}
\NormalTok{  util.eval\_expectand\_pushforward(samples, euclidean\_length,}
\NormalTok{                                  \{}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{: beta\_names\})}

\NormalTok{util.plot\_expectand\_pushforward(plot.gca(), pushforward\_samples, }\DecValTok{10}\NormalTok{,}
\NormalTok{                                display\_name}\OperatorTok{=}\StringTok{"Slope Vector Length"}\NormalTok{)}
\NormalTok{plot.show()}
\end{Highlighting}
\end{Shaded}

\includegraphics{pystan3_demo_files/figure-pdf/cell-23-output-1.pdf}

Calculating the probability allocated to implicitly-defined subsets
proceeds similarly.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi\_est }\OperatorTok{=}\NormalTok{ util.implicit\_subset\_prob(samples,}
                                   \KeywordTok{lambda}\NormalTok{ x: x }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{,}
\NormalTok{                                   \{}\StringTok{\textquotesingle{}x\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}beta[2]\textquotesingle{}}\NormalTok{\})}

\BuiltInTok{print}\NormalTok{( }\StringTok{\textquotesingle{}Posterior probability that beta[2] is greater than zero \textquotesingle{}}
      \SpecialStringTok{f\textquotesingle{}= }\SpecialCharTok{\{}\NormalTok{pi\_est[}\DecValTok{0}\NormalTok{]}\SpecialCharTok{:.2\}}\SpecialStringTok{ +/{-} }\SpecialCharTok{\{}\DecValTok{2} \OperatorTok{*}\NormalTok{ pi\_est[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{:.2\}}\SpecialStringTok{.\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Posterior probability that beta[2] is greater than zero = 0.28 +/- 0.12.
\end{verbatim}

\section*{License}\label{license}
\addcontentsline{toc}{section}{License}

The code in this case study is copyrighted by Michael Betancourt and
licensed under the new BSD (3-clause) license:

https://opensource.org/licenses/BSD-3-Clause

The text and figures in this case study are copyrighted by Michael
Betancourt and licensed under the CC BY-NC 4.0 license:

https://creativecommons.org/licenses/by-nc/4.0/

\section*{Original Computing
Environment}\label{original-computing-environment}
\addcontentsline{toc}{section}{Original Computing Environment}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ watermark }\ImportTok{import}\NormalTok{ watermark}
\BuiltInTok{print}\NormalTok{(watermark())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Last updated: 2024-09-13T15:41:15.396481-04:00

Python implementation: CPython
Python version       : 3.9.6
IPython version      : 8.16.1

Compiler    : Clang 12.0.0 (clang-1200.0.32.29)
OS          : Darwin
Release     : 23.4.0
Machine     : x86_64
Processor   : i386
CPU cores   : 16
Architecture: 64bit
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(watermark(packages}\OperatorTok{=}\StringTok{"matplotlib,numpy,stan,scipy"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
matplotlib: 3.8.0
numpy     : 1.26.1
stan      : 3.9.0
scipy     : 1.11.3
\end{verbatim}



\end{document}
